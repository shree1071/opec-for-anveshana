{"version":3,"file":"lib.modern.js","sources":["../src/BaseConversation.ts","../src/utils/BaseConnection.ts","../src/version.ts","../src/utils/events.ts","../src/utils/overrides.ts","../src/utils/errors.ts","../src/utils/WebSocketConnection.ts","../src/utils/audio.ts","../src/utils/createWorkletModuleLoader.ts","../src/utils/rawAudioProcessor.generated.ts","../src/utils/WebRTCConnection.ts","../src/utils/ConnectionFactory.ts","../src/utils/compatibility.ts","../src/utils/applyDelay.ts","../src/TextConversation.ts","../src/utils/input.ts","../src/utils/audioConcatProcessor.generated.ts","../src/utils/output.ts","../src/VoiceConversation.ts","../src/utils/postOverallFeedback.ts","../src/scribe/connection.ts","../src/utils/scribeAudioProcessor.generated.ts","../src/scribe/scribe.ts","../src/index.ts"],"sourcesContent":["import { Callbacks, Mode, Status } from \"@elevenlabs/types\";\nimport type {\n  BaseConnection,\n  DisconnectionDetails,\n  SessionConfig,\n  FormatConfig,\n} from \"./utils/BaseConnection\";\nimport type {\n  AgentAudioEvent,\n  AgentChatResponsePartEvent,\n  AgentResponseEvent,\n  ClientToolCallEvent,\n  IncomingSocketEvent,\n  InternalTentativeAgentResponseEvent,\n  InterruptionEvent,\n  UserTranscriptionEvent,\n  VadScoreEvent,\n  MCPToolCallClientEvent,\n  AgentToolResponseEvent,\n  ConversationMetadataEvent,\n  AsrInitiationMetadataEvent,\n  MCPConnectionStatusEvent,\n  ErrorMessageEvent,\n  AgentToolRequestEvent,\n} from \"./utils/events\";\nimport type { InputConfig } from \"./utils/input\";\nimport type { OutputConfig } from \"./utils/output\";\n\nexport type { Role, Mode, Status, Callbacks } from \"@elevenlabs/types\";\n\n/** Allows self-hosting the worklets to avoid whitelisting blob: and data: in the CSP script-src  */\nexport type AudioWorkletConfig = {\n  workletPaths?: {\n    rawAudioProcessor?: string;\n    audioConcatProcessor?: string;\n  };\n  libsampleratePath?: string;\n};\n\nexport type Options = SessionConfig &\n  Callbacks &\n  ClientToolsConfig &\n  InputConfig &\n  OutputConfig &\n  AudioWorkletConfig;\n\nexport type PartialOptions = SessionConfig &\n  Partial<Callbacks> &\n  Partial<ClientToolsConfig> &\n  Partial<InputConfig> &\n  Partial<OutputConfig> &\n  Partial<FormatConfig> &\n  Partial<AudioWorkletConfig>;\n\nexport type ClientToolsConfig = {\n  clientTools: Record<\n    string,\n    (\n      parameters: any\n    ) => Promise<string | number | void> | string | number | void\n  >;\n};\n\nconst EMPTY_FREQUENCY_DATA = new Uint8Array(0);\n\nexport class BaseConversation {\n  protected lastInterruptTimestamp = 0;\n  protected mode: Mode = \"listening\";\n  protected status: Status = \"connecting\";\n  protected volume = 1;\n  protected currentEventId = 1;\n  protected lastFeedbackEventId = 0;\n  protected canSendFeedback = false;\n\n  protected static getFullOptions(partialOptions: PartialOptions): Options {\n    return {\n      clientTools: {},\n      onConnect: () => {},\n      onDebug: () => {},\n      onDisconnect: () => {},\n      onError: () => {},\n      onMessage: () => {},\n      onAudio: () => {},\n      onModeChange: () => {},\n      onStatusChange: () => {},\n      onCanSendFeedbackChange: () => {},\n      onInterruption: () => {},\n      ...partialOptions,\n    };\n  }\n\n  protected constructor(\n    protected readonly options: Options,\n    protected readonly connection: BaseConnection\n  ) {\n    if (this.options.onConnect) {\n      this.options.onConnect({ conversationId: connection.conversationId });\n    }\n    this.connection.onMessage(this.onMessage);\n    this.connection.onDisconnect(this.endSessionWithDetails);\n    this.connection.onModeChange(mode => this.updateMode(mode));\n    this.updateStatus(\"connected\");\n  }\n\n  public endSession() {\n    return this.endSessionWithDetails({ reason: \"user\" });\n  }\n\n  private endSessionWithDetails = async (details: DisconnectionDetails) => {\n    if (this.status !== \"connected\" && this.status !== \"connecting\") return;\n    this.updateStatus(\"disconnecting\");\n    await this.handleEndSession();\n    this.updateStatus(\"disconnected\");\n    if (this.options.onDisconnect) {\n      this.options.onDisconnect(details);\n    }\n  };\n\n  protected async handleEndSession() {\n    this.connection.close();\n  }\n\n  protected updateMode(mode: Mode) {\n    if (mode !== this.mode) {\n      this.mode = mode;\n      if (this.options.onModeChange) {\n        this.options.onModeChange({ mode });\n      }\n    }\n  }\n\n  protected updateStatus(status: Status) {\n    if (status !== this.status) {\n      this.status = status;\n      if (this.options.onStatusChange) {\n        this.options.onStatusChange({ status });\n      }\n    }\n  }\n\n  protected updateCanSendFeedback() {\n    const canSendFeedback = this.currentEventId !== this.lastFeedbackEventId;\n    if (this.canSendFeedback !== canSendFeedback) {\n      this.canSendFeedback = canSendFeedback;\n      if (this.options.onCanSendFeedbackChange) {\n        this.options.onCanSendFeedbackChange({ canSendFeedback });\n      }\n    }\n  }\n\n  protected handleInterruption(event: InterruptionEvent) {\n    if (event.interruption_event) {\n      this.lastInterruptTimestamp = event.interruption_event.event_id;\n\n      if (this.options.onInterruption) {\n        this.options.onInterruption({\n          event_id: event.interruption_event.event_id,\n        });\n      }\n    }\n  }\n\n  protected handleAgentResponse(event: AgentResponseEvent) {\n    if (this.options.onMessage) {\n      this.options.onMessage({\n        source: \"ai\",\n        role: \"agent\",\n        message: event.agent_response_event.agent_response,\n      });\n    }\n  }\n\n  protected handleUserTranscript(event: UserTranscriptionEvent) {\n    if (this.options.onMessage) {\n      this.options.onMessage({\n        source: \"user\",\n        role: \"user\",\n        message: event.user_transcription_event.user_transcript,\n      });\n    }\n  }\n\n  protected handleTentativeAgentResponse(\n    event: InternalTentativeAgentResponseEvent\n  ) {\n    if (this.options.onDebug) {\n      this.options.onDebug({\n        type: \"tentative_agent_response\",\n        response:\n          event.tentative_agent_response_internal_event\n            .tentative_agent_response,\n      });\n    }\n  }\n\n  protected handleVadScore(event: VadScoreEvent) {\n    if (this.options.onVadScore) {\n      this.options.onVadScore({\n        vadScore: event.vad_score_event.vad_score,\n      });\n    }\n  }\n\n  protected async handleClientToolCall(event: ClientToolCallEvent) {\n    if (\n      Object.prototype.hasOwnProperty.call(\n        this.options.clientTools,\n        event.client_tool_call.tool_name\n      )\n    ) {\n      try {\n        const result =\n          (await this.options.clientTools[event.client_tool_call.tool_name](\n            event.client_tool_call.parameters\n          )) ?? \"Client tool execution successful.\"; // default client-tool call response\n\n        // The API expects result to be a string, so we need to convert it if it's not already a string\n        const formattedResult =\n          typeof result === \"object\" ? JSON.stringify(result) : String(result);\n\n        this.connection.sendMessage({\n          type: \"client_tool_result\",\n          tool_call_id: event.client_tool_call.tool_call_id,\n          result: formattedResult,\n          is_error: false,\n        });\n      } catch (e) {\n        this.onError(\n          `Client tool execution failed with following error: ${(e as Error)?.message}`,\n          {\n            clientToolName: event.client_tool_call.tool_name,\n          }\n        );\n        this.connection.sendMessage({\n          type: \"client_tool_result\",\n          tool_call_id: event.client_tool_call.tool_call_id,\n          result: `Client tool execution failed: ${(e as Error)?.message}`,\n          is_error: true,\n        });\n      }\n    } else {\n      if (this.options.onUnhandledClientToolCall) {\n        this.options.onUnhandledClientToolCall(event.client_tool_call);\n\n        return;\n      }\n\n      this.onError(\n        `Client tool with name ${event.client_tool_call.tool_name} is not defined on client`,\n        {\n          clientToolName: event.client_tool_call.tool_name,\n        }\n      );\n      this.connection.sendMessage({\n        type: \"client_tool_result\",\n        tool_call_id: event.client_tool_call.tool_call_id,\n        result: `Client tool with name ${event.client_tool_call.tool_name} is not defined on client`,\n        is_error: true,\n      });\n    }\n  }\n\n  protected handleAudio(event: AgentAudioEvent) {}\n\n  protected handleMCPToolCall(event: MCPToolCallClientEvent) {\n    if (this.options.onMCPToolCall) {\n      this.options.onMCPToolCall(event.mcp_tool_call);\n    }\n  }\n\n  protected handleMCPConnectionStatus(event: MCPConnectionStatusEvent) {\n    if (this.options.onMCPConnectionStatus) {\n      this.options.onMCPConnectionStatus(event.mcp_connection_status);\n    }\n  }\n\n  protected handleAgentToolRequest(event: AgentToolRequestEvent) {\n    if (this.options.onAgentToolRequest) {\n      this.options.onAgentToolRequest(event.agent_tool_request);\n    }\n  }\n\n  protected handleAgentToolResponse(event: AgentToolResponseEvent) {\n    if (event.agent_tool_response.tool_name === \"end_call\") {\n      this.endSessionWithDetails({\n        reason: \"agent\",\n        context: new CloseEvent(\"end_call\", { reason: \"Agent ended the call\" }),\n      });\n    }\n\n    if (this.options.onAgentToolResponse) {\n      this.options.onAgentToolResponse(event.agent_tool_response);\n    }\n  }\n\n  protected handleConversationMetadata(event: ConversationMetadataEvent) {\n    if (this.options.onConversationMetadata) {\n      this.options.onConversationMetadata(\n        event.conversation_initiation_metadata_event\n      );\n    }\n  }\n\n  protected handleAsrInitiationMetadata(event: AsrInitiationMetadataEvent) {\n    if (this.options.onAsrInitiationMetadata) {\n      this.options.onAsrInitiationMetadata(event.asr_initiation_metadata_event);\n    }\n  }\n\n  protected handleAgentChatResponsePart(event: AgentChatResponsePartEvent) {\n    if (this.options.onAgentChatResponsePart) {\n      this.options.onAgentChatResponsePart(event.text_response_part);\n    }\n  }\n\n  protected handleErrorEvent(event: ErrorMessageEvent) {\n    const errorType = event.error_event.error_type;\n    const message =\n      event.error_event.message || event.error_event.reason || \"Unknown error\";\n\n    if (errorType === \"max_duration_exceeded\") {\n      this.endSessionWithDetails({\n        reason: \"error\",\n        message: message,\n        context: new Event(\"max_duration_exceeded\"),\n      });\n      return;\n    }\n\n    this.onError(`Server error: ${message}`, {\n      errorType,\n      code: event.error_event.code,\n      debugMessage: event.error_event.debug_message,\n      details: event.error_event.details,\n    });\n  }\n\n  private onMessage = async (parsedEvent: IncomingSocketEvent) => {\n    switch (parsedEvent.type) {\n      case \"interruption\": {\n        this.handleInterruption(parsedEvent);\n        return;\n      }\n      case \"agent_response\": {\n        this.handleAgentResponse(parsedEvent);\n        return;\n      }\n      case \"user_transcript\": {\n        this.handleUserTranscript(parsedEvent);\n        return;\n      }\n      case \"internal_tentative_agent_response\": {\n        this.handleTentativeAgentResponse(parsedEvent);\n        return;\n      }\n      case \"client_tool_call\": {\n        try {\n          await this.handleClientToolCall(parsedEvent);\n        } catch (error) {\n          this.onError(\n            `Unexpected error in client tool call handling: ${error instanceof Error ? error.message : String(error)}`,\n            {\n              clientToolName: parsedEvent.client_tool_call.tool_name,\n              toolCallId: parsedEvent.client_tool_call.tool_call_id,\n            }\n          );\n        }\n        return;\n      }\n      case \"audio\": {\n        this.handleAudio(parsedEvent);\n        return;\n      }\n\n      case \"vad_score\": {\n        this.handleVadScore(parsedEvent);\n        return;\n      }\n\n      case \"ping\": {\n        this.connection.sendMessage({\n          type: \"pong\",\n          event_id: parsedEvent.ping_event.event_id,\n        });\n        // parsedEvent.ping_event.ping_ms can be used on client side, for example\n        // to warn if ping is too high that experience might be degraded.\n        return;\n      }\n\n      case \"mcp_tool_call\": {\n        this.handleMCPToolCall(parsedEvent);\n        return;\n      }\n\n      case \"mcp_connection_status\": {\n        this.handleMCPConnectionStatus(parsedEvent);\n        return;\n      }\n\n      case \"agent_tool_request\": {\n        this.handleAgentToolRequest(parsedEvent);\n        return;\n      }\n\n      case \"agent_tool_response\": {\n        this.handleAgentToolResponse(parsedEvent);\n        return;\n      }\n\n      case \"conversation_initiation_metadata\": {\n        this.handleConversationMetadata(parsedEvent);\n        return;\n      }\n\n      case \"asr_initiation_metadata\": {\n        this.handleAsrInitiationMetadata(parsedEvent);\n        return;\n      }\n\n      case \"agent_chat_response_part\": {\n        this.handleAgentChatResponsePart(parsedEvent);\n        return;\n      }\n\n      case \"error\": {\n        this.handleErrorEvent(parsedEvent);\n        return;\n      }\n\n      default: {\n        if (this.options.onDebug) {\n          this.options.onDebug(parsedEvent);\n        }\n        return;\n      }\n    }\n  };\n\n  private onError(message: string, context?: any) {\n    console.error(message, context);\n    if (this.options.onError) {\n      this.options.onError(message, context);\n    }\n  }\n\n  public getId() {\n    return this.connection.conversationId;\n  }\n\n  public isOpen() {\n    return this.status === \"connected\";\n  }\n\n  public setVolume = ({ volume }: { volume: number }) => {\n    this.volume = volume;\n  };\n\n  public setMicMuted(isMuted: boolean) {\n    this.connection.setMicMuted(isMuted);\n  }\n\n  public getInputByteFrequencyData(): Uint8Array {\n    return EMPTY_FREQUENCY_DATA;\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array {\n    return EMPTY_FREQUENCY_DATA;\n  }\n\n  public getInputVolume() {\n    return 0;\n  }\n\n  public getOutputVolume() {\n    return 0;\n  }\n\n  public sendFeedback(like: boolean) {\n    if (!this.canSendFeedback) {\n      console.warn(\n        this.lastFeedbackEventId === 0\n          ? \"Cannot send feedback: the conversation has not started yet.\"\n          : \"Cannot send feedback: feedback has already been sent for the current response.\"\n      );\n      return;\n    }\n\n    this.connection.sendMessage({\n      type: \"feedback\",\n      score: like ? \"like\" : \"dislike\",\n      event_id: this.currentEventId,\n    });\n    this.lastFeedbackEventId = this.currentEventId;\n    this.updateCanSendFeedback();\n  }\n\n  public sendContextualUpdate(text: string) {\n    this.connection.sendMessage({\n      type: \"contextual_update\",\n      text,\n    });\n  }\n\n  public sendUserMessage(text: string) {\n    this.connection.sendMessage({\n      type: \"user_message\",\n      text,\n    });\n  }\n\n  public sendUserActivity() {\n    this.connection.sendMessage({\n      type: \"user_activity\",\n    });\n  }\n\n  public sendMCPToolApprovalResult(toolCallId: string, isApproved: boolean) {\n    this.connection.sendMessage({\n      type: \"mcp_tool_approval_result\",\n      tool_call_id: toolCallId,\n      is_approved: isApproved,\n    });\n  }\n}\n","import type { IncomingSocketEvent, OutgoingSocketEvent } from \"./events\";\nimport type { Mode } from \"../BaseConversation\";\nimport type { ConversationConfigOverrideAgentLanguage as Language } from \"@elevenlabs/types/generated/types/asyncapi-types\";\nimport type { DisconnectionDetails } from \"@elevenlabs/types\";\n\nexport type {\n  DisconnectionDetails,\n  ConversationConfigOverrideAgentLanguage as Language,\n} from \"@elevenlabs/types\";\n\nexport type DelayConfig = {\n  default: number;\n  android?: number;\n  ios?: number;\n};\n\nexport type FormatConfig = {\n  format: \"pcm\" | \"ulaw\";\n  sampleRate: number;\n  outputDeviceId?: string;\n};\n\nexport type OnDisconnectCallback = (details: DisconnectionDetails) => void;\nexport type OnMessageCallback = (event: IncomingSocketEvent) => void;\n\nexport type BaseSessionConfig = {\n  origin?: string;\n  authorization?: string;\n  livekitUrl?: string;\n  overrides?: {\n    agent?: {\n      prompt?: {\n        prompt?: string;\n      };\n      firstMessage?: string;\n      language?: Language;\n    };\n    tts?: {\n      voiceId?: string;\n      speed?: number;\n      stability?: number;\n      similarityBoost?: number;\n    };\n    conversation?: {\n      textOnly?: boolean;\n    };\n    client?: {\n      source?: string;\n      version?: string;\n    };\n  };\n  customLlmExtraBody?: unknown;\n  dynamicVariables?: Record<string, string | number | boolean>;\n  useWakeLock?: boolean;\n  connectionDelay?: DelayConfig;\n  textOnly?: boolean;\n  userId?: string;\n};\n\nexport type ConnectionType = \"websocket\" | \"webrtc\";\n\nexport type PublicSessionConfig = BaseSessionConfig & {\n  agentId: string;\n  connectionType: ConnectionType;\n  signedUrl?: never;\n  conversationToken?: never;\n};\n\nexport type PrivateWebSocketSessionConfig = BaseSessionConfig & {\n  signedUrl: string;\n  connectionType?: \"websocket\";\n  agentId?: never;\n  conversationToken?: never;\n};\n\nexport type PrivateWebRTCSessionConfig = BaseSessionConfig & {\n  conversationToken: string;\n  connectionType?: \"webrtc\";\n  agentId?: never;\n  signedUrl?: never;\n};\n\n// Union type for all possible session configurations\nexport type SessionConfig =\n  | PublicSessionConfig\n  | PrivateWebSocketSessionConfig\n  | PrivateWebRTCSessionConfig;\n\nexport abstract class BaseConnection {\n  public abstract readonly conversationId: string;\n  public abstract readonly inputFormat: FormatConfig;\n  public abstract readonly outputFormat: FormatConfig;\n\n  protected queue: IncomingSocketEvent[] = [];\n  protected disconnectionDetails: DisconnectionDetails | null = null;\n  protected onDisconnectCallback: OnDisconnectCallback | null = null;\n  protected onMessageCallback: OnMessageCallback | null = null;\n  protected onModeChangeCallback: ((mode: Mode) => void) | null = null;\n  protected onDebug?: (info: unknown) => void;\n\n  constructor(config: { onDebug?: (info: unknown) => void } = {}) {\n    this.onDebug = config.onDebug;\n  }\n\n  protected debug(info: unknown) {\n    if (this.onDebug) this.onDebug(info);\n  }\n\n  public abstract close(): void;\n  public abstract sendMessage(message: OutgoingSocketEvent): void;\n  public abstract setMicMuted(isMuted: boolean): Promise<void>;\n\n  public onMessage(callback: OnMessageCallback) {\n    this.onMessageCallback = callback;\n    const queue = this.queue;\n    this.queue = [];\n\n    if (queue.length > 0) {\n      // Make sure the queue is flushed after the constructors finishes and\n      // classes are initialized.\n      queueMicrotask(() => {\n        queue.forEach(callback);\n      });\n    }\n  }\n\n  public onDisconnect(callback: OnDisconnectCallback) {\n    this.onDisconnectCallback = callback;\n    const details = this.disconnectionDetails;\n    if (details) {\n      // Make sure the event is triggered after the constructors finishes and\n      // classes are initialized.\n      queueMicrotask(() => {\n        callback(details);\n      });\n    }\n  }\n\n  public onModeChange(callback: (mode: Mode) => void) {\n    this.onModeChangeCallback = callback;\n  }\n\n  protected updateMode(mode: Mode) {\n    this.onModeChangeCallback?.(mode);\n  }\n\n  protected disconnect(details: DisconnectionDetails) {\n    if (!this.disconnectionDetails) {\n      this.disconnectionDetails = details;\n      this.onDisconnectCallback?.(details);\n    }\n  }\n\n  protected handleMessage(parsedEvent: IncomingSocketEvent) {\n    if (this.onMessageCallback) {\n      this.onMessageCallback(parsedEvent);\n    } else {\n      this.queue.push(parsedEvent);\n    }\n  }\n}\n\nexport function parseFormat(format: string): FormatConfig {\n  const [formatPart, sampleRatePart] = format.split(\"_\");\n  if (![\"pcm\", \"ulaw\"].includes(formatPart)) {\n    throw new Error(`Invalid format: ${format}`);\n  }\n\n  const sampleRate = Number.parseInt(sampleRatePart);\n  if (Number.isNaN(sampleRate)) {\n    throw new Error(`Invalid sample rate: ${sampleRatePart}`);\n  }\n\n  return {\n    format: formatPart as FormatConfig[\"format\"],\n    sampleRate,\n  };\n}\n","// This file is auto-generated during build\nexport const PACKAGE_VERSION = \"0.13.0\";\n","import { Outgoing } from \"@elevenlabs/types\";\nimport type { AudioAlignmentEvent } from \"@elevenlabs/types\";\nimport {\n  AgentChatResponsePartClientEvent,\n  AgentResponse,\n  AgentResponseCorrection,\n  AgentToolResponseClientEvent,\n  AsrInitiationMetadataEvent as AsrMetadataEvent,\n  Audio,\n  AgentToolRequestClientEvent,\n  ClientToolCallMessage,\n  ConversationMetadata,\n  ErrorMessage,\n  Interruption,\n  McpConnectionStatusClientEvent,\n  McpToolCall,\n  Ping,\n  InternalTentativeAgentResponse as TentativeAgentResponseInternal,\n  UserTranscript,\n  VadScore,\n} from \"@elevenlabs/types/generated/types/asyncapi-types\";\n\n// Compatibility layer - incoming events\nexport type UserTranscriptionEvent = UserTranscript;\nexport type AgentResponseEvent = AgentResponse;\nexport type AgentAudioEvent = Audio;\nexport type InterruptionEvent = Interruption;\nexport type InternalTentativeAgentResponseEvent =\n  TentativeAgentResponseInternal;\nexport type ConfigEvent = ConversationMetadata;\nexport type PingEvent = Ping;\nexport type ClientToolCallEvent = ClientToolCallMessage;\nexport type VadScoreEvent = VadScore;\nexport type MCPToolCallClientEvent = McpToolCall;\nexport type AgentResponseCorrectionEvent = AgentResponseCorrection;\nexport type AgentToolRequestEvent = AgentToolRequestClientEvent;\nexport type AgentToolResponseEvent = AgentToolResponseClientEvent;\nexport type ConversationMetadataEvent = ConversationMetadata;\nexport type AsrInitiationMetadataEvent = AsrMetadataEvent;\nexport type MCPConnectionStatusEvent = McpConnectionStatusClientEvent;\nexport type AgentChatResponsePartEvent = AgentChatResponsePartClientEvent;\nexport type ErrorMessageEvent = ErrorMessage;\nexport type { AudioAlignmentEvent };\n\nexport type IncomingSocketEvent =\n  | UserTranscriptionEvent\n  | AgentResponseEvent\n  | AgentResponseCorrectionEvent\n  | AgentAudioEvent\n  | InterruptionEvent\n  | InternalTentativeAgentResponseEvent\n  | ConfigEvent\n  | PingEvent\n  | ClientToolCallEvent\n  | VadScoreEvent\n  | MCPToolCallClientEvent\n  | AgentToolRequestEvent\n  | AgentToolResponseEvent\n  | ConversationMetadataEvent\n  | AsrInitiationMetadataEvent\n  | MCPConnectionStatusEvent\n  | AgentChatResponsePartEvent\n  | ErrorMessageEvent;\n\n// Compatibility layer - outgoing events\nexport type PongEvent = Outgoing.PongClientToOrchestratorEvent;\nexport type UserAudioEvent = Outgoing.UserAudio;\nexport type UserFeedbackEvent = Outgoing.UserFeedbackClientToOrchestratorEvent;\nexport type ClientToolResultEvent =\n  Outgoing.ClientToolResultClientToOrchestratorEvent;\nexport type InitiationClientDataEvent =\n  Outgoing.ConversationInitiationClientToOrchestratorEvent;\nexport type ContextualUpdateEvent =\n  Outgoing.ContextualUpdateClientToOrchestratorEvent;\nexport type UserMessageEvent = Outgoing.UserMessageClientToOrchestratorEvent;\nexport type UserActivityEvent = Outgoing.UserActivityClientToOrchestratorEvent;\nexport type MCPToolApprovalResultEvent =\n  Outgoing.McpToolApprovalResultClientToOrchestratorEvent;\n\nexport type OutgoingSocketEvent =\n  | PongEvent\n  | UserAudioEvent\n  | InitiationClientDataEvent\n  | UserFeedbackEvent\n  | ClientToolResultEvent\n  | ContextualUpdateEvent\n  | UserMessageEvent\n  | UserActivityEvent\n  | MCPToolApprovalResultEvent;\n\nexport function isValidSocketEvent(event: any): event is IncomingSocketEvent {\n  return !!event.type;\n}\n","import type { SessionConfig } from \"./BaseConnection\";\nimport type { InitiationClientDataEvent } from \"./events\";\n\nexport const CONVERSATION_INITIATION_CLIENT_DATA_TYPE =\n  \"conversation_initiation_client_data\";\n\nexport function constructOverrides(\n  config: SessionConfig\n): InitiationClientDataEvent {\n  const overridesEvent: InitiationClientDataEvent = {\n    type: CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n  };\n\n  if (config.overrides) {\n    overridesEvent.conversation_config_override = {\n      agent: {\n        prompt: config.overrides.agent?.prompt,\n        first_message: config.overrides.agent?.firstMessage,\n        language: config.overrides.agent?.language,\n      },\n      tts: {\n        voice_id: config.overrides.tts?.voiceId,\n        speed: config.overrides.tts?.speed,\n        stability: config.overrides.tts?.stability,\n        similarity_boost: config.overrides.tts?.similarityBoost,\n      },\n      conversation: {\n        text_only: config.overrides.conversation?.textOnly,\n      },\n    };\n  }\n\n  if (config.customLlmExtraBody) {\n    overridesEvent.custom_llm_extra_body = config.customLlmExtraBody;\n  }\n\n  if (config.dynamicVariables) {\n    overridesEvent.dynamic_variables = config.dynamicVariables;\n  }\n\n  if (config.userId) {\n    overridesEvent.user_id = config.userId;\n  }\n\n  if (config.overrides?.client) {\n    overridesEvent.source_info = {\n      source: config.overrides.client.source,\n      version: config.overrides.client.version,\n    };\n  }\n\n  return overridesEvent;\n}\n","export class SessionConnectionError extends Error {\n  public readonly closeCode?: number;\n  public readonly closeReason?: string;\n\n  constructor(\n    message: string,\n    options?: { closeCode?: number; closeReason?: string }\n  ) {\n    super(message);\n    this.name = \"SessionConnectionError\";\n    this.closeCode = options?.closeCode;\n    this.closeReason = options?.closeReason;\n  }\n}\n","import {\n  BaseConnection,\n  type SessionConfig,\n  type FormatConfig,\n  parseFormat,\n} from \"./BaseConnection\";\nimport { PACKAGE_VERSION } from \"../version\";\nimport {\n  type ConfigEvent,\n  isValidSocketEvent,\n  type OutgoingSocketEvent,\n} from \"./events\";\nimport { constructOverrides } from \"./overrides\";\nimport { SessionConnectionError } from \"./errors\";\n\nconst MAIN_PROTOCOL = \"convai\";\nconst WSS_API_ORIGIN = \"wss://api.elevenlabs.io\";\nconst WSS_API_PATHNAME = \"/v1/convai/conversation?agent_id=\";\n\nexport class WebSocketConnection extends BaseConnection {\n  public readonly conversationId: string;\n  public readonly inputFormat: FormatConfig;\n  public readonly outputFormat: FormatConfig;\n\n  private constructor(\n    private readonly socket: WebSocket,\n    conversationId: string,\n    inputFormat: FormatConfig,\n    outputFormat: FormatConfig\n  ) {\n    super();\n    this.conversationId = conversationId;\n    this.inputFormat = inputFormat;\n    this.outputFormat = outputFormat;\n\n    this.socket.addEventListener(\"error\", event => {\n      // In case the error event is followed by a close event, we want the\n      // latter to be the one that disconnects the session as it contains more\n      // useful information.\n      setTimeout(\n        () =>\n          this.disconnect({\n            reason: \"error\",\n            message: \"The connection was closed due to a socket error.\",\n            context: event,\n          }),\n        0\n      );\n    });\n\n    this.socket.addEventListener(\"close\", event => {\n      this.disconnect(\n        event.code === 1000\n          ? {\n              reason: \"agent\",\n              context: event,\n              closeCode: event.code,\n              closeReason: event.reason || undefined,\n            }\n          : {\n              reason: \"error\",\n              message:\n                event.reason || \"The connection was closed by the server.\",\n              context: event,\n              closeCode: event.code,\n              closeReason: event.reason || undefined,\n            }\n      );\n    });\n\n    this.socket.addEventListener(\"message\", event => {\n      try {\n        const parsedEvent = JSON.parse(event.data);\n        if (!isValidSocketEvent(parsedEvent)) {\n          this.debug({\n            type: \"invalid_event\",\n            message: \"Received invalid socket event\",\n            data: event.data,\n          });\n          return;\n        }\n        this.handleMessage(parsedEvent);\n      } catch (error) {\n        this.debug({\n          type: \"parsing_error\",\n          message: \"Failed to parse socket message\",\n          error: error instanceof Error ? error.message : String(error),\n          data: event.data,\n        });\n      }\n    });\n  }\n\n  public static async create(\n    config: SessionConfig\n  ): Promise<WebSocketConnection> {\n    let socket: WebSocket | null = null;\n\n    try {\n      const origin = config.origin ?? WSS_API_ORIGIN;\n      let url: string;\n\n      const version = config.overrides?.client?.version || PACKAGE_VERSION;\n      const source = config.overrides?.client?.source || \"js_sdk\";\n\n      if (config.signedUrl) {\n        const separator = config.signedUrl.includes(\"?\") ? \"&\" : \"?\";\n        url = `${config.signedUrl}${separator}source=${source}&version=${version}`;\n      } else {\n        url = `${origin}${WSS_API_PATHNAME}${config.agentId}&source=${source}&version=${version}`;\n      }\n\n      const protocols = [MAIN_PROTOCOL];\n      if (config.authorization) {\n        protocols.push(`bearer.${config.authorization}`);\n      }\n      socket = new WebSocket(url, protocols);\n\n      const conversationConfig = await new Promise<\n        ConfigEvent[\"conversation_initiation_metadata_event\"]\n      >((resolve, reject) => {\n        socket!.addEventListener(\n          \"open\",\n          () => {\n            const overridesEvent = constructOverrides(config);\n\n            socket?.send(JSON.stringify(overridesEvent));\n          },\n          { once: true }\n        );\n\n        socket!.addEventListener(\"error\", event => {\n          // In case the error event is followed by a close event, we want the\n          // latter to be the one that rejects the promise as it contains more\n          // useful information.\n          setTimeout(\n            () =>\n              reject(\n                new SessionConnectionError(\n                  \"The connection was closed due to a socket error.\"\n                )\n              ),\n            0\n          );\n        });\n\n        socket!.addEventListener(\"close\", (event: CloseEvent) => {\n          const message =\n            event.reason ||\n            (event.code === 1000\n              ? \"Connection closed normally before session could be established.\"\n              : \"Connection closed unexpectedly before session could be established.\");\n          reject(\n            new SessionConnectionError(message, {\n              closeCode: event.code,\n              closeReason: event.reason || undefined,\n            })\n          );\n        });\n\n        socket!.addEventListener(\n          \"message\",\n          (event: MessageEvent) => {\n            const message = JSON.parse(event.data);\n\n            if (!isValidSocketEvent(message)) {\n              return;\n            }\n\n            if (message.type === \"conversation_initiation_metadata\") {\n              resolve(message.conversation_initiation_metadata_event);\n            } else {\n              console.warn(\n                \"First received message is not conversation metadata.\"\n              );\n            }\n          },\n          { once: true }\n        );\n      });\n\n      const {\n        conversation_id,\n        agent_output_audio_format,\n        user_input_audio_format,\n      } = conversationConfig;\n\n      const inputFormat = parseFormat(user_input_audio_format ?? \"pcm_16000\");\n      const outputFormat = parseFormat(agent_output_audio_format);\n\n      return new WebSocketConnection(\n        socket,\n        conversation_id,\n        inputFormat,\n        outputFormat\n      );\n    } catch (error) {\n      socket?.close();\n      throw error;\n    }\n  }\n\n  public close() {\n    this.socket.close(1000, \"User ended conversation\");\n  }\n\n  public sendMessage(message: OutgoingSocketEvent) {\n    this.socket.send(JSON.stringify(message));\n  }\n\n  public async setMicMuted(isMuted: boolean): Promise<void> {\n    console.warn(\n      `WebSocket connection setMicMuted called with ${isMuted}, but this is handled by VoiceConversation`\n    );\n  }\n}\n","export function arrayBufferToBase64(b: ArrayBufferLike) {\n  const buffer = new Uint8Array(b);\n  // @ts-ignore\n  const base64Data = window.btoa(String.fromCharCode(...buffer));\n  return base64Data;\n}\n\nexport function base64ToArrayBuffer(base64: string): ArrayBuffer {\n  const binaryString = window.atob(base64);\n  const len = binaryString.length;\n  const bytes = new Uint8Array(len);\n  for (let i = 0; i < len; i++) {\n    bytes[i] = binaryString.charCodeAt(i);\n  }\n  return bytes.buffer;\n}\n","const URLCache = new Map<string, string>();\n\nexport function createWorkletModuleLoader(name: string, sourceCode: string) {\n  return async (worklet: AudioWorklet, path?: string) => {\n    const cachedUrl = URLCache.get(name);\n    if (cachedUrl) {\n      return worklet.addModule(cachedUrl);\n    }\n\n    // If a path is provided, use it directly (CSP-friendly approach)\n    if (path) {\n      try {\n        await worklet.addModule(path);\n        URLCache.set(name, path);\n        return;\n      } catch (error) {\n        throw new Error(\n          `Failed to load the ${name} worklet module from path: ${path}. Error: ${error}`\n        );\n      }\n    }\n\n    const blob = new Blob([sourceCode], { type: \"application/javascript\" });\n    const blobURL = URL.createObjectURL(blob);\n    try {\n      await worklet.addModule(blobURL);\n      URLCache.set(name, blobURL);\n      return;\n    } catch {\n      URL.revokeObjectURL(blobURL);\n    }\n\n    try {\n      // Attempting to start a conversation in Safari inside an iframe will\n      // throw a CORS error because the blob:// protocol is considered\n      // cross-origin. In such cases, fall back to using a base64 data URL:\n      const base64 = btoa(sourceCode);\n      const moduleURL = `data:application/javascript;base64,${base64}`;\n      await worklet.addModule(moduleURL);\n      URLCache.set(name, moduleURL);\n    } catch (error) {\n      throw new Error(\n        `Failed to load the ${name} worklet module. Make sure the browser supports AudioWorklets. If you are using a strict CSP, you may need to self-host the worklet files.`\n      );\n    }\n  };\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadRawAudioProcessor = createWorkletModuleLoader(\n  \"rawAudioProcessor\",\n  // language=JavaScript\n  `/*\n * ulaw encoding logic taken from the wavefile library\n * https://github.com/rochars/wavefile/blob/master/lib/codecs/mulaw.js\n * USED BY @elevenlabs/client\n */\n\nconst BIAS = 0x84;\nconst CLIP = 32635;\nconst encodeTable = [\n  0,0,1,1,2,2,2,2,3,3,3,3,3,3,3,3,\n  4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,\n  5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,\n  5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7\n];\n\nfunction encodeSample(sample) {\n  let sign;\n  let exponent;\n  let mantissa;\n  let muLawSample;\n  sign = (sample >> 8) & 0x80;\n  if (sign !== 0) sample = -sample;\n  sample = sample + BIAS;\n  if (sample > CLIP) sample = CLIP;\n  exponent = encodeTable[(sample>>7) & 0xFF];\n  mantissa = (sample >> (exponent+3)) & 0x0F;\n  muLawSample = ~(sign | (exponent << 4) | mantissa);\n  \n  return muLawSample;\n}\n\nclass RawAudioProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n              \n    this.port.onmessage = ({ data }) => {\n      switch (data.type) {\n        case \"setFormat\":\n          this.isMuted = false;\n          this.buffer = []; // Initialize an empty buffer\n          this.bufferSize = data.sampleRate / 4;\n          this.format = data.format;\n\n          if (globalThis.LibSampleRate && sampleRate !== data.sampleRate) {\n            globalThis.LibSampleRate.create(1, sampleRate, data.sampleRate).then(resampler => {\n              this.resampler = resampler;\n            });\n          }\n          break;\n        case \"setMuted\":\n          this.isMuted = data.isMuted;\n          break;\n      }\n    };\n  }\n  process(inputs) {\n    if (!this.buffer) {\n      return true;\n    }\n    \n    const input = inputs[0]; // Get the first input node\n    if (input.length > 0) {\n      let channelData = input[0]; // Get the first channel's data\n\n      // Resample the audio if necessary\n      if (this.resampler) {\n        channelData = this.resampler.full(channelData);\n      }\n\n      // Add channel data to the buffer\n      this.buffer.push(...channelData);\n      // Get max volume \n      let sum = 0.0;\n      for (let i = 0; i < channelData.length; i++) {\n        sum += channelData[i] * channelData[i];\n      }\n      const maxVolume = Math.sqrt(sum / channelData.length);\n      // Check if buffer size has reached or exceeded the threshold\n      if (this.buffer.length >= this.bufferSize) {\n        const float32Array = this.isMuted \n          ? new Float32Array(this.buffer.length)\n          : new Float32Array(this.buffer);\n\n        let encodedArray = this.format === \"ulaw\"\n          ? new Uint8Array(float32Array.length)\n          : new Int16Array(float32Array.length);\n\n        // Iterate through the Float32Array and convert each sample to PCM16\n        for (let i = 0; i < float32Array.length; i++) {\n          // Clamp the value to the range [-1, 1]\n          let sample = Math.max(-1, Math.min(1, float32Array[i]));\n\n          // Scale the sample to the range [-32768, 32767]\n          let value = sample < 0 ? sample * 32768 : sample * 32767;\n          if (this.format === \"ulaw\") {\n            value = encodeSample(Math.round(value));\n          }\n\n          encodedArray[i] = value;\n        }\n\n        // Send the buffered data to the main script\n        this.port.postMessage([encodedArray, maxVolume]);\n\n        // Clear the buffer after sending\n        this.buffer = [];\n      }\n    }\n    return true; // Continue processing\n  }\n}\nregisterProcessor(\"rawAudioProcessor\", RawAudioProcessor);\n`\n);\n","import {\n  BaseConnection,\n  type SessionConfig,\n  type FormatConfig,\n  parseFormat,\n} from \"./BaseConnection\";\nimport { PACKAGE_VERSION } from \"../version\";\nimport { isValidSocketEvent, type OutgoingSocketEvent } from \"./events\";\nimport {\n  Room,\n  RoomEvent,\n  Track,\n  ConnectionState,\n  createLocalAudioTrack,\n} from \"livekit-client\";\nimport type {\n  RemoteAudioTrack,\n  Participant,\n  TrackPublication,\n  RemoteParticipant,\n} from \"livekit-client\";\nimport {\n  constructOverrides,\n  CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n} from \"./overrides\";\nimport { arrayBufferToBase64 } from \"./audio\";\nimport { loadRawAudioProcessor } from \"./rawAudioProcessor.generated\";\n\nconst DEFAULT_LIVEKIT_WS_URL = \"wss://livekit.rtc.elevenlabs.io\";\nconst HTTPS_API_ORIGIN = \"https://api.elevenlabs.io\";\n\n// Convert WSS origin to HTTPS for API calls\nfunction convertWssToHttps(origin: string): string {\n  return origin.replace(/^wss:\\/\\//, \"https://\");\n}\n\nexport type ConnectionConfig = SessionConfig & {\n  onDebug?: (info: unknown) => void;\n};\n\nexport class WebRTCConnection extends BaseConnection {\n  public conversationId: string;\n  public readonly inputFormat: FormatConfig;\n  public readonly outputFormat: FormatConfig;\n\n  private room: Room;\n  private isConnected = false;\n  private audioEventId = 1;\n  private audioCaptureContext: AudioContext | null = null;\n  private audioElements: HTMLAudioElement[] = [];\n  private outputDeviceId: string | null = null;\n\n  private outputAnalyser: AnalyserNode | null = null;\n  private outputFrequencyData: Uint8Array<ArrayBuffer> | null = null;\n\n  private constructor(\n    room: Room,\n    conversationId: string,\n    inputFormat: FormatConfig,\n    outputFormat: FormatConfig,\n    config: { onDebug?: (info: unknown) => void } = {}\n  ) {\n    super(config);\n    this.room = room;\n    this.conversationId = conversationId;\n    this.inputFormat = inputFormat;\n    this.outputFormat = outputFormat;\n\n    this.setupRoomEventListeners();\n  }\n\n  public static async create(\n    config: ConnectionConfig\n  ): Promise<WebRTCConnection> {\n    let conversationToken: string;\n\n    // Handle different authentication scenarios\n    if (\"conversationToken\" in config && config.conversationToken) {\n      // Direct token provided\n      conversationToken = config.conversationToken;\n    } else if (\"agentId\" in config && config.agentId) {\n      // Agent ID provided - fetch token from API\n      try {\n        const version = config.overrides?.client?.version || PACKAGE_VERSION;\n        const source = config.overrides?.client?.source || \"js_sdk\";\n        const configOrigin = config.origin ?? HTTPS_API_ORIGIN;\n        const origin = convertWssToHttps(configOrigin); //origin is wss, not https\n        const url = `${origin}/v1/convai/conversation/token?agent_id=${config.agentId}&source=${source}&version=${version}`;\n        const response = await fetch(url);\n\n        if (!response.ok) {\n          throw new Error(\n            `ElevenLabs API returned ${response.status} ${response.statusText}`\n          );\n        }\n\n        const data = await response.json();\n        conversationToken = data.token;\n\n        if (!conversationToken) {\n          throw new Error(\"No conversation token received from API\");\n        }\n      } catch (error) {\n        let msg = error instanceof Error ? error.message : String(error);\n        if (error instanceof Error && error.message.includes(\"401\")) {\n          msg =\n            \"Your agent has authentication enabled, but no signed URL or conversation token was provided.\";\n        }\n\n        throw new Error(\n          `Failed to fetch conversation token for agent ${config.agentId}: ${msg}`\n        );\n      }\n    } else {\n      throw new Error(\n        \"Either conversationToken or agentId is required for WebRTC connection\"\n      );\n    }\n\n    const room = new Room();\n\n    try {\n      // Create connection instance first to set up event listeners\n      const conversationId = `room_${Date.now()}`;\n      const inputFormat = parseFormat(\"pcm_48000\");\n      const outputFormat = parseFormat(\"pcm_48000\");\n      const connection = new WebRTCConnection(\n        room,\n        conversationId,\n        inputFormat,\n        outputFormat,\n        config\n      );\n\n      // Use configurable LiveKit URL or default if not provided\n      const livekitUrl = config.livekitUrl || DEFAULT_LIVEKIT_WS_URL;\n\n      // Connect to the LiveKit room and wait for the Connected event\n      await room.connect(livekitUrl, conversationToken);\n\n      // Wait for the Connected event to ensure isConnected is true\n      await new Promise<void>(resolve => {\n        if (connection.isConnected) {\n          resolve();\n        } else {\n          const onConnected = () => {\n            room.off(RoomEvent.Connected, onConnected);\n            resolve();\n          };\n          room.on(RoomEvent.Connected, onConnected);\n        }\n      });\n\n      if (room.name) {\n        connection.conversationId =\n          room.name.match(/(conv_[a-zA-Z0-9]+)/)?.[0] || room.name;\n      }\n\n      // Enable microphone only if not text-only mode\n      if (!config.textOnly) {\n        await room.localParticipant.setMicrophoneEnabled(true);\n      }\n\n      const overridesEvent = constructOverrides(config);\n\n      connection.debug({\n        type: CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n        message: overridesEvent,\n      });\n\n      await connection.sendMessage(overridesEvent);\n\n      return connection;\n    } catch (error) {\n      await room.disconnect();\n      throw error;\n    }\n  }\n\n  private setupRoomEventListeners() {\n    this.room.on(RoomEvent.Connected, async () => {\n      this.isConnected = true;\n      console.info(\"WebRTC room connected\");\n    });\n\n    this.room.on(RoomEvent.Disconnected, reason => {\n      this.isConnected = false;\n      this.disconnect({\n        reason: \"agent\",\n        context: new CloseEvent(\"close\", { reason: reason?.toString() }),\n      });\n    });\n\n    this.room.on(RoomEvent.ConnectionStateChanged, state => {\n      if (state === ConnectionState.Disconnected) {\n        this.isConnected = false;\n        this.disconnect({\n          reason: \"error\",\n          message: `LiveKit connection state changed to ${state}`,\n          context: new Event(\"connection_state_changed\"),\n        });\n      }\n    });\n\n    // Handle incoming data messages\n    this.room.on(\n      RoomEvent.DataReceived,\n      (payload: Uint8Array, _participant) => {\n        try {\n          const message = JSON.parse(new TextDecoder().decode(payload));\n\n          // Filter out audio messages for WebRTC - they're handled via audio tracks\n          if (message.type === \"audio\") {\n            return;\n          }\n\n          if (isValidSocketEvent(message)) {\n            this.handleMessage(message);\n          } else {\n            console.warn(\"Invalid socket event received:\", message);\n          }\n        } catch (error) {\n          console.warn(\"Failed to parse incoming data message:\", error);\n          console.warn(\"Raw payload:\", new TextDecoder().decode(payload));\n        }\n      }\n    );\n\n    this.room.on(\n      RoomEvent.TrackSubscribed,\n      async (\n        track: Track,\n        _publication: TrackPublication,\n        participant: Participant\n      ) => {\n        if (\n          track.kind === Track.Kind.Audio &&\n          participant.identity.includes(\"agent\")\n        ) {\n          // Play the audio track\n          const remoteAudioTrack = track as RemoteAudioTrack;\n          const audioElement = remoteAudioTrack.attach();\n          audioElement.autoplay = true;\n          audioElement.controls = false;\n\n          // Set output device if one was previously selected\n          if (this.outputDeviceId && audioElement.setSinkId) {\n            try {\n              await audioElement.setSinkId(this.outputDeviceId);\n            } catch (error) {\n              console.warn(\n                \"Failed to set output device for new audio element:\",\n                error\n              );\n            }\n          }\n\n          // Add to DOM (hidden) to ensure it plays\n          audioElement.style.display = \"none\";\n          document.body.appendChild(audioElement);\n\n          // Store reference for volume control\n          this.audioElements.push(audioElement);\n\n          // Apply current volume if it exists (for when volume was set before audio track arrived)\n          if (this.audioElements.length === 1) {\n            // First audio element - trigger a callback to sync with current volume\n            this.onDebug?.({ type: \"audio_element_ready\" });\n          }\n\n          // Set up audio capture for onAudio callback\n          await this.setupAudioCapture(remoteAudioTrack);\n        }\n      }\n    );\n\n    this.room.on(\n      RoomEvent.ActiveSpeakersChanged,\n      async (speakers: Participant[]) => {\n        if (speakers.length > 0) {\n          this.updateMode(\n            speakers[0].identity.startsWith(\"agent\") ? \"speaking\" : \"listening\"\n          );\n        } else {\n          this.updateMode(\"listening\");\n        }\n      }\n    );\n\n    this.room.on(\n      RoomEvent.ParticipantDisconnected,\n      (participant: RemoteParticipant) => {\n        if (participant.identity?.startsWith(\"agent\")) {\n          this.disconnect({\n            reason: \"agent\",\n            context: new CloseEvent(\"close\", { reason: \"agent disconnected\" }),\n          });\n        }\n      }\n    );\n  }\n\n  public close() {\n    if (this.isConnected) {\n      try {\n        // Explicitly stop all local tracks before disconnecting to ensure microphone is released\n        this.room.localParticipant.audioTrackPublications.forEach(\n          publication => {\n            if (publication.track) {\n              publication.track.stop();\n            }\n          }\n        );\n      } catch (error) {\n        console.warn(\"Error stopping local tracks:\", error);\n      }\n\n      // Clean up audio capture context (non-blocking)\n      if (this.audioCaptureContext) {\n        this.audioCaptureContext.close().catch(error => {\n          console.warn(\"Error closing audio capture context:\", error);\n        });\n        this.audioCaptureContext = null;\n      }\n\n      // Clean up audio elements\n      this.audioElements.forEach(element => {\n        if (element.parentNode) {\n          element.parentNode.removeChild(element);\n        }\n      });\n      this.audioElements = [];\n\n      this.room.disconnect();\n    }\n  }\n\n  public async sendMessage(message: OutgoingSocketEvent) {\n    if (!this.isConnected || !this.room.localParticipant) {\n      console.warn(\n        \"Cannot send message: room not connected or no local participant\"\n      );\n      return;\n    }\n\n    // In WebRTC mode, audio is sent via published tracks, not data messages\n    if (\"user_audio_chunk\" in message) {\n      // Ignore audio data messages - audio flows through WebRTC tracks\n      return;\n    }\n\n    try {\n      const encoder = new TextEncoder();\n      const data = encoder.encode(JSON.stringify(message));\n\n      await this.room.localParticipant.publishData(data, { reliable: true });\n    } catch (error) {\n      this.debug({\n        type: \"send_message_error\",\n        message: {\n          message,\n          error,\n        },\n      });\n      console.error(\"Failed to send message via WebRTC:\", error);\n    }\n  }\n\n  // Get the room instance for advanced usage\n  public getRoom(): Room {\n    return this.room;\n  }\n\n  public async setMicMuted(isMuted: boolean): Promise<void> {\n    if (!this.isConnected || !this.room.localParticipant) {\n      console.warn(\n        \"Cannot set microphone muted: room not connected or no local participant\"\n      );\n      return;\n    }\n\n    // Get the microphone track publication\n    const micTrackPublication = this.room.localParticipant.getTrackPublication(\n      Track.Source.Microphone\n    );\n\n    if (micTrackPublication?.track) {\n      try {\n        // Use LiveKit's built-in track muting\n        if (isMuted) {\n          await micTrackPublication.track.mute();\n        } else {\n          await micTrackPublication.track.unmute();\n        }\n      } catch (_error) {\n        // If track muting fails, fall back to participant-level control\n        await this.room.localParticipant.setMicrophoneEnabled(!isMuted);\n      }\n    } else {\n      // No track found, use participant-level control directly\n      await this.room.localParticipant.setMicrophoneEnabled(!isMuted);\n    }\n  }\n\n  private async setupAudioCapture(track: RemoteAudioTrack) {\n    try {\n      // Create audio context for processing\n      const audioContext = new AudioContext();\n      this.audioCaptureContext = audioContext;\n\n      // Create analyser for frequency data\n      this.outputAnalyser = audioContext.createAnalyser();\n      this.outputAnalyser.fftSize = 2048;\n      this.outputAnalyser.smoothingTimeConstant = 0.8;\n\n      // Create MediaStream from the track\n      const mediaStream = new MediaStream([track.mediaStreamTrack]);\n\n      // Create audio source from the stream\n      const source = audioContext.createMediaStreamSource(mediaStream);\n\n      // Connect source to analyser\n      source.connect(this.outputAnalyser);\n\n      await loadRawAudioProcessor(audioContext.audioWorklet);\n      const worklet = new AudioWorkletNode(audioContext, \"rawAudioProcessor\");\n\n      // Connect analyser to worklet for processing\n      this.outputAnalyser.connect(worklet);\n\n      // Configure the processor for the output format\n      worklet.port.postMessage({\n        type: \"setFormat\",\n        format: this.outputFormat.format,\n        sampleRate: this.outputFormat.sampleRate,\n      });\n\n      // Handle processed audio data\n      worklet.port.onmessage = (event: MessageEvent) => {\n        const [audioData, maxVolume] = event.data;\n\n        // Only send audio if there's significant volume (not just silence)\n        const volumeThreshold = 0.01;\n\n        if (maxVolume > volumeThreshold) {\n          // Convert to base64\n          const base64Audio = arrayBufferToBase64(audioData.buffer);\n\n          // Use sequential event ID for proper feedback tracking\n          const eventId = this.audioEventId++;\n\n          // Trigger the onAudio callback by simulating an audio event\n          this.handleMessage({\n            type: \"audio\",\n            audio_event: {\n              audio_base_64: base64Audio,\n              event_id: eventId,\n            },\n          });\n        }\n      };\n\n      // Connect the audio processing chain\n      source.connect(worklet);\n    } catch (error) {\n      console.warn(\"Failed to set up audio capture:\", error);\n    }\n  }\n\n  public setAudioVolume(volume: number) {\n    this.audioElements.forEach(element => {\n      element.volume = volume;\n    });\n  }\n\n  public async setAudioOutputDevice(deviceId: string): Promise<void> {\n    if (!(\"setSinkId\" in HTMLAudioElement.prototype)) {\n      throw new Error(\"setSinkId is not supported in this browser\");\n    }\n\n    // Set output device for all existing audio elements\n    const promises = this.audioElements.map(async element => {\n      try {\n        await element.setSinkId(deviceId);\n      } catch (error) {\n        console.error(\"Failed to set sink ID for audio element:\", error);\n        throw error;\n      }\n    });\n\n    await Promise.all(promises);\n\n    // Store the device ID for future audio elements\n    this.outputDeviceId = deviceId;\n  }\n\n  public async setAudioInputDevice(deviceId: string): Promise<void> {\n    if (!this.isConnected || !this.room.localParticipant) {\n      throw new Error(\n        \"Cannot change input device: room not connected or no local participant\"\n      );\n    }\n\n    try {\n      // Get the current microphone track publication\n      const currentMicTrackPublication =\n        this.room.localParticipant.getTrackPublication(Track.Source.Microphone);\n\n      // Stop the current microphone track if it exists\n      if (currentMicTrackPublication?.track) {\n        await currentMicTrackPublication.track.stop();\n        await this.room.localParticipant.unpublishTrack(\n          currentMicTrackPublication.track\n        );\n      }\n\n      // Create constraints for the new input device\n      const audioConstraints: MediaTrackConstraints = {\n        deviceId: { exact: deviceId },\n        echoCancellation: true,\n        noiseSuppression: true,\n        autoGainControl: true,\n        channelCount: { ideal: 1 },\n      };\n\n      // Create new audio track with the specified device\n      const audioTrack = await createLocalAudioTrack(audioConstraints);\n\n      // Publish the new microphone track\n      await this.room.localParticipant.publishTrack(audioTrack, {\n        name: \"microphone\",\n        source: Track.Source.Microphone,\n      });\n    } catch (error) {\n      console.error(\"Failed to change input device:\", error);\n\n      // Try to re-enable default microphone on failure\n      try {\n        await this.room.localParticipant.setMicrophoneEnabled(true);\n      } catch (recoveryError) {\n        console.error(\n          \"Failed to recover microphone after device switch error:\",\n          recoveryError\n        );\n      }\n\n      throw error;\n    }\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array<ArrayBuffer> | null {\n    if (!this.outputAnalyser) return null;\n\n    this.outputFrequencyData ??= new Uint8Array(\n      this.outputAnalyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.outputAnalyser.getByteFrequencyData(this.outputFrequencyData);\n    return this.outputFrequencyData;\n  }\n}\n","import type {\n  BaseConnection,\n  SessionConfig,\n  ConnectionType,\n} from \"./BaseConnection\";\nimport { WebSocketConnection } from \"./WebSocketConnection\";\nimport { WebRTCConnection } from \"./WebRTCConnection\";\n\nfunction determineConnectionType(config: SessionConfig): ConnectionType {\n  // If connectionType is explicitly specified, use it\n  if (config.connectionType) {\n    return config.connectionType;\n  }\n\n  // If conversationToken is provided, use WebRTC\n  if (\"conversationToken\" in config && config.conversationToken) {\n    return \"webrtc\";\n  }\n\n  // Default to WebSocket for backward compatibility\n  return \"websocket\";\n}\n\nexport async function createConnection(\n  config: SessionConfig\n): Promise<BaseConnection> {\n  const connectionType = determineConnectionType(config);\n\n  switch (connectionType) {\n    case \"websocket\":\n      return WebSocketConnection.create(config);\n    case \"webrtc\":\n      return WebRTCConnection.create(config);\n    default:\n      throw new Error(`Unknown connection type: ${connectionType}`);\n  }\n}\n","export function isIosDevice() {\n  return (\n    [\n      \"iPad Simulator\",\n      \"iPhone Simulator\",\n      \"iPod Simulator\",\n      \"iPad\",\n      \"iPhone\",\n      \"iPod\",\n    ].includes(navigator.platform) ||\n    // iPad on iOS 13 detection\n    (navigator.userAgent.includes(\"Mac\") && \"ontouchend\" in document)\n  );\n}\n\nexport function isAndroidDevice() {\n  return /android/i.test(navigator.userAgent);\n}\n","import { isAndroidDevice, isIosDevice } from \"./compatibility\";\nimport type { DelayConfig } from \"./connection\";\n\nexport async function applyDelay(\n  delayConfig: DelayConfig = {\n    default: 0,\n    // Give the Android AudioManager enough time to switch to the correct audio mode\n    android: 3_000,\n  }\n) {\n  let delay = delayConfig.default;\n  if (isAndroidDevice()) {\n    delay = delayConfig.android ?? delay;\n  } else if (isIosDevice()) {\n    delay = delayConfig.ios ?? delay;\n  }\n\n  if (delay > 0) {\n    await new Promise(resolve => setTimeout(resolve, delay));\n  }\n}\n","import { createConnection } from \"./utils/ConnectionFactory\";\nimport type { BaseConnection } from \"./utils/BaseConnection\";\nimport { applyDelay } from \"./utils/applyDelay\";\nimport { BaseConversation, type PartialOptions } from \"./BaseConversation\";\n\nexport class TextConversation extends BaseConversation {\n  public static async startSession(\n    options: PartialOptions\n  ): Promise<TextConversation> {\n    const fullOptions = BaseConversation.getFullOptions(options);\n\n    if (fullOptions.onStatusChange) {\n      fullOptions.onStatusChange({ status: \"connecting\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n    if (fullOptions.onModeChange) {\n      fullOptions.onModeChange({ mode: \"listening\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n\n    let connection: BaseConnection | null = null;\n    try {\n      await applyDelay(fullOptions.connectionDelay);\n      connection = await createConnection(options);\n      return new TextConversation(fullOptions, connection);\n    } catch (error) {\n      if (fullOptions.onStatusChange) {\n        fullOptions.onStatusChange({ status: \"disconnected\" });\n      }\n      connection?.close();\n      throw error;\n    }\n  }\n}\n","import { loadRawAudioProcessor } from \"./rawAudioProcessor.generated\";\nimport type { FormatConfig } from \"./connection\";\nimport { isIosDevice } from \"./compatibility\";\nimport type { AudioWorkletConfig } from \"../BaseConversation\";\n\nexport type InputConfig = {\n  preferHeadphonesForIosDevices?: boolean;\n  inputDeviceId?: string;\n};\n\nconst LIBSAMPLERATE_JS =\n  \"https://cdn.jsdelivr.net/npm/@alexanderolsen/libsamplerate-js@2.1.2/dist/libsamplerate.worklet.js\";\n\nconst defaultConstraints = {\n  echoCancellation: true,\n  noiseSuppression: true,\n  // Automatic gain control helps maintain a steady volume level with microphones: https://developer.mozilla.org/en-US/docs/Web/API/MediaTrackSettings/autoGainControl\n  autoGainControl: true,\n  // Mono audio for better echo cancellation\n  channelCount: { ideal: 1 },\n};\n\nexport class Input {\n  public static async create({\n    sampleRate,\n    format,\n    preferHeadphonesForIosDevices,\n    inputDeviceId,\n    workletPaths,\n    libsampleratePath,\n  }: FormatConfig & InputConfig & AudioWorkletConfig): Promise<Input> {\n    let context: AudioContext | null = null;\n    let inputStream: MediaStream | null = null;\n\n    try {\n      const options: MediaTrackConstraints = {\n        sampleRate: { ideal: sampleRate },\n        ...defaultConstraints,\n      };\n\n      if (isIosDevice() && preferHeadphonesForIosDevices) {\n        const availableDevices =\n          await window.navigator.mediaDevices.enumerateDevices();\n        const idealDevice = availableDevices.find(\n          d =>\n            // cautious to include \"bluetooth\" in the search\n            // as might trigger bluetooth speakers\n            d.kind === \"audioinput\" &&\n            [\"airpod\", \"headphone\", \"earphone\"].find(keyword =>\n              d.label.toLowerCase().includes(keyword)\n            )\n        );\n        if (idealDevice) {\n          options.deviceId = { ideal: idealDevice.deviceId };\n        }\n      }\n\n      if (inputDeviceId) {\n        options.deviceId = Input.getDeviceIdConstraint(inputDeviceId);\n      }\n\n      const supportsSampleRateConstraint =\n        navigator.mediaDevices.getSupportedConstraints().sampleRate;\n\n      context = new window.AudioContext(\n        supportsSampleRateConstraint ? { sampleRate } : {}\n      );\n      const analyser = context.createAnalyser();\n      if (!supportsSampleRateConstraint) {\n        // Use custom libsamplerate path if provided, otherwise fallback to CDN\n        const libsamplerateUrl = libsampleratePath || LIBSAMPLERATE_JS;\n        await context.audioWorklet.addModule(libsamplerateUrl);\n      }\n      await loadRawAudioProcessor(\n        context.audioWorklet,\n        workletPaths?.[\"rawAudioProcessor\"]\n      );\n\n      const constraints = { voiceIsolation: true, ...options };\n      inputStream = await navigator.mediaDevices.getUserMedia({\n        audio: constraints,\n      });\n\n      const source = context.createMediaStreamSource(inputStream);\n      const worklet = new AudioWorkletNode(context, \"rawAudioProcessor\");\n      worklet.port.postMessage({ type: \"setFormat\", format, sampleRate });\n\n      source.connect(analyser);\n      analyser.connect(worklet);\n\n      await context.resume();\n\n      return new Input(context, analyser, worklet, inputStream, source);\n    } catch (error) {\n      inputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      context?.close();\n      throw error;\n    }\n  }\n\n  // Use { ideal } on iOS as a defensive measure - some iOS versions may not support { exact } for deviceId constraints\n  private static getDeviceIdConstraint(\n    inputDeviceId?: string\n  ): MediaTrackConstraints[\"deviceId\"] {\n    if (!inputDeviceId) {\n      return undefined;\n    }\n    return isIosDevice() ? { ideal: inputDeviceId } : { exact: inputDeviceId };\n  }\n\n  private constructor(\n    public readonly context: AudioContext,\n    public readonly analyser: AnalyserNode,\n    public readonly worklet: AudioWorkletNode,\n    public inputStream: MediaStream,\n    private mediaStreamSource: MediaStreamAudioSourceNode\n  ) {}\n\n  public async close() {\n    this.inputStream.getTracks().forEach(track => {\n      track.stop();\n    });\n    this.mediaStreamSource.disconnect();\n    await this.context.close();\n  }\n\n  public setMuted(isMuted: boolean) {\n    this.worklet.port.postMessage({ type: \"setMuted\", isMuted });\n  }\n\n  public async setInputDevice(inputDeviceId?: string): Promise<void> {\n    try {\n      // Create new constraints with the specified device or use default\n      const options: MediaTrackConstraints = {\n        ...defaultConstraints,\n      };\n\n      if (inputDeviceId) {\n        options.deviceId = Input.getDeviceIdConstraint(inputDeviceId);\n      }\n      // If inputDeviceId is undefined, don't set deviceId constraint - browser uses default\n\n      const constraints = { voiceIsolation: true, ...options };\n\n      // Get new media stream with the specified device\n      const newInputStream = await navigator.mediaDevices.getUserMedia({\n        audio: constraints,\n      });\n\n      // Stop old tracks and disconnect old source\n      this.inputStream.getTracks().forEach(track => {\n        track.stop();\n      });\n      this.mediaStreamSource.disconnect();\n\n      // Replace the stream and create new source\n      this.inputStream = newInputStream;\n      this.mediaStreamSource =\n        this.context.createMediaStreamSource(newInputStream);\n\n      // Reconnect the audio graph\n      this.mediaStreamSource.connect(this.analyser);\n    } catch (error) {\n      console.error(\"Failed to switch input device:\", error);\n      throw error;\n    }\n  }\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadAudioConcatProcessor = createWorkletModuleLoader(\n  \"audioConcatProcessor\",\n  // language=JavaScript\n  `/*\n * ulaw decoding logic taken from the wavefile library\n * https://github.com/rochars/wavefile/blob/master/lib/codecs/mulaw.js\n * USED BY @elevenlabs/client\n */\n\nconst decodeTable = [0,132,396,924,1980,4092,8316,16764];\n\nfunction decodeSample(muLawSample) {\n  let sign;\n  let exponent;\n  let mantissa;\n  let sample;\n  muLawSample = ~muLawSample;\n  sign = (muLawSample & 0x80);\n  exponent = (muLawSample >> 4) & 0x07;\n  mantissa = muLawSample & 0x0F;\n  sample = decodeTable[exponent] + (mantissa << (exponent+3));\n  if (sign !== 0) sample = -sample;\n\n  return sample;\n}\n\nclass AudioConcatProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this.buffers = []; // Initialize an empty buffer\n    this.cursor = 0;\n    this.currentBuffer = null;\n    this.wasInterrupted = false;\n    this.finished = false;\n    \n    this.port.onmessage = ({ data }) => {\n      switch (data.type) {\n        case \"setFormat\":\n          this.format = data.format;\n          break;\n        case \"buffer\":\n          this.wasInterrupted = false;\n          this.buffers.push(\n            this.format === \"ulaw\"\n              ? new Uint8Array(data.buffer)\n              : new Int16Array(data.buffer)\n          );\n          break;\n        case \"interrupt\":\n          this.wasInterrupted = true;\n          break;\n        case \"clearInterrupted\":\n          if (this.wasInterrupted) {\n            this.wasInterrupted = false;\n            this.buffers = [];\n            this.currentBuffer = null;\n          }\n      }\n    };\n  }\n  process(_, outputs) {\n    let finished = false;\n    const output = outputs[0][0];\n    for (let i = 0; i < output.length; i++) {\n      if (!this.currentBuffer) {\n        if (this.buffers.length === 0) {\n          finished = true;\n          break;\n        }\n        this.currentBuffer = this.buffers.shift();\n        this.cursor = 0;\n      }\n\n      let value = this.currentBuffer[this.cursor];\n      if (this.format === \"ulaw\") {\n        value = decodeSample(value);\n      }\n      output[i] = value / 32768;\n      this.cursor++;\n\n      if (this.cursor >= this.currentBuffer.length) {\n        this.currentBuffer = null;\n      }\n    }\n\n    if (this.finished !== finished) {\n      this.finished = finished;\n      this.port.postMessage({ type: \"process\", finished });\n    }\n\n    return true; // Continue processing\n  }\n}\n\nregisterProcessor(\"audioConcatProcessor\", AudioConcatProcessor);\n`\n);\n","import { loadAudioConcatProcessor } from \"./audioConcatProcessor.generated\";\nimport type { FormatConfig } from \"./connection\";\nimport type { AudioWorkletConfig } from \"../BaseConversation\";\n\nexport type OutputConfig = {\n  outputDeviceId?: string;\n};\n\nexport class Output {\n  public static async create({\n    sampleRate,\n    format,\n    outputDeviceId,\n    workletPaths,\n  }: FormatConfig & OutputConfig & AudioWorkletConfig): Promise<Output> {\n    let context: AudioContext | null = null;\n    let audioElement: HTMLAudioElement | null = null;\n    try {\n      context = new AudioContext({ sampleRate });\n      const analyser = context.createAnalyser();\n      const gain = context.createGain();\n\n      // Always create an audio element for device switching capability\n      audioElement = new Audio();\n      audioElement.src = \"\";\n      audioElement.load();\n      audioElement.autoplay = true;\n      audioElement.style.display = \"none\";\n\n      document.body.appendChild(audioElement);\n\n      // Create media stream destination to route audio to the element\n      const destination = context.createMediaStreamDestination();\n      audioElement.srcObject = destination.stream;\n\n      gain.connect(analyser);\n      analyser.connect(destination);\n\n      await loadAudioConcatProcessor(\n        context.audioWorklet,\n        workletPaths?.[\"audioConcatProcessor\"]\n      );\n      const worklet = new AudioWorkletNode(context, \"audioConcatProcessor\");\n      worklet.port.postMessage({ type: \"setFormat\", format });\n      worklet.connect(gain);\n\n      await context.resume();\n\n      // Set initial output device if provided\n      if (outputDeviceId && audioElement.setSinkId) {\n        await audioElement.setSinkId(outputDeviceId);\n      }\n\n      const newOutput = new Output(\n        context,\n        analyser,\n        gain,\n        worklet,\n        audioElement\n      );\n\n      return newOutput;\n    } catch (error) {\n      // Clean up audio element from DOM\n      if (audioElement?.parentNode) {\n        audioElement.parentNode.removeChild(audioElement);\n      }\n      audioElement?.pause();\n      if (context && context.state !== \"closed\") {\n        await context.close();\n      }\n\n      throw error;\n    }\n  }\n\n  private constructor(\n    public readonly context: AudioContext,\n    public readonly analyser: AnalyserNode,\n    public readonly gain: GainNode,\n    public readonly worklet: AudioWorkletNode,\n    public readonly audioElement: HTMLAudioElement\n  ) {}\n\n  public async setOutputDevice(deviceId?: string): Promise<void> {\n    if (!(\"setSinkId\" in HTMLAudioElement.prototype)) {\n      throw new Error(\"setSinkId is not supported in this browser\");\n    }\n\n    // If deviceId is undefined, use empty string which resets to default device\n    await this.audioElement.setSinkId(deviceId || \"\");\n  }\n\n  public async close() {\n    // Remove audio element from DOM\n    if (this.audioElement.parentNode) {\n      this.audioElement.parentNode.removeChild(this.audioElement);\n    }\n    this.audioElement.pause();\n    await this.context.close();\n  }\n}\n","import { arrayBufferToBase64, base64ToArrayBuffer } from \"./utils/audio\";\nimport { Input, type InputConfig } from \"./utils/input\";\nimport { Output } from \"./utils/output\";\nimport { createConnection } from \"./utils/ConnectionFactory\";\nimport type { BaseConnection, FormatConfig } from \"./utils/BaseConnection\";\nimport { WebRTCConnection } from \"./utils/WebRTCConnection\";\nimport type { AgentAudioEvent, InterruptionEvent } from \"./utils/events\";\nimport { applyDelay } from \"./utils/applyDelay\";\nimport {\n  BaseConversation,\n  type Options,\n  type PartialOptions,\n} from \"./BaseConversation\";\nimport { WebSocketConnection } from \"./utils/WebSocketConnection\";\n\nexport class VoiceConversation extends BaseConversation {\n  private static async requestWakeLock(): Promise<WakeLockSentinel | null> {\n    if (\"wakeLock\" in navigator) {\n      // unavailable without HTTPS, including localhost in dev\n      try {\n        return await navigator.wakeLock.request(\"screen\");\n      } catch (_e) {\n        // Wake Lock is not required for the conversation to work\n      }\n    }\n    return null;\n  }\n\n  public static async startSession(\n    options: PartialOptions\n  ): Promise<VoiceConversation> {\n    const fullOptions = BaseConversation.getFullOptions(options);\n\n    if (fullOptions.onStatusChange) {\n      fullOptions.onStatusChange({ status: \"connecting\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n\n    let input: Input | null = null;\n    let connection: BaseConnection | null = null;\n    let output: Output | null = null;\n    let preliminaryInputStream: MediaStream | null = null;\n\n    const useWakeLock = options.useWakeLock ?? true;\n    let wakeLock: WakeLockSentinel | null = null;\n    if (useWakeLock) {\n      wakeLock = await VoiceConversation.requestWakeLock();\n    }\n\n    try {\n      // some browsers won't allow calling getSupportedConstraints or enumerateDevices\n      // before getting approval for microphone access\n      preliminaryInputStream = await navigator.mediaDevices.getUserMedia({\n        audio: true,\n      });\n\n      await applyDelay(fullOptions.connectionDelay);\n      connection = await createConnection(options);\n      [input, output] = await Promise.all([\n        Input.create({\n          ...connection.inputFormat,\n          preferHeadphonesForIosDevices: options.preferHeadphonesForIosDevices,\n          inputDeviceId: options.inputDeviceId,\n          workletPaths: options.workletPaths,\n          libsampleratePath: options.libsampleratePath,\n        }),\n        Output.create({\n          ...connection.outputFormat,\n          outputDeviceId: options.outputDeviceId,\n          workletPaths: options.workletPaths,\n        }),\n      ]);\n\n      preliminaryInputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      preliminaryInputStream = null;\n\n      return new VoiceConversation(\n        fullOptions,\n        connection,\n        input,\n        output,\n        wakeLock\n      );\n    } catch (error) {\n      if (fullOptions.onStatusChange) {\n        fullOptions.onStatusChange({ status: \"disconnected\" });\n      }\n      preliminaryInputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      connection?.close();\n      await input?.close();\n      await output?.close();\n      try {\n        await wakeLock?.release();\n        wakeLock = null;\n      } catch (_e) {}\n      throw error;\n    }\n  }\n\n  private inputFrequencyData?: Uint8Array<ArrayBuffer>;\n  private outputFrequencyData?: Uint8Array<ArrayBuffer>;\n  private visibilityChangeHandler: (() => void) | null = null;\n\n  protected constructor(\n    options: Options,\n    connection: BaseConnection,\n    public input: Input,\n    public output: Output,\n    public wakeLock: WakeLockSentinel | null\n  ) {\n    super(options, connection);\n    this.input.worklet.port.onmessage = this.onInputWorkletMessage;\n    this.output.worklet.port.onmessage = this.onOutputWorkletMessage;\n\n    if (wakeLock) {\n      // Wake locks are automatically released when a page is hidden like when switching tabs\n      // so attempt to re-acquire lock when page becomes visible again\n      this.visibilityChangeHandler = () => {\n        if (document.visibilityState === \"visible\" && this.wakeLock?.released) {\n          VoiceConversation.requestWakeLock().then(lock => {\n            this.wakeLock = lock;\n          });\n        }\n      };\n      document.addEventListener(\n        \"visibilitychange\",\n        this.visibilityChangeHandler\n      );\n    }\n  }\n\n  protected override async handleEndSession() {\n    await super.handleEndSession();\n\n    if (this.visibilityChangeHandler) {\n      document.removeEventListener(\n        \"visibilitychange\",\n        this.visibilityChangeHandler\n      );\n    }\n\n    try {\n      await this.wakeLock?.release();\n      this.wakeLock = null;\n    } catch (_e) {}\n\n    await this.input.close();\n    await this.output.close();\n  }\n\n  protected override handleInterruption(event: InterruptionEvent) {\n    super.handleInterruption(event);\n    this.fadeOutAudio();\n  }\n\n  protected override handleAudio(event: AgentAudioEvent) {\n    super.handleAudio(event);\n\n    if (event.audio_event.alignment && this.options.onAudioAlignment) {\n      this.options.onAudioAlignment(event.audio_event.alignment);\n    }\n\n    if (this.lastInterruptTimestamp <= event.audio_event.event_id) {\n      if (event.audio_event.audio_base_64) {\n        this.options.onAudio?.(event.audio_event.audio_base_64);\n\n        // Only play audio through the output worklet for WebSocket connections\n        // WebRTC connections handle audio playback directly through LiveKit tracks\n        if (!(this.connection instanceof WebRTCConnection)) {\n          this.addAudioBase64Chunk(event.audio_event.audio_base_64);\n        }\n      }\n\n      this.currentEventId = event.audio_event.event_id;\n      this.updateCanSendFeedback();\n      this.updateMode(\"speaking\");\n    }\n  }\n\n  private onInputWorkletMessage = (event: MessageEvent): void => {\n    const rawAudioPcmData = event.data[0];\n\n    // TODO: When supported, maxVolume can be used to avoid sending silent audio\n    // const maxVolume = event.data[1];\n\n    if (this.status === \"connected\") {\n      this.connection.sendMessage({\n        user_audio_chunk: arrayBufferToBase64(rawAudioPcmData.buffer),\n      });\n    }\n  };\n\n  private onOutputWorkletMessage = ({ data }: MessageEvent): void => {\n    if (data.type === \"process\") {\n      this.updateMode(data.finished ? \"listening\" : \"speaking\");\n    }\n  };\n\n  private addAudioBase64Chunk = (chunk: string) => {\n    this.output.gain.gain.cancelScheduledValues(\n      this.output.context.currentTime\n    );\n    this.output.gain.gain.value = this.volume;\n    this.output.worklet.port.postMessage({ type: \"clearInterrupted\" });\n    this.output.worklet.port.postMessage({\n      type: \"buffer\",\n      buffer: base64ToArrayBuffer(chunk),\n    });\n  };\n\n  private fadeOutAudio = () => {\n    // mute agent\n    this.updateMode(\"listening\");\n    this.output.worklet.port.postMessage({ type: \"interrupt\" });\n    this.output.gain.gain.exponentialRampToValueAtTime(\n      0.0001,\n      this.output.context.currentTime + 2\n    );\n\n    // reset volume back\n    setTimeout(() => {\n      this.output.gain.gain.value = this.volume;\n      this.output.worklet.port.postMessage({ type: \"clearInterrupted\" });\n    }, 2000); // Adjust the duration as needed\n  };\n\n  private calculateVolume = (frequencyData: Uint8Array) => {\n    if (frequencyData.length === 0) {\n      return 0;\n    }\n\n    // TODO: Currently this averages all frequencies, but we should probably\n    // bias towards the frequencies that are more typical for human voice\n    let volume = 0;\n    for (let i = 0; i < frequencyData.length; i++) {\n      volume += frequencyData[i] / 255;\n    }\n    volume /= frequencyData.length;\n\n    return volume < 0 ? 0 : volume > 1 ? 1 : volume;\n  };\n\n  public setMicMuted(isMuted: boolean) {\n    // Use LiveKit track muting for WebRTC connections\n    if (this.connection instanceof WebRTCConnection) {\n      this.connection.setMicMuted(isMuted);\n    } else {\n      // Use input muting for WebSocket connections\n      this.input.setMuted(isMuted);\n    }\n  }\n\n  public getInputByteFrequencyData(): Uint8Array<ArrayBuffer> {\n    this.inputFrequencyData ??= new Uint8Array(\n      this.input.analyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.input.analyser.getByteFrequencyData(this.inputFrequencyData);\n    return this.inputFrequencyData;\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array<ArrayBuffer> {\n    // Use WebRTC analyser if available\n    if (this.connection instanceof WebRTCConnection) {\n      const webrtcData = this.connection.getOutputByteFrequencyData();\n      if (webrtcData) {\n        return webrtcData as Uint8Array<ArrayBuffer>;\n      }\n      // Fallback to empty array if WebRTC analyser not ready\n      return new Uint8Array(1024) as Uint8Array<ArrayBuffer>;\n    }\n\n    this.outputFrequencyData ??= new Uint8Array(\n      this.output.analyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.output.analyser.getByteFrequencyData(this.outputFrequencyData);\n    return this.outputFrequencyData;\n  }\n\n  public getInputVolume() {\n    return this.calculateVolume(this.getInputByteFrequencyData());\n  }\n\n  public getOutputVolume() {\n    return this.calculateVolume(this.getOutputByteFrequencyData());\n  }\n\n  public async changeInputDevice({\n    sampleRate,\n    format,\n    preferHeadphonesForIosDevices,\n    inputDeviceId,\n  }: FormatConfig & InputConfig): Promise<Input> {\n    try {\n      // For WebSocket connections, try to change device on existing input first\n      if (this.connection instanceof WebSocketConnection) {\n        try {\n          await this.input.setInputDevice(inputDeviceId);\n          return this.input;\n        } catch (error) {\n          console.warn(\n            \"Failed to change device on existing input, recreating:\",\n            error\n          );\n          // Fall back to recreating the input\n        }\n      }\n\n      // Handle WebRTC connections differently\n      if (this.connection instanceof WebRTCConnection) {\n        await this.connection.setAudioInputDevice(inputDeviceId || \"\");\n      }\n\n      // Fallback: recreate the input\n      await this.input.close();\n\n      const newInput = await Input.create({\n        sampleRate: sampleRate ?? this.connection.inputFormat.sampleRate,\n        format: format ?? this.connection.inputFormat.format,\n        preferHeadphonesForIosDevices,\n        inputDeviceId,\n        workletPaths: this.options.workletPaths,\n        libsampleratePath: this.options.libsampleratePath,\n      });\n\n      this.input = newInput;\n      this.input.worklet.port.onmessage = this.onInputWorkletMessage;\n\n      return this.input;\n    } catch (error) {\n      console.error(\"Error changing input device\", error);\n      throw error;\n    }\n  }\n\n  public async changeOutputDevice({\n    sampleRate,\n    format,\n    outputDeviceId,\n  }: FormatConfig): Promise<Output> {\n    try {\n      // For WebSocket connections, try to change device on existing output first\n      if (this.connection instanceof WebSocketConnection) {\n        try {\n          await this.output.setOutputDevice(outputDeviceId);\n          return this.output;\n        } catch (error) {\n          console.warn(\n            \"Failed to change device on existing output, recreating:\",\n            error\n          );\n          // Fall back to recreating the output\n        }\n      }\n\n      // Handle WebRTC connections differently\n      if (this.connection instanceof WebRTCConnection) {\n        await this.connection.setAudioOutputDevice(outputDeviceId || \"\");\n      }\n\n      // Fallback: recreate the output\n      await this.output.close();\n\n      const newOutput = await Output.create({\n        sampleRate: sampleRate ?? this.connection.outputFormat.sampleRate,\n        format: format ?? this.connection.outputFormat.format,\n        outputDeviceId,\n        workletPaths: this.options.workletPaths,\n      });\n\n      this.output = newOutput;\n\n      return this.output;\n    } catch (error) {\n      console.error(\"Error changing output device\", error);\n      throw error;\n    }\n  }\n\n  public setVolume = ({ volume }: { volume: number }) => {\n    // clamp & coerce\n    const clampedVolume = Number.isFinite(volume)\n      ? Math.min(1, Math.max(0, volume))\n      : 1;\n    this.volume = clampedVolume;\n\n    if (this.connection instanceof WebRTCConnection) {\n      // For WebRTC connections, control volume via HTML audio elements\n      this.connection.setAudioVolume(clampedVolume);\n    } else {\n      // For WebSocket connections, control volume via gain node\n      this.output.gain.gain.value = clampedVolume;\n    }\n  };\n}\n","const HTTPS_API_ORIGIN = \"https://api.elevenlabs.io\";\n\nexport interface RatingFeedback {\n  rating: number;\n  comment?: string;\n}\n\ntype Feedback = RatingFeedback;\n\nexport function postOverallFeedback(\n  conversationId: string,\n  like: boolean,\n  origin?: string\n): Promise<Response>;\nexport function postOverallFeedback(\n  conversationId: string,\n  feedback: Feedback,\n  origin?: string\n): Promise<Response>;\nexport function postOverallFeedback(\n  conversationId: string,\n  likeOrFeedback: boolean | Feedback,\n  origin: string = HTTPS_API_ORIGIN\n): Promise<Response> {\n  const body: {\n    feedback?: \"like\" | \"dislike\";\n    rating?: number;\n    comment?: string;\n  } = {};\n\n  if (typeof likeOrFeedback === \"boolean\") {\n    body.feedback = likeOrFeedback ? \"like\" : \"dislike\";\n  } else {\n    body.rating = likeOrFeedback.rating;\n    body.comment = likeOrFeedback.comment;\n  }\n\n  return fetch(`${origin}/v1/convai/conversations/${conversationId}/feedback`, {\n    method: \"POST\",\n    body: JSON.stringify(body),\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n  });\n}\n","import type {\n  InputAudioChunk,\n  SessionStartedMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n  ScribeCommitThrottledErrorMessage,\n  ScribeTranscriberErrorMessage,\n  ScribeUnacceptedTermsErrorMessage,\n  ScribeRateLimitedErrorMessage,\n  ScribeInputErrorMessage,\n  ScribeQueueOverflowErrorMessage,\n  ScribeResourceExhaustedErrorMessage,\n  ScribeSessionTimeLimitExceededErrorMessage,\n  ScribeChunkSizeExceededErrorMessage,\n  ScribeInsufficientAudioActivityErrorMessage,\n} from \"@elevenlabs/types\";\n\n// Re-export types for public API\nexport type {\n  SessionStartedMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n  ScribeCommitThrottledErrorMessage,\n  ScribeTranscriberErrorMessage,\n  ScribeUnacceptedTermsErrorMessage,\n  ScribeRateLimitedErrorMessage,\n  ScribeInputErrorMessage,\n  ScribeQueueOverflowErrorMessage,\n  ScribeResourceExhaustedErrorMessage,\n  ScribeSessionTimeLimitExceededErrorMessage,\n  ScribeChunkSizeExceededErrorMessage,\n  ScribeInsufficientAudioActivityErrorMessage,\n};\n\nexport type WebSocketMessage =\n  | SessionStartedMessage\n  | PartialTranscriptMessage\n  | CommittedTranscriptMessage\n  | CommittedTranscriptWithTimestampsMessage\n  | ScribeErrorMessage\n  | ScribeAuthErrorMessage\n  | ScribeQuotaExceededErrorMessage\n  | ScribeCommitThrottledErrorMessage\n  | ScribeTranscriberErrorMessage\n  | ScribeUnacceptedTermsErrorMessage\n  | ScribeRateLimitedErrorMessage\n  | ScribeInputErrorMessage\n  | ScribeQueueOverflowErrorMessage\n  | ScribeResourceExhaustedErrorMessage\n  | ScribeSessionTimeLimitExceededErrorMessage\n  | ScribeChunkSizeExceededErrorMessage\n  | ScribeInsufficientAudioActivityErrorMessage;\n\n/**\n * Simple EventEmitter implementation for browser compatibility.\n */\nclass EventEmitter {\n  private listeners: Map<string, Set<(...args: unknown[]) => void>> = new Map();\n\n  on(event: string, listener: (...args: unknown[]) => void): void {\n    if (!this.listeners.has(event)) {\n      this.listeners.set(event, new Set());\n    }\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.add(listener);\n    }\n  }\n\n  off(event: string, listener: (...args: unknown[]) => void): void {\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.delete(listener);\n    }\n  }\n\n  emit(event: string, ...args: unknown[]): void {\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.forEach(listener => {\n        listener(...args);\n      });\n    }\n  }\n}\n\n/**\n * Events emitted by the RealtimeConnection.\n */\nexport enum RealtimeEvents {\n  /** Emitted when the session is successfully started */\n  SESSION_STARTED = \"session_started\",\n  /** Emitted when a partial (interim) transcript is available */\n  PARTIAL_TRANSCRIPT = \"partial_transcript\",\n  /** Emitted when a final transcript is available */\n  COMMITTED_TRANSCRIPT = \"committed_transcript\",\n  /** Emitted when a final transcript with timestamps is available */\n  COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS = \"committed_transcript_with_timestamps\",\n  /** Emitted when an authentication error occurs */\n  AUTH_ERROR = \"auth_error\",\n  /** Emitted when an error occurs (also emitted for all specific error types) */\n  ERROR = \"error\",\n  /** Emitted when the WebSocket connection is opened */\n  OPEN = \"open\",\n  /** Emitted when the WebSocket connection is closed */\n  CLOSE = \"close\",\n  /** Emitted when a quota exceeded error occurs */\n  QUOTA_EXCEEDED = \"quota_exceeded\",\n  /** Emitted when commit is throttled */\n  COMMIT_THROTTLED = \"commit_throttled\",\n  /** Emitted when a transcriber error occurs */\n  TRANSCRIBER_ERROR = \"transcriber_error\",\n  /** Emitted when terms have not been accepted */\n  UNACCEPTED_TERMS = \"unaccepted_terms\",\n  /** Emitted when rate limited */\n  RATE_LIMITED = \"rate_limited\",\n  /** Emitted when there's an input error */\n  INPUT_ERROR = \"input_error\",\n  /** Emitted when the queue overflows */\n  QUEUE_OVERFLOW = \"queue_overflow\",\n  /** Emitted when resources are exhausted */\n  RESOURCE_EXHAUSTED = \"resource_exhausted\",\n  /** Emitted when session time limit is exceeded */\n  SESSION_TIME_LIMIT_EXCEEDED = \"session_time_limit_exceeded\",\n  /** Emitted when chunk size is exceeded */\n  CHUNK_SIZE_EXCEEDED = \"chunk_size_exceeded\",\n  /** Emitted when there's insufficient audio activity */\n  INSUFFICIENT_AUDIO_ACTIVITY = \"insufficient_audio_activity\",\n}\n\n/**\n * Map of event types to their payload types.\n */\nexport interface RealtimeEventMap {\n  [RealtimeEvents.SESSION_STARTED]: SessionStartedMessage;\n  [RealtimeEvents.PARTIAL_TRANSCRIPT]: PartialTranscriptMessage;\n  [RealtimeEvents.COMMITTED_TRANSCRIPT]: CommittedTranscriptMessage;\n  [RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS]: CommittedTranscriptWithTimestampsMessage;\n  [RealtimeEvents.ERROR]: ScribeErrorMessage;\n  [RealtimeEvents.AUTH_ERROR]: ScribeAuthErrorMessage;\n  [RealtimeEvents.QUOTA_EXCEEDED]: ScribeQuotaExceededErrorMessage;\n  [RealtimeEvents.COMMIT_THROTTLED]: ScribeCommitThrottledErrorMessage;\n  [RealtimeEvents.TRANSCRIBER_ERROR]: ScribeTranscriberErrorMessage;\n  [RealtimeEvents.UNACCEPTED_TERMS]: ScribeUnacceptedTermsErrorMessage;\n  [RealtimeEvents.RATE_LIMITED]: ScribeRateLimitedErrorMessage;\n  [RealtimeEvents.INPUT_ERROR]: ScribeInputErrorMessage;\n  [RealtimeEvents.QUEUE_OVERFLOW]: ScribeQueueOverflowErrorMessage;\n  [RealtimeEvents.RESOURCE_EXHAUSTED]: ScribeResourceExhaustedErrorMessage;\n  [RealtimeEvents.SESSION_TIME_LIMIT_EXCEEDED]: ScribeSessionTimeLimitExceededErrorMessage;\n  [RealtimeEvents.CHUNK_SIZE_EXCEEDED]: ScribeChunkSizeExceededErrorMessage;\n  [RealtimeEvents.INSUFFICIENT_AUDIO_ACTIVITY]: ScribeInsufficientAudioActivityErrorMessage;\n  [RealtimeEvents.OPEN]: undefined;\n  [RealtimeEvents.CLOSE]: CloseEvent;\n}\n\n/**\n * Manages a real-time transcription WebSocket connection.\n *\n * @example\n * ```typescript\n * const connection = await Scribe.connect({\n *     token: \"...\",\n *     modelId: \"scribe_v2_realtime\",\n *     audioFormat: AudioFormat.PCM_16000,\n *     sampleRate: 16000,\n * });\n *\n * connection.on(RealtimeEvents.SESSION_STARTED, (data) => {\n *     console.log(\"Session started\");\n * });\n *\n * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {\n *     console.log(\"Partial:\", data.transcript);\n * });\n *\n * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n *     console.log(\"Final:\", data.transcript);\n *     connection.close();\n * });\n *\n * // Send audio data\n * connection.send({ audioBase64: base64String });\n *\n * // Commit and close\n * connection.commit();\n * ```\n */\nexport class RealtimeConnection {\n  private websocket: WebSocket | null = null;\n  private eventEmitter: EventEmitter = new EventEmitter();\n  private currentSampleRate: number = 16000;\n  public _audioCleanup?: () => void;\n\n  constructor(sampleRate: number) {\n    this.currentSampleRate = sampleRate;\n  }\n\n  /**\n   * @internal\n   * Used internally by ScribeRealtime to attach the WebSocket after connection is created.\n   */\n  public setWebSocket(websocket: WebSocket): void {\n    this.websocket = websocket;\n\n    // If WebSocket is already open, emit OPEN event immediately\n    if (this.websocket.readyState === WebSocket.OPEN) {\n      this.eventEmitter.emit(RealtimeEvents.OPEN);\n    } else {\n      // Otherwise, wait for the open event\n      this.websocket.addEventListener(\"open\", () => {\n        this.eventEmitter.emit(RealtimeEvents.OPEN);\n      });\n    }\n\n    this.websocket.addEventListener(\"message\", (event: MessageEvent) => {\n      try {\n        const data = JSON.parse(event.data) as WebSocketMessage;\n\n        switch (data.message_type) {\n          case \"session_started\":\n            this.eventEmitter.emit(RealtimeEvents.SESSION_STARTED, data);\n            break;\n          case \"partial_transcript\":\n            this.eventEmitter.emit(RealtimeEvents.PARTIAL_TRANSCRIPT, data);\n            break;\n          case \"committed_transcript\":\n            this.eventEmitter.emit(RealtimeEvents.COMMITTED_TRANSCRIPT, data);\n            break;\n          case \"committed_transcript_with_timestamps\":\n            this.eventEmitter.emit(\n              RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS,\n              data\n            );\n            break;\n          // Error cases - emit both specific event and generic ERROR\n          case \"auth_error\":\n            this.eventEmitter.emit(RealtimeEvents.AUTH_ERROR, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"quota_exceeded\":\n            this.eventEmitter.emit(RealtimeEvents.QUOTA_EXCEEDED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"commit_throttled\":\n            this.eventEmitter.emit(RealtimeEvents.COMMIT_THROTTLED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"transcriber_error\":\n            this.eventEmitter.emit(RealtimeEvents.TRANSCRIBER_ERROR, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"unaccepted_terms\":\n            this.eventEmitter.emit(RealtimeEvents.UNACCEPTED_TERMS, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"rate_limited\":\n            this.eventEmitter.emit(RealtimeEvents.RATE_LIMITED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"input_error\":\n            this.eventEmitter.emit(RealtimeEvents.INPUT_ERROR, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"queue_overflow\":\n            this.eventEmitter.emit(RealtimeEvents.QUEUE_OVERFLOW, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"resource_exhausted\":\n            this.eventEmitter.emit(RealtimeEvents.RESOURCE_EXHAUSTED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"session_time_limit_exceeded\":\n            this.eventEmitter.emit(\n              RealtimeEvents.SESSION_TIME_LIMIT_EXCEEDED,\n              data\n            );\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"chunk_size_exceeded\":\n            this.eventEmitter.emit(RealtimeEvents.CHUNK_SIZE_EXCEEDED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"insufficient_audio_activity\":\n            this.eventEmitter.emit(\n              RealtimeEvents.INSUFFICIENT_AUDIO_ACTIVITY,\n              data\n            );\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"error\":\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          default:\n            console.warn(\"Unknown message type:\", data);\n        }\n      } catch (error) {\n        console.error(\"Failed to parse WebSocket message:\", error, event.data);\n        this.eventEmitter.emit(\n          RealtimeEvents.ERROR,\n          new Error(`Failed to parse message: ${error}`)\n        );\n      }\n    });\n\n    this.websocket.addEventListener(\"error\", (error: Event) => {\n      console.error(\"WebSocket error:\", error);\n      this.eventEmitter.emit(RealtimeEvents.ERROR, error);\n    });\n\n    this.websocket.addEventListener(\"close\", (event: CloseEvent) => {\n      console.log(\n        `WebSocket closed: code=${event.code}, reason=\"${event.reason}\", wasClean=${event.wasClean}`\n      );\n\n      // Emit error if close was not clean or had an error code\n      if (!event.wasClean || (event.code !== 1000 && event.code !== 1005)) {\n        const errorMessage = `WebSocket closed unexpectedly: ${event.code} - ${event.reason || \"No reason provided\"}`;\n        console.error(errorMessage);\n        this.eventEmitter.emit(RealtimeEvents.ERROR, new Error(errorMessage));\n      }\n\n      this.eventEmitter.emit(RealtimeEvents.CLOSE, event);\n    });\n  }\n\n  /**\n   * Attaches an event listener for the specified event.\n   *\n   * @param event - The event to listen for (use RealtimeEvents enum)\n   * @param listener - The callback function to execute when the event fires\n   *\n   * @example\n   * ```typescript\n   * connection.on(RealtimeEvents.SESSION_STARTED, (data) => {\n   *     console.log(\"Session started\", data.session_id);\n   * });\n   *\n   * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {\n   *     console.log(\"Partial:\", data.text);\n   * });\n   *\n   * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n   *     console.log(\"Final:\", data.text);\n   * });\n   * ```\n   */\n  public on<E extends RealtimeEvents>(\n    event: E,\n    listener: RealtimeEventMap[E] extends undefined\n      ? () => void\n      : (data: RealtimeEventMap[E]) => void\n  ): void {\n    this.eventEmitter.on(event, listener as (...args: unknown[]) => void);\n  }\n\n  /**\n   * Removes an event listener for the specified event.\n   *\n   * @param event - The event to stop listening for\n   * @param listener - The callback function to remove\n   *\n   * @example\n   * ```typescript\n   * const handler = (data: PartialTranscriptMessage) => console.log(data.text);\n   * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, handler);\n   *\n   * // Later, remove the listener\n   * connection.off(RealtimeEvents.PARTIAL_TRANSCRIPT, handler);\n   * ```\n   */\n  public off<E extends RealtimeEvents>(\n    event: E,\n    listener: RealtimeEventMap[E] extends undefined\n      ? () => void\n      : (data: RealtimeEventMap[E]) => void\n  ): void {\n    this.eventEmitter.off(event, listener as (...args: unknown[]) => void);\n  }\n\n  /**\n   * Sends audio data to the transcription service.\n   *\n   * @param data - Audio data configuration\n   * @param data.audioBase64 - Base64-encoded audio data\n   * @param data.commit - Whether to commit the transcription after this chunk. You likely want to use connection.commit() instead (default: false)\n   * @param data.sampleRate - Sample rate of the audio (default: configured sample rate)\n   * @param data.previousText - Send context to the model via base64 encoded audio or text from a previous transcription. Can only be sent alongside the first audio chunk. If sent in a subsequent chunk, an error will be returned.\n   *\n   * @throws {Error} If the WebSocket connection is not open\n   *\n   * @example\n   * ```typescript\n   * // Send audio chunk without committing\n   * connection.send({\n   *     audioBase64: base64EncodedAudio,\n   * });\n   *\n   * // Send audio chunk with custom sample rate and previous text\n   * connection.send({\n   *     audioBase64: base64EncodedAudio,\n   *     sampleRate: 16000,\n   *     previousText: \"Previous transcription text\",\n   * });\n   * ```\n   */\n  public send(data: {\n    audioBase64: string;\n    commit?: boolean;\n    sampleRate?: number;\n    previousText?: string;\n  }): void {\n    if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {\n      throw new Error(\"WebSocket is not connected\");\n    }\n\n    const message: InputAudioChunk = {\n      message_type: \"input_audio_chunk\",\n      audio_base_64: data.audioBase64,\n      commit: data.commit ?? false,\n      sample_rate: data.sampleRate ?? this.currentSampleRate,\n      previous_text: data.previousText,\n    };\n\n    this.websocket.send(JSON.stringify(message));\n  }\n\n  /**\n   * Commits the transcription, signaling that a segment of audio has been sent. This clears the buffer and triggers a COMMITTED_TRANSCRIPT event. Context from previous segments is kept.\n   * Committing a segment triggers a COMMITTED_TRANSCRIPT event.\n   *\n   * @throws {Error} If the WebSocket connection is not open\n   *\n   * @remarks\n   * Only needed when using CommitStrategy.MANUAL.\n   * When using CommitStrategy.VAD, commits are handled automatically by the server.\n   *\n   * @example\n   * ```typescript\n   * // Send all audio chunks\n   * for (const chunk of audioChunks) {\n   *     connection.send({ audioBase64: chunk });\n   * }\n   *\n   * // Finalize the transcription\n   * connection.commit();\n   * ```\n   */\n  public commit(): void {\n    if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {\n      throw new Error(\"WebSocket is not connected\");\n    }\n\n    const message: InputAudioChunk = {\n      message_type: \"input_audio_chunk\",\n      audio_base_64: \"\",\n      commit: true,\n      sample_rate: this.currentSampleRate,\n    };\n\n    this.websocket.send(JSON.stringify(message));\n  }\n\n  /**\n   * Closes the WebSocket connection and cleans up resources.\n   * This will terminate any ongoing transcription and stop microphone streaming if active.\n   *\n   * @remarks\n   * After calling close(), this connection cannot be reused.\n   * Create a new connection if you need to start transcribing again.\n   *\n   * @example\n   * ```typescript\n   * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n   *     console.log(\"Segment committed:\", data.transcript);\n   *     connection.close();\n   * });\n   * ```\n   */\n  public close(): void {\n    // Cleanup audio resources (microphone stream, audio context)\n    if (this._audioCleanup) {\n      this._audioCleanup();\n    }\n\n    // Close WebSocket connection\n    if (this.websocket) {\n      this.websocket.close(1000, \"User ended session\");\n    }\n  }\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadScribeAudioProcessor = createWorkletModuleLoader(\n  \"scribeAudioProcessor\",\n  // language=JavaScript\n  `/*\n * Scribe Audio Processor for converting microphone audio to PCM16 format\n * Supports resampling for browsers like Firefox that don't support\n * AudioContext sample rate constraints.\n * USED BY @elevenlabs/client\n */\n\nclass ScribeAudioProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this.buffer = [];\n    this.bufferSize = 4096; // Buffer size for optimal chunk transmission\n\n    // Resampling state\n    this.inputSampleRate = null;\n    this.outputSampleRate = null;\n    this.resampleRatio = 1;\n    this.lastSample = 0;\n    this.resampleAccumulator = 0;\n\n    this.port.onmessage = ({ data }) => {\n      if (data.type === \"configure\") {\n        this.inputSampleRate = data.inputSampleRate;\n        this.outputSampleRate = data.outputSampleRate;\n        if (this.inputSampleRate && this.outputSampleRate) {\n          this.resampleRatio = this.inputSampleRate / this.outputSampleRate;\n        }\n      }\n    };\n  }\n\n  // Linear interpolation resampling\n  resample(inputData) {\n    if (this.resampleRatio === 1 || !this.inputSampleRate) {\n      return inputData;\n    }\n\n    const outputSamples = [];\n\n    for (let i = 0; i < inputData.length; i++) {\n      const currentSample = inputData[i];\n\n      // Generate output samples using linear interpolation\n      while (this.resampleAccumulator < 1) {\n        const interpolated =\n          this.lastSample +\n          (currentSample - this.lastSample) * this.resampleAccumulator;\n        outputSamples.push(interpolated);\n        this.resampleAccumulator += this.resampleRatio;\n      }\n\n      this.resampleAccumulator -= 1;\n      this.lastSample = currentSample;\n    }\n\n    return new Float32Array(outputSamples);\n  }\n\n  process(inputs) {\n    const input = inputs[0];\n    if (input.length > 0) {\n      let channelData = input[0]; // Get first channel (mono)\n\n      // Resample if needed (for Firefox and other browsers that don't\n      // support AudioContext sample rate constraints)\n      if (this.resampleRatio !== 1) {\n        channelData = this.resample(channelData);\n      }\n\n      // Add incoming audio to buffer\n      for (let i = 0; i < channelData.length; i++) {\n        this.buffer.push(channelData[i]);\n      }\n\n      // When buffer reaches threshold, convert and send\n      if (this.buffer.length >= this.bufferSize) {\n        const float32Array = new Float32Array(this.buffer);\n        const int16Array = new Int16Array(float32Array.length);\n\n        // Convert Float32 [-1, 1] to Int16 [-32768, 32767]\n        for (let i = 0; i < float32Array.length; i++) {\n          // Clamp the value to prevent overflow\n          const sample = Math.max(-1, Math.min(1, float32Array[i]));\n          // Scale to PCM16 range\n          int16Array[i] = sample < 0 ? sample * 32768 : sample * 32767;\n        }\n\n        // Send to main thread as transferable ArrayBuffer\n        this.port.postMessage(\n          {\n            audioData: int16Array.buffer\n          },\n          [int16Array.buffer]\n        );\n\n        // Clear buffer\n        this.buffer = [];\n      }\n    }\n\n    return true; // Continue processing\n  }\n}\n\nregisterProcessor(\"scribeAudioProcessor\", ScribeAudioProcessor);\n\n`\n);\n","import { RealtimeConnection } from \"./connection\";\nimport { loadScribeAudioProcessor } from \"../utils/scribeAudioProcessor.generated\";\n\nexport enum AudioFormat {\n  PCM_8000 = \"pcm_8000\",\n  PCM_16000 = \"pcm_16000\",\n  PCM_22050 = \"pcm_22050\",\n  PCM_24000 = \"pcm_24000\",\n  PCM_44100 = \"pcm_44100\",\n  PCM_48000 = \"pcm_48000\",\n  ULAW_8000 = \"ulaw_8000\",\n}\n\nexport enum CommitStrategy {\n  MANUAL = \"manual\",\n  VAD = \"vad\",\n}\n\ninterface BaseOptions {\n  /**\n   * Token to use for the WebSocket connection. Obtained from the ElevenLabs API.\n   */\n  token: string;\n  /**\n   * Strategy for committing transcriptions.\n   * @default CommitStrategy.MANUAL\n   */\n  commitStrategy?: CommitStrategy;\n  /**\n   * Silence threshold in seconds for VAD (Voice Activity Detection).\n   * Must be a positive number between 0.3 and 3.0\n   */\n  vadSilenceThresholdSecs?: number;\n  /**\n   * Threshold for voice activity detection.\n   * Must be between 0.1 and 0.9.\n   */\n  vadThreshold?: number;\n  /**\n   * Minimum speech duration in milliseconds.\n   * Must be a positive integer between 50 and 2000.\n   */\n  minSpeechDurationMs?: number;\n  /**\n   * Minimum silence duration in milliseconds.\n   * Must be a positive integer between 50 and 2000.\n   */\n  minSilenceDurationMs?: number;\n  /**\n   * Model ID to use for transcription.\n   * Must be a valid model ID.\n   */\n  modelId: string;\n  /**\n   * An ISO-639-1 or ISO-639-3 language_code corresponding to the language of the audio file.\n   * Can sometimes improve transcription performance if known beforehand.\n   */\n  languageCode?: string;\n  /**\n   * Base URI to use for the WebSocket connection.\n   * If not provided, the default URI will be used.\n   */\n  baseUri?: string;\n  /**\n   * Whether to receive a committed_transcript_with_timestamps event which includes word-level timestamps.\n   * @default false\n   */\n  includeTimestamps?: boolean;\n}\n\nexport interface AudioOptions extends BaseOptions {\n  audioFormat: AudioFormat;\n  sampleRate: number;\n  microphone?: never;\n}\n\n/**\n * Options for automatic microphone streaming in the browser.\n */\nexport interface MicrophoneOptions extends BaseOptions {\n  microphone?: {\n    deviceId?: ConstrainDOMString;\n    echoCancellation?: boolean;\n    noiseSuppression?: boolean;\n    autoGainControl?: boolean;\n    channelCount?: number;\n  };\n  audioFormat?: never;\n  sampleRate?: never;\n}\n\n/**\n * Real-time speech-to-text transcription client for browser environments.\n * Supports microphone streaming and manual audio chunk transmission.\n */\n\n// biome-ignore lint/complexity/noStaticOnlyClass: This class is static only because it is a singleton\nexport class ScribeRealtime {\n  private static readonly DEFAULT_BASE_URI = \"wss://api.elevenlabs.io\";\n\n  private static getWebSocketUri(\n    baseUri: string = ScribeRealtime.DEFAULT_BASE_URI\n  ): string {\n    return `${baseUri}/v1/speech-to-text/realtime`;\n  }\n\n  private static buildWebSocketUri(\n    options: AudioOptions | MicrophoneOptions\n  ): string {\n    const baseUri = ScribeRealtime.getWebSocketUri(options.baseUri);\n    const params = new URLSearchParams();\n\n    // Model ID and token are required, so no check required\n    params.append(\"model_id\", options.modelId);\n    params.append(\"token\", options.token);\n\n    // Add optional parameters if provided, with validation\n    if (options.commitStrategy !== undefined) {\n      params.append(\"commit_strategy\", options.commitStrategy);\n    }\n    if (options.audioFormat !== undefined) {\n      params.append(\"audio_format\", options.audioFormat);\n    }\n    if (options.vadSilenceThresholdSecs !== undefined) {\n      if (\n        options.vadSilenceThresholdSecs <= 0.3 ||\n        options.vadSilenceThresholdSecs > 3.0\n      ) {\n        throw new Error(\"vadSilenceThresholdSecs must be between 0.3 and 3.0\");\n      }\n      params.append(\n        \"vad_silence_threshold_secs\",\n        options.vadSilenceThresholdSecs.toString()\n      );\n    }\n    if (options.vadThreshold !== undefined) {\n      if (options.vadThreshold < 0.1 || options.vadThreshold > 0.9) {\n        throw new Error(\"vadThreshold must be between 0.1 and 0.9\");\n      }\n      params.append(\"vad_threshold\", options.vadThreshold.toString());\n    }\n    if (options.minSpeechDurationMs !== undefined) {\n      if (\n        options.minSpeechDurationMs <= 50 ||\n        options.minSpeechDurationMs > 2000\n      ) {\n        throw new Error(\"minSpeechDurationMs must be between 50 and 2000\");\n      }\n      params.append(\n        \"min_speech_duration_ms\",\n        options.minSpeechDurationMs.toString()\n      );\n    }\n    if (options.minSilenceDurationMs !== undefined) {\n      if (\n        options.minSilenceDurationMs <= 50 ||\n        options.minSilenceDurationMs > 2000\n      ) {\n        throw new Error(\"minSilenceDurationMs must be between 50 and 2000\");\n      }\n      params.append(\n        \"min_silence_duration_ms\",\n        options.minSilenceDurationMs.toString()\n      );\n    }\n    if (options.languageCode !== undefined) {\n      params.append(\"language_code\", options.languageCode);\n    }\n    if (options.includeTimestamps !== undefined) {\n      params.append(\n        \"include_timestamps\",\n        options.includeTimestamps ? \"true\" : \"false\"\n      );\n    }\n\n    const queryString = params.toString();\n    return queryString ? `${baseUri}?${queryString}` : baseUri;\n  }\n\n  /**\n   * Establishes a WebSocket connection for real-time speech-to-text transcription.\n   *\n   * @param options - Configuration options for the connection\n   * @returns A RealtimeConnection instance\n   *\n   * @example\n   * ```typescript\n   * // Manual audio streaming\n   * const connection = Scribe.connect({\n   *     token: \"...\",\n   *     modelId: \"scribe_v2_realtime\",\n   *     audioFormat: AudioFormat.PCM_16000,\n   *     sampleRate: 16000,\n   * });\n   *\n   * // Automatic microphone streaming\n   * const connection = Scribe.connect({\n   *     token: \"...\",\n   *     modelId: \"scribe_v2_realtime\",\n   *     microphone: {\n   *         echoCancellation: true,\n   *         noiseSuppression: true\n   *     }\n   * });\n   * ```\n   */\n  public static connect(\n    options: AudioOptions | MicrophoneOptions\n  ): RealtimeConnection {\n    if (!options.modelId) {\n      throw new Error(\"modelId is required\");\n    }\n\n    // Create connection object first so users can attach event listeners before messages arrive\n    const sampleRate =\n      \"microphone\" in options && options.microphone\n        ? 16000\n        : (options as AudioOptions).sampleRate;\n    const connection = new RealtimeConnection(sampleRate);\n\n    // Build WebSocket URI with query parameters\n    const uri = ScribeRealtime.buildWebSocketUri(options);\n\n    const websocket = new WebSocket(uri);\n\n    // If microphone mode, set up streaming handler\n    if (\"microphone\" in options && options.microphone) {\n      websocket.addEventListener(\"open\", () => {\n        ScribeRealtime.streamFromMicrophone(\n          options as MicrophoneOptions,\n          connection\n        );\n      });\n    }\n\n    connection.setWebSocket(websocket);\n\n    return connection;\n  }\n\n  private static async streamFromMicrophone(\n    options: MicrophoneOptions,\n    connection: RealtimeConnection\n  ): Promise<void> {\n    const TARGET_SAMPLE_RATE = 16000;\n\n    try {\n      // Get microphone access\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          deviceId: options.microphone?.deviceId,\n          echoCancellation: options.microphone?.echoCancellation ?? true,\n          noiseSuppression: options.microphone?.noiseSuppression ?? true,\n          autoGainControl: options.microphone?.autoGainControl ?? true,\n          channelCount: options.microphone?.channelCount ?? 1,\n          sampleRate: { ideal: TARGET_SAMPLE_RATE },\n        },\n      });\n\n      // Get the actual sample rate from the stream - the ideal may not have been honored\n      const trackSettings = stream.getAudioTracks()[0]?.getSettings();\n      const streamSampleRate = trackSettings?.sampleRate;\n\n      // Create audio context matching the stream's sample rate to avoid Firefox errors\n      // Firefox requires the AudioContext to match the microphone's native sample rate\n      const audioContext = new AudioContext(\n        streamSampleRate ? { sampleRate: streamSampleRate } : {}\n      );\n\n      // Load scribe worklet\n      await loadScribeAudioProcessor(audioContext.audioWorklet);\n\n      // Set up audio pipeline\n      const source = audioContext.createMediaStreamSource(stream);\n      const scribeNode = new AudioWorkletNode(\n        audioContext,\n        \"scribeAudioProcessor\"\n      );\n\n      // Configure the worklet with sample rate info for resampling\n      // (only needed when AudioContext sample rate differs from target)\n      if (audioContext.sampleRate !== TARGET_SAMPLE_RATE) {\n        scribeNode.port.postMessage({\n          type: \"configure\",\n          inputSampleRate: audioContext.sampleRate,\n          outputSampleRate: TARGET_SAMPLE_RATE,\n        });\n      }\n\n      // Handle audio data from worklet\n      scribeNode.port.onmessage = event => {\n        const { audioData } = event.data;\n        // Convert ArrayBuffer to base64\n        const bytes = new Uint8Array(audioData);\n        let binary = \"\";\n        for (let i = 0; i < bytes.length; i++) {\n          binary += String.fromCharCode(bytes[i]);\n        }\n        const base64Audio = btoa(binary);\n\n        connection.send({ audioBase64: base64Audio });\n      };\n\n      // Connect audio pipeline\n      source.connect(scribeNode);\n\n      // Resume audio context if needed\n      if (audioContext.state === \"suspended\") {\n        await audioContext.resume();\n      }\n\n      // Store cleanup function\n      connection._audioCleanup = () => {\n        stream.getTracks().forEach(track => {\n          track.stop();\n        });\n        source.disconnect();\n        scribeNode.disconnect();\n        audioContext.close();\n      };\n    } catch (error) {\n      console.error(\"Failed to start microphone streaming:\", error);\n      throw error;\n    }\n  }\n}\n","import { BaseConversation, type PartialOptions } from \"./BaseConversation\";\nimport { TextConversation } from \"./TextConversation\";\nimport { VoiceConversation } from \"./VoiceConversation\";\n\nexport type {\n  Mode,\n  Role,\n  Options,\n  PartialOptions,\n  ClientToolsConfig,\n  Callbacks,\n  Status,\n  AudioWorkletConfig,\n} from \"./BaseConversation\";\nexport type { InputConfig } from \"./utils/input\";\nexport type { OutputConfig } from \"./utils/output\";\nexport { Input } from \"./utils/input\";\nexport { Output } from \"./utils/output\";\nexport type {\n  IncomingSocketEvent,\n  VadScoreEvent,\n  AudioAlignmentEvent,\n} from \"./utils/events\";\nexport type {\n  SessionConfig,\n  BaseSessionConfig,\n  DisconnectionDetails,\n  Language,\n  ConnectionType,\n  FormatConfig,\n} from \"./utils/BaseConnection\";\nexport { createConnection } from \"./utils/ConnectionFactory\";\nexport { WebSocketConnection } from \"./utils/WebSocketConnection\";\nexport { WebRTCConnection } from \"./utils/WebRTCConnection\";\nexport { postOverallFeedback } from \"./utils/postOverallFeedback\";\nexport { SessionConnectionError } from \"./utils/errors\";\nexport { VoiceConversation } from \"./VoiceConversation\";\nexport { TextConversation } from \"./TextConversation\";\n\n// Scribe exports\nexport {\n  Scribe,\n  AudioFormat,\n  CommitStrategy,\n  RealtimeEvents,\n  RealtimeConnection,\n} from \"./scribe\";\nexport type {\n  AudioOptions,\n  MicrophoneOptions,\n  WebSocketMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n  ScribeCommitThrottledErrorMessage,\n  ScribeTranscriberErrorMessage,\n  ScribeUnacceptedTermsErrorMessage,\n  ScribeRateLimitedErrorMessage,\n  ScribeInputErrorMessage,\n  ScribeQueueOverflowErrorMessage,\n  ScribeResourceExhaustedErrorMessage,\n  ScribeSessionTimeLimitExceededErrorMessage,\n  ScribeChunkSizeExceededErrorMessage,\n  ScribeInsufficientAudioActivityErrorMessage,\n} from \"./scribe\";\n\nexport class Conversation extends BaseConversation {\n  public static startSession(options: PartialOptions): Promise<Conversation> {\n    return options.textOnly\n      ? TextConversation.startSession(options)\n      : VoiceConversation.startSession(options);\n  }\n}\n"],"names":["EMPTY_FREQUENCY_DATA","Uint8Array","BaseConversation","getFullOptions","partialOptions","_extends","clientTools","onConnect","onDebug","onDisconnect","onError","onMessage","onAudio","onModeChange","onStatusChange","onCanSendFeedbackChange","onInterruption","constructor","options","connection","_this","lastInterruptTimestamp","this","mode","status","volume","currentEventId","lastFeedbackEventId","canSendFeedback","endSessionWithDetails","async","details","updateStatus","handleEndSession","parsedEvent","type","handleInterruption","handleAgentResponse","handleUserTranscript","handleTentativeAgentResponse","handleClientToolCall","error","Error","message","String","clientToolName","client_tool_call","tool_name","toolCallId","tool_call_id","handleAudio","handleVadScore","sendMessage","event_id","ping_event","handleMCPToolCall","handleMCPConnectionStatus","handleAgentToolRequest","handleAgentToolResponse","handleConversationMetadata","handleAsrInitiationMetadata","handleAgentChatResponsePart","handleErrorEvent","setVolume","conversationId","updateMode","endSession","reason","close","updateCanSendFeedback","event","interruption_event","source","role","agent_response_event","agent_response","user_transcription_event","user_transcript","response","tentative_agent_response_internal_event","tentative_agent_response","onVadScore","vadScore","vad_score_event","vad_score","Object","prototype","hasOwnProperty","call","_await$this$options$c","result","parameters","formattedResult","JSON","stringify","is_error","e","onUnhandledClientToolCall","onMCPToolCall","mcp_tool_call","onMCPConnectionStatus","mcp_connection_status","onAgentToolRequest","agent_tool_request","agent_tool_response","context","CloseEvent","onAgentToolResponse","onConversationMetadata","conversation_initiation_metadata_event","onAsrInitiationMetadata","asr_initiation_metadata_event","onAgentChatResponsePart","text_response_part","errorType","error_event","error_type","code","debugMessage","debug_message","Event","console","getId","isOpen","setMicMuted","isMuted","getInputByteFrequencyData","getOutputByteFrequencyData","getInputVolume","getOutputVolume","sendFeedback","like","score","warn","sendContextualUpdate","text","sendUserMessage","sendUserActivity","sendMCPToolApprovalResult","isApproved","is_approved","BaseConnection","config","queue","disconnectionDetails","onDisconnectCallback","onMessageCallback","onModeChangeCallback","debug","info","callback","length","queueMicrotask","forEach","_this$onModeChangeCal","disconnect","_this$onDisconnectCal","handleMessage","push","parseFormat","format","formatPart","sampleRatePart","split","includes","sampleRate","Number","parseInt","isNaN","PACKAGE_VERSION","isValidSocketEvent","CONVERSATION_INITIATION_CLIENT_DATA_TYPE","constructOverrides","_config$overrides","overridesEvent","_config$overrides$age","_config$overrides$age2","_config$overrides$age3","_config$overrides$tts","_config$overrides$tts2","_config$overrides$tts3","_config$overrides$tts4","_config$overrides$con","overrides","conversation_config_override","agent","prompt","first_message","firstMessage","language","tts","voice_id","voiceId","speed","stability","similarity_boost","similarityBoost","conversation","text_only","textOnly","customLlmExtraBody","custom_llm_extra_body","dynamicVariables","dynamic_variables","userId","user_id","client","source_info","version","SessionConnectionError","super","closeCode","closeReason","name","WebSocketConnection","socket","inputFormat","outputFormat","addEventListener","setTimeout","undefined","parse","data","create","_config$origin","_config$overrides2","origin","url","signedUrl","separator","agentId","protocols","authorization","WebSocket","conversationConfig","Promise","resolve","reject","_socket","send","once","conversation_id","agent_output_audio_format","user_input_audio_format","_socket2","arrayBufferToBase64","b","buffer","window","btoa","fromCharCode","base64ToArrayBuffer","base64","binaryString","atob","len","bytes","i","charCodeAt","URLCache","Map","createWorkletModuleLoader","sourceCode","worklet","path","cachedUrl","get","addModule","set","blob","Blob","blobURL","URL","createObjectURL","_unused","revokeObjectURL","moduleURL","loadRawAudioProcessor","WebRTCConnection","room","isConnected","audioEventId","audioCaptureContext","audioElements","outputDeviceId","outputAnalyser","outputFrequencyData","setupRoomEventListeners","conversationToken","replace","fetch","ok","statusText","json","token","msg","Room","Date","now","livekitUrl","_room$name$match","connect","onConnected","off","RoomEvent","Connected","on","match","localParticipant","setMicrophoneEnabled","Disconnected","toString","ConnectionStateChanged","state","ConnectionState","DataReceived","payload","_participant","TextDecoder","decode","TrackSubscribed","track","_publication","participant","kind","Track","Kind","Audio","identity","remoteAudioTrack","audioElement","attach","autoplay","controls","setSinkId","style","display","document","body","appendChild","setupAudioCapture","ActiveSpeakersChanged","speakers","startsWith","ParticipantDisconnected","_participant$identity","audioTrackPublications","publication","stop","catch","element","parentNode","removeChild","TextEncoder","encode","publishData","reliable","getRoom","micTrackPublication","getTrackPublication","Source","Microphone","mute","unmute","_error","audioContext","AudioContext","createAnalyser","fftSize","smoothingTimeConstant","mediaStream","MediaStream","mediaStreamTrack","createMediaStreamSource","audioWorklet","AudioWorkletNode","port","postMessage","onmessage","audioData","maxVolume","base64Audio","eventId","audio_event","audio_base_64","setAudioVolume","setAudioOutputDevice","deviceId","HTMLAudioElement","promises","map","all","setAudioInputDevice","currentMicTrackPublication","unpublishTrack","audioConstraints","exact","echoCancellation","noiseSuppression","autoGainControl","channelCount","ideal","audioTrack","createLocalAudioTrack","publishTrack","recoveryError","_this$outputFrequency","frequencyBinCount","getByteFrequencyData","createConnection","connectionType","determineConnectionType","isIosDevice","navigator","platform","userAgent","applyDelay","delayConfig","default","android","delay","_delayConfig$android","test","_delayConfig$ios","ios","TextConversation","startSession","fullOptions","connectionDelay","_connection","defaultConstraints","Input","preferHeadphonesForIosDevices","inputDeviceId","workletPaths","libsampleratePath","inputStream","idealDevice","mediaDevices","enumerateDevices","find","d","keyword","label","toLowerCase","getDeviceIdConstraint","supportsSampleRateConstraint","getSupportedConstraints","analyser","libsamplerateUrl","constraints","voiceIsolation","getUserMedia","audio","resume","_inputStream","_context","getTracks","mediaStreamSource","setMuted","setInputDevice","newInputStream","loadAudioConcatProcessor","Output","gain","createGain","src","load","destination","createMediaStreamDestination","srcObject","stream","_audioElement","_audioElement2","pause","setOutputDevice","VoiceConversation","requestWakeLock","wakeLock","request","_e","_options$useWakeLock","input","output","preliminaryInputStream","useWakeLock","_preliminaryInputStre","_preliminaryInputStre2","_input","_output","_wakeLock","release","inputFrequencyData","visibilityChangeHandler","onInputWorkletMessage","user_audio_chunk","onOutputWorkletMessage","finished","addAudioBase64Chunk","chunk","cancelScheduledValues","currentTime","value","fadeOutAudio","exponentialRampToValueAtTime","calculateVolume","frequencyData","clampedVolume","isFinite","Math","min","max","_this$wakeLock","visibilityState","released","then","lock","removeEventListener","_this$wakeLock2","_this$options$onAudio","_this$options","alignment","onAudioAlignment","changeInputDevice","newInput","changeOutputDevice","newOutput","postOverallFeedback","likeOrFeedback","feedback","rating","comment","method","headers","EventEmitter","listeners","listener","has","Set","eventListeners","add","delete","emit","args","RealtimeEvents","RealtimeConnection","websocket","eventEmitter","currentSampleRate","_audioCleanup","setWebSocket","readyState","OPEN","message_type","SESSION_STARTED","PARTIAL_TRANSCRIPT","COMMITTED_TRANSCRIPT","COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS","AUTH_ERROR","ERROR","QUOTA_EXCEEDED","COMMIT_THROTTLED","TRANSCRIBER_ERROR","UNACCEPTED_TERMS","RATE_LIMITED","INPUT_ERROR","QUEUE_OVERFLOW","RESOURCE_EXHAUSTED","SESSION_TIME_LIMIT_EXCEEDED","CHUNK_SIZE_EXCEEDED","INSUFFICIENT_AUDIO_ACTIVITY","log","wasClean","errorMessage","CLOSE","_data$commit","_data$sampleRate","audioBase64","commit","sample_rate","previous_text","previousText","loadScribeAudioProcessor","AudioFormat","CommitStrategy","ScribeRealtime","getWebSocketUri","baseUri","DEFAULT_BASE_URI","buildWebSocketUri","params","URLSearchParams","append","modelId","commitStrategy","audioFormat","vadSilenceThresholdSecs","vadThreshold","minSpeechDurationMs","minSilenceDurationMs","languageCode","includeTimestamps","queryString","microphone","uri","streamFromMicrophone","TARGET_SAMPLE_RATE","_options$microphone","_options$microphone$e","_options$microphone2","_options$microphone$n","_options$microphone3","_options$microphone$a","_options$microphone4","_options$microphone$c","_options$microphone5","_stream$getAudioTrack","trackSettings","getAudioTracks","getSettings","streamSampleRate","scribeNode","inputSampleRate","outputSampleRate","binary","Conversation"],"mappings":"wUA+DA,MAAMA,EAAuB,IAAIC,WAAW,SAE/BC,EASD,qBAAOC,CAAeC,GAC9B,OAAAC,EACEC,CAAAA,YAAa,CAAA,EACbC,UAAWA,OACXC,QAASA,OACTC,aAAcA,OACdC,QAASA,OACTC,UAAWA,OACXC,QAASA,OACTC,aAAcA,OACdC,eAAgBA,OAChBC,wBAAyBA,OACzBC,eAAgBA,QACbZ,EAEP,CAEAa,WAAAA,CACqBC,EACAC,GAA0B,IAAAC,EAD1BF,KAAAA,KAAAA,aACAC,EAAAA,KAAAA,gBA3BXE,EAAAA,KAAAA,uBAAyB,EAACC,KAC1BC,KAAa,YAAWD,KACxBE,OAAiB,aACjBC,KAAAA,OAAS,OACTC,eAAiB,EAACJ,KAClBK,oBAAsB,EACtBC,KAAAA,iBAAkB,EAoCpBC,KAAAA,sBAAwBC,eAAOC,GACjB,cAAhBX,EAAKI,QAA0C,eAAhBJ,EAAKI,SACxCJ,EAAKY,aAAa,uBACZZ,EAAKa,mBACXb,EAAKY,aAAa,gBACdZ,EAAKF,QAAQT,cACfW,EAAKF,QAAQT,aAAasB,GAE9B,EA6NQpB,KAAAA,UAAYmB,eAAOI,GACzB,OAAQA,EAAYC,MAClB,IAAK,eAEH,YADAf,EAAKgB,mBAAmBF,GAG1B,IAAK,iBAEH,YADAd,EAAKiB,oBAAoBH,GAG3B,IAAK,kBAEH,YADAd,EAAKkB,qBAAqBJ,GAG5B,IAAK,oCAEH,YADAd,EAAKmB,6BAA6BL,GAGpC,IAAK,mBACH,UACQd,EAAKoB,qBAAqBN,EAClC,CAAE,MAAOO,GACPrB,EAAKV,QACH,kDAAkD+B,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,KAClG,CACEI,eAAgBX,EAAYY,iBAAiBC,UAC7CC,WAAYd,EAAYY,iBAAiBG,cAG/C,CACA,OAEF,IAAK,QAEH,YADA7B,EAAK8B,YAAYhB,GAInB,IAAK,YAEH,YADAd,EAAK+B,eAAejB,GAItB,IAAK,OAOH,YANAd,EAAKD,WAAWiC,YAAY,CAC1BjB,KAAM,OACNkB,SAAUnB,EAAYoB,WAAWD,WAOrC,IAAK,gBAEH,YADAjC,EAAKmC,kBAAkBrB,GAIzB,IAAK,wBAEH,YADAd,EAAKoC,0BAA0BtB,GAIjC,IAAK,qBAEH,YADAd,EAAKqC,uBAAuBvB,GAI9B,IAAK,sBAEH,YADAd,EAAKsC,wBAAwBxB,GAI/B,IAAK,mCAEH,YADAd,EAAKuC,2BAA2BzB,GAIlC,IAAK,0BAEH,YADAd,EAAKwC,4BAA4B1B,GAInC,IAAK,2BAEH,YADAd,EAAKyC,4BAA4B3B,GAInC,IAAK,QAEH,YADAd,EAAK0C,iBAAiB5B,GAIxB,QAIE,YAHId,EAAKF,QAAQV,SACfY,EAAKF,QAAQV,QAAQ0B,IAK7B,EAiBO6B,KAAAA,UAAY,EAAGtC,aACpBH,KAAKG,OAASA,GA1WKH,KAAOJ,QAAPA,EACAI,KAAUH,WAAVA,EAEfG,KAAKJ,QAAQX,WACfe,KAAKJ,QAAQX,UAAU,CAAEyD,eAAgB7C,EAAW6C,iBAEtD1C,KAAKH,WAAWR,UAAUW,KAAKX,WAC/BW,KAAKH,WAAWV,aAAaa,KAAKO,uBAClCP,KAAKH,WAAWN,aAAaU,GAAQD,KAAK2C,WAAW1C,IACrDD,KAAKU,aAAa,YACpB,CAEOkC,UAAAA,GACL,OAAW5C,KAACO,sBAAsB,CAAEsC,OAAQ,QAC9C,CAYU,sBAAMlC,GACdX,KAAKH,WAAWiD,OAClB,CAEUH,UAAAA,CAAW1C,GACfA,IAASD,KAAKC,OAChBD,KAAKC,KAAOA,EACRD,KAAKJ,QAAQL,cACfS,KAAKJ,QAAQL,aAAa,CAAEU,SAGlC,CAEUS,YAAAA,CAAaR,GACjBA,IAAWF,KAAKE,SAClBF,KAAKE,OAASA,EACVF,KAAKJ,QAAQJ,gBACfQ,KAAKJ,QAAQJ,eAAe,CAAEU,WAGpC,CAEU6C,qBAAAA,GACR,MAAMzC,EAAkBN,KAAKI,iBAAmBJ,KAAKK,oBACjDL,KAAKM,kBAAoBA,IAC3BN,KAAKM,gBAAkBA,EACnBN,KAAKJ,QAAQH,yBACfO,KAAKJ,QAAQH,wBAAwB,CAAEa,oBAG7C,CAEUQ,kBAAAA,CAAmBkC,GACvBA,EAAMC,qBACRjD,KAAKD,uBAAyBiD,EAAMC,mBAAmBlB,SAEnD/B,KAAKJ,QAAQF,gBACfM,KAAKJ,QAAQF,eAAe,CAC1BqC,SAAUiB,EAAMC,mBAAmBlB,WAI3C,CAEUhB,mBAAAA,CAAoBiC,GACxBhD,KAAKJ,QAAQP,WACfW,KAAKJ,QAAQP,UAAU,CACrB6D,OAAQ,KACRC,KAAM,QACN9B,QAAS2B,EAAMI,qBAAqBC,gBAG1C,CAEUrC,oBAAAA,CAAqBgC,GACzBhD,KAAKJ,QAAQP,WACfW,KAAKJ,QAAQP,UAAU,CACrB6D,OAAQ,OACRC,KAAM,OACN9B,QAAS2B,EAAMM,yBAAyBC,iBAG9C,CAEUtC,4BAAAA,CACR+B,GAEIhD,KAAKJ,QAAQV,SACfc,KAAKJ,QAAQV,QAAQ,CACnB2B,KAAM,2BACN2C,SACER,EAAMS,wCACHC,0BAGX,CAEU7B,cAAAA,CAAemB,GACnBhD,KAAKJ,QAAQ+D,YACf3D,KAAKJ,QAAQ+D,WAAW,CACtBC,SAAUZ,EAAMa,gBAAgBC,WAGtC,CAEU,0BAAM5C,CAAqB8B,GACnC,GACEe,OAAOC,UAAUC,eAAeC,KAC9BlE,KAAKJ,QAAQZ,YACbgE,EAAMxB,iBAAiBC,WAGzB,IAAI0C,IAAAA,EACF,MAAMC,EAGH,OAHSD,QACHnE,KAAKJ,QAAQZ,YAAYgE,EAAMxB,iBAAiBC,WACrDuB,EAAMxB,iBAAiB6C,aACxBF,EAAK,oCAGFG,EACc,iBAAXF,EAAsBG,KAAKC,UAAUJ,GAAU9C,OAAO8C,GAE/DpE,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcqB,EAAMxB,iBAAiBG,aACrCyC,OAAQE,EACRG,UAAU,GAEd,CAAE,MAAOC,GACP1E,KAAKZ,QACH,sDAAuDsF,MAAAA,OAAAA,EAAAA,EAAarD,UACpE,CACEE,eAAgByB,EAAMxB,iBAAiBC,YAG3CzB,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcqB,EAAMxB,iBAAiBG,aACrCyC,OAAQ,iCAAkCM,MAAAA,OAAAA,EAAAA,EAAarD,UACvDoD,UAAU,GAEd,KACK,CACL,GAAIzE,KAAKJ,QAAQ+E,0BAGf,YAFA3E,KAAKJ,QAAQ+E,0BAA0B3B,EAAMxB,kBAK/CxB,KAAKZ,QACH,yBAAyB4D,EAAMxB,iBAAiBC,qCAChD,CACEF,eAAgByB,EAAMxB,iBAAiBC,YAG3CzB,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcqB,EAAMxB,iBAAiBG,aACrCyC,OAAQ,yBAAyBpB,EAAMxB,iBAAiBC,qCACxDgD,UAAU,GAEd,CACF,CAEU7C,WAAAA,CAAYoB,GAAsB,CAElCf,iBAAAA,CAAkBe,GACtBhD,KAAKJ,QAAQgF,eACf5E,KAAKJ,QAAQgF,cAAc5B,EAAM6B,cAErC,CAEU3C,yBAAAA,CAA0Bc,GAC9BhD,KAAKJ,QAAQkF,uBACf9E,KAAKJ,QAAQkF,sBAAsB9B,EAAM+B,sBAE7C,CAEU5C,sBAAAA,CAAuBa,GAC3BhD,KAAKJ,QAAQoF,oBACfhF,KAAKJ,QAAQoF,mBAAmBhC,EAAMiC,mBAE1C,CAEU7C,uBAAAA,CAAwBY,GACY,aAAxCA,EAAMkC,oBAAoBzD,WAC5BzB,KAAKO,sBAAsB,CACzBsC,OAAQ,QACRsC,QAAS,IAAIC,WAAW,WAAY,CAAEvC,OAAQ,2BAI9C7C,KAAKJ,QAAQyF,qBACfrF,KAAKJ,QAAQyF,oBAAoBrC,EAAMkC,oBAE3C,CAEU7C,0BAAAA,CAA2BW,GAC/BhD,KAAKJ,QAAQ0F,wBACftF,KAAKJ,QAAQ0F,uBACXtC,EAAMuC,uCAGZ,CAEUjD,2BAAAA,CAA4BU,GAChChD,KAAKJ,QAAQ4F,yBACfxF,KAAKJ,QAAQ4F,wBAAwBxC,EAAMyC,8BAE/C,CAEUlD,2BAAAA,CAA4BS,GAChChD,KAAKJ,QAAQ8F,yBACf1F,KAAKJ,QAAQ8F,wBAAwB1C,EAAM2C,mBAE/C,CAEUnD,gBAAAA,CAAiBQ,GACzB,MAAM4C,EAAY5C,EAAM6C,YAAYC,WAC9BzE,EACJ2B,EAAM6C,YAAYxE,SAAW2B,EAAM6C,YAAYhD,QAAU,gBAEzC,0BAAd+C,EASJ5F,KAAKZ,QAAQ,iBAAiBiC,IAAW,CACvCuE,YACAG,KAAM/C,EAAM6C,YAAYE,KACxBC,aAAchD,EAAM6C,YAAYI,cAChCxF,QAASuC,EAAM6C,YAAYpF,UAZ3BT,KAAKO,sBAAsB,CACzBsC,OAAQ,QACRxB,QAASA,EACT8D,QAAS,IAAIe,MAAM,0BAWzB,CAuGQ9G,OAAAA,CAAQiC,EAAiB8D,GAC/BgB,QAAQhF,MAAME,EAAS8D,GACnBnF,KAAKJ,QAAQR,SACfY,KAAKJ,QAAQR,QAAQiC,EAAS8D,EAElC,CAEOiB,KAAAA,GACL,OAAWpG,KAACH,WAAW6C,cACzB,CAEO2D,MAAAA,GACL,MAAuB,cAAZrG,KAACE,MACd,CAMOoG,WAAAA,CAAYC,GACjBvG,KAAKH,WAAWyG,YAAYC,EAC9B,CAEOC,yBAAAA,GACL,OAAO9H,CACT,CAEO+H,0BAAAA,GACL,OAAO/H,CACT,CAEOgI,cAAAA,GACL,OAAO,CACT,CAEOC,eAAAA,GACL,OAAO,CACT,CAEOC,YAAAA,CAAaC,GACb7G,KAAKM,iBASVN,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,WACNiG,MAAOD,EAAO,OAAS,UACvB9E,SAAU/B,KAAKI,iBAEjBJ,KAAKK,oBAAsBL,KAAKI,eAChCJ,KAAK+C,yBAdHoD,QAAQY,KACuB,IAA7B/G,KAAKK,oBACD,8DACA,iFAYV,CAEO2G,oBAAAA,CAAqBC,GAC1BjH,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,oBACNoG,QAEJ,CAEOC,eAAAA,CAAgBD,GACrBjH,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,eACNoG,QAEJ,CAEOE,gBAAAA,GACLnH,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,iBAEV,CAEOuG,yBAAAA,CAA0B1F,EAAoB2F,GACnDrH,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,2BACNc,aAAcD,EACd4F,YAAaD,GAEjB,QClboBE,EAYpB5H,WAAAA,CAAY6H,EAAgD,CAAE,GAPpDC,KAAAA,MAA+B,QAC/BC,qBAAoD,KAAI1H,KACxD2H,qBAAoD,KACpDC,KAAAA,kBAA8C,KAAI5H,KAClD6H,qBAAsD,KACtD3I,KAAAA,aAGR,EAAAc,KAAKd,QAAUsI,EAAOtI,OACxB,CAEU4I,KAAAA,CAAMC,GACV/H,KAAKd,SAASc,KAAKd,QAAQ6I,EACjC,CAMO1I,SAAAA,CAAU2I,GACfhI,KAAK4H,kBAAoBI,EACzB,MAAMP,EAAQzH,KAAKyH,MACnBzH,KAAKyH,MAAQ,GAETA,EAAMQ,OAAS,GAGjBC,eAAe,KACbT,EAAMU,QAAQH,IAGpB,CAEO7I,YAAAA,CAAa6I,GAClBhI,KAAK2H,qBAAuBK,EAC5B,MAAMvH,EAAUT,KAAK0H,qBACjBjH,GAGFyH,eAAe,KACbF,EAASvH,IAGf,CAEOlB,YAAAA,CAAayI,GAClBhI,KAAK6H,qBAAuBG,CAC9B,CAEUrF,UAAAA,CAAW1C,GAAUmI,IAAAA,EAC7BA,OAAAA,EAAIpI,KAAC6H,uBAALO,EAAAlE,UAA4BjE,EAC9B,CAEUoI,UAAAA,CAAW5H,GACa6H,IAAAA,EAA3BtI,KAAK0H,uBACR1H,KAAK0H,qBAAuBjH,SAC5B6H,EAAAtI,KAAK2H,uBAALW,EAAApE,KAAAlE,KAA4BS,GAEhC,CAEU8H,aAAAA,CAAc3H,GAClBZ,KAAK4H,kBACP5H,KAAK4H,kBAAkBhH,GAEvBZ,KAAKyH,MAAMe,KAAK5H,EAEpB,EAGc,SAAA6H,EAAYC,GAC1B,MAAOC,EAAYC,GAAkBF,EAAOG,MAAM,KAClD,IAAK,CAAC,MAAO,QAAQC,SAASH,GAC5B,MAAM,IAAIvH,MAAM,mBAAmBsH,KAGrC,MAAMK,EAAaC,OAAOC,SAASL,GACnC,GAAII,OAAOE,MAAMH,GACf,MAAU,IAAA3H,MAAM,wBAAwBwH,KAG1C,MAAO,CACLF,OAAQC,EACRI,aAEJ,CChLa,MAAAI,EAAkB,SCyFf,SAAAC,EAAmBpG,GACjC,QAASA,EAAMnC,IACjB,CCzFa,MAAAwI,EACX,sCAEI,SAAUC,EACd9B,GAAqB,IAAA+B,EAErB,MAAMC,EAA4C,CAChD3I,KAAMwI,GAGcI,IAAAA,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAsCtB,OAtCIxC,EAAOyC,YACTT,EAAeU,6BAA+B,CAC5CC,MAAO,CACLC,OAA8B,OAAxBX,EAAEjC,EAAOyC,UAAUE,YAAK,EAAtBV,EAAwBW,OAChCC,cAAqC,OAAxBX,EAAElC,EAAOyC,UAAUE,YAAK,EAAtBT,EAAwBY,aACvCC,SAAgC,OAAxBZ,EAAEnC,EAAOyC,UAAUE,YAAK,EAAtBR,EAAwBY,UAEpCC,IAAK,CACHC,SAAUb,OAAFA,EAAEpC,EAAOyC,UAAUO,UAAjBZ,EAAAA,EAAsBc,QAChCC,MAAOd,OAAFA,EAAErC,EAAOyC,UAAUO,UAAjBX,EAAAA,EAAsBc,MAC7BC,UAA+B,OAAtBd,EAAEtC,EAAOyC,UAAUO,UAAG,EAApBV,EAAsBc,UACjCC,iBAAsC,OAAtBd,EAAEvC,EAAOyC,UAAUO,UAAG,EAApBT,EAAsBe,iBAE1CC,aAAc,CACZC,UAAWhB,OAAFA,EAAExC,EAAOyC,UAAUc,mBAAjBf,EAAAA,EAA+BiB,YAK5CzD,EAAO0D,qBACT1B,EAAe2B,sBAAwB3D,EAAO0D,oBAG5C1D,EAAO4D,mBACT5B,EAAe6B,kBAAoB7D,EAAO4D,kBAGxC5D,EAAO8D,SACT9B,EAAe+B,QAAU/D,EAAO8D,eAGlC/B,EAAI/B,EAAOyC,YAAPV,EAAkBiC,SACpBhC,EAAeiC,YAAc,CAC3BvI,OAAQsE,EAAOyC,UAAUuB,OAAOtI,OAChCwI,QAASlE,EAAOyC,UAAUuB,OAAOE,UAI9BlC,CACT,CCpDM,MAAOmC,UAA+BvK,MAI1CzB,WAAAA,CACE0B,EACAzB,GAEAgM,MAAMvK,GAASrB,KAPD6L,eAAS,EAAA7L,KACT8L,iBAAW,EAOzB9L,KAAK+L,KAAO,yBACZ/L,KAAK6L,UAAYjM,MAAAA,OAAAA,EAAAA,EAASiM,UAC1B7L,KAAK8L,YAAclM,MAAAA,OAAAA,EAAAA,EAASkM,WAC9B,ECOI,MAAOE,UAA4BzE,EAKvC5H,WAAAA,CACmBsM,EACjBvJ,EACAwJ,EACAC,GAEAP,QAAQ5L,KALSiM,mBALHvJ,oBAAc,EAAA1C,KACdkM,iBAAW,EAAAlM,KACXmM,kBAAY,EAGTnM,KAAMiM,OAANA,EAMjBjM,KAAK0C,eAAiBA,EACtB1C,KAAKkM,YAAcA,EACnBlM,KAAKmM,aAAeA,EAEpBnM,KAAKiM,OAAOG,iBAAiB,QAASpJ,IAIpCqJ,WACE,IACErM,KAAKqI,WAAW,CACdxF,OAAQ,QACRxB,QAAS,mDACT8D,QAASnC,IAEb,KAIJhD,KAAKiM,OAAOG,iBAAiB,QAASpJ,IACpChD,KAAKqI,WACY,MAAfrF,EAAM+C,KACF,CACElD,OAAQ,QACRsC,QAASnC,EACT6I,UAAW7I,EAAM+C,KACjB+F,YAAa9I,EAAMH,aAAUyJ,GAE/B,CACEzJ,OAAQ,QACRxB,QACE2B,EAAMH,QAAU,2CAClBsC,QAASnC,EACT6I,UAAW7I,EAAM+C,KACjB+F,YAAa9I,EAAMH,aAAUyJ,MAKvCtM,KAAKiM,OAAOG,iBAAiB,UAAWpJ,IACtC,IACE,MAAMpC,EAAc2D,KAAKgI,MAAMvJ,EAAMwJ,MACrC,IAAKpD,EAAmBxI,GAMtB,YALAZ,KAAK8H,MAAM,CACTjH,KAAM,gBACNQ,QAAS,gCACTmL,KAAMxJ,EAAMwJ,OAIhBxM,KAAKuI,cAAc3H,EACrB,CAAE,MAAOO,GACPnB,KAAK8H,MAAM,CACTjH,KAAM,gBACNQ,QAAS,iCACTF,MAAOA,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,GACvDqL,KAAMxJ,EAAMwJ,MAEhB,GAEJ,CAEO,mBAAaC,CAClBjF,GAEA,IAAIyE,EAA2B,KAE/B,IAAIS,IAAAA,EAAAnD,EAAAoD,EACF,MAAMC,EAAsBF,OAAhBA,EAAGlF,EAAOoF,QAAMF,EAnFX,0BAoFjB,IAAIG,EAEJ,MAAMnB,UAAUnC,EAAA/B,EAAOyC,mBAASV,EAAhBA,EAAkBiC,eAAlBjC,EAA0BmC,UAAWvC,EAC/CjG,GAAyB,OAAhByJ,EAAAnF,EAAOyC,mBAAS0C,EAAhBA,EAAkBnB,eAAlBmB,EAA0BzJ,SAAU,SAEnD,GAAIsE,EAAOsF,UAAW,CACpB,MAAMC,EAAYvF,EAAOsF,UAAUhE,SAAS,KAAO,IAAM,IACzD+D,EAAM,GAAGrF,EAAOsF,YAAYC,WAAmB7J,aAAkBwI,GACnE,MACEmB,EAAM,GAAGD,qCAA4BpF,EAAOwF,kBAAkB9J,aAAkBwI,IAGlF,MAAMuB,EAAY,CAjGF,UAkGZzF,EAAO0F,eACTD,EAAUzE,KAAK,UAAUhB,EAAO0F,iBAElCjB,EAAS,IAAIkB,UAAUN,EAAKI,GAE5B,MAAMG,QAA2B,IAAIC,QAEnC,CAACC,EAASC,KACVtB,EAAQG,iBACN,OACA,SAAKoB,EACH,MAAMhE,EAAiBF,EAAmB9B,GAE1CgG,OAAAA,EAAAvB,IAAAuB,EAAQC,KAAKlJ,KAAKC,UAAUgF,KAE9B,CAAEkE,MAAM,IAGVzB,EAAQG,iBAAiB,QAASpJ,IAIhCqJ,WACE,IACEkB,EACE,IAAI5B,EACF,qDAGN,KAIJM,EAAQG,iBAAiB,QAAUpJ,IAMjCuK,EACE,IAAI5B,EALJ3I,EAAMH,SACU,MAAfG,EAAM+C,KACH,kEACA,uEAEgC,CAClC8F,UAAW7I,EAAM+C,KACjB+F,YAAa9I,EAAMH,aAAUyJ,OAKnCL,EAAQG,iBACN,UACCpJ,IACC,MAAM3B,EAAUkD,KAAKgI,MAAMvJ,EAAMwJ,MAE5BpD,EAAmB/H,KAIH,qCAAjBA,EAAQR,KACVyM,EAAQjM,EAAQkE,wCAEhBY,QAAQY,KACN,0DAIN,CAAE2G,MAAM,OAINC,gBACJA,EAAeC,0BACfA,EAAyBC,wBACzBA,GACET,EAEElB,EAAczD,QAAYoF,EAAAA,EAA2B,aACrD1B,EAAe1D,EAAYmF,GAEjC,WAAW5B,EACTC,EACA0B,EACAzB,EACAC,EAEJ,CAAE,MAAOhL,GAAO2M,IAAAA,EAEd,aADAA,EAAA7B,IAAA6B,EAAQhL,QACF3B,CACR,CACF,CAEO2B,KAAAA,GACL9C,KAAKiM,OAAOnJ,MAAM,IAAM,0BAC1B,CAEOhB,WAAAA,CAAYT,GACjBrB,KAAKiM,OAAOwB,KAAKlJ,KAAKC,UAAUnD,GAClC,CAEO,iBAAMiF,CAAYC,GACvBJ,QAAQY,KACN,gDAAgDR,8CAEpD,ECtNI,SAAUwH,EAAoBC,GAClC,MAAMC,EAAS,IAAItP,WAAWqP,GAG9B,OADmBE,OAAOC,KAAK7M,OAAO8M,gBAAgBH,GAExD,UAEgBI,EAAoBC,GAClC,MAAMC,EAAeL,OAAOM,KAAKF,GAC3BG,EAAMF,EAAatG,OACnByG,EAAQ,IAAI/P,WAAW8P,GAC7B,IAAK,IAAIE,EAAI,EAAGA,EAAIF,EAAKE,IACvBD,EAAMC,GAAKJ,EAAaK,WAAWD,GAErC,OAAOD,EAAMT,MACf,CCfA,MAAMY,EAAW,IAAIC,IAEL,SAAAC,EAA0BhD,EAAciD,GACtD,OAAcC,MAAAA,EAAuBC,KACnC,MAAMC,EAAYN,EAASO,IAAIrD,GAC/B,GAAIoD,EACF,OAAOF,EAAQI,UAAUF,GAI3B,GAAID,EACF,IAGE,aAFMD,EAAQI,UAAUH,QACxBL,EAASS,IAAIvD,EAAMmD,EAErB,CAAE,MAAO/N,GACP,UAAUC,MACR,sBAAsB2K,+BAAkCmD,aAAgB/N,IAE5E,CAGF,MAAMoO,EAAO,IAAIC,KAAK,CAACR,GAAa,CAAEnO,KAAM,2BACtC4O,EAAUC,IAAIC,gBAAgBJ,GACpC,IAGE,aAFMN,EAAQI,UAAUI,QACxBZ,EAASS,IAAIvD,EAAM0D,EAErB,CAAE,MAAAG,GACAF,IAAIG,gBAAgBJ,EACtB,CAEA,IAIE,MACMK,EAAY,sCADH3B,KAAKa,WAEdC,EAAQI,UAAUS,GACxBjB,EAASS,IAAIvD,EAAM+D,EACrB,CAAE,MAAO3O,GACP,MAAU,IAAAC,MACR,sBAAsB2K,8IAE1B,EAEJ,CC3CO,MAAMgE,EAAwBhB,EACnC,oBAEA,g2HCkCI,MAAOiB,UAAyBzI,EAepC5H,WAAAA,CACEsQ,EACAvN,EACAwJ,EACAC,EACA3E,EAAgD,CAAA,GAEhDoE,MAAMpE,GAAQxH,KArBT0C,oBAAc,EAAA1C,KACLkM,iBAAW,EAAAlM,KACXmM,kBAAY,EAAAnM,KAEpBiQ,UAAI,EAAAjQ,KACJkQ,aAAc,EACdC,KAAAA,aAAe,EACfC,KAAAA,oBAA2C,KAAIpQ,KAC/CqQ,cAAoC,GAAErQ,KACtCsQ,eAAgC,KAEhCC,KAAAA,eAAsC,KACtCC,KAAAA,oBAAsD,KAU5DxQ,KAAKiQ,KAAOA,EACZjQ,KAAK0C,eAAiBA,EACtB1C,KAAKkM,YAAcA,EACnBlM,KAAKmM,aAAeA,EAEpBnM,KAAKyQ,yBACP,CAEO,mBAAahE,CAClBjF,GAEA,IAAIkJ,EAGJ,GAAI,sBAAuBlJ,GAAUA,EAAOkJ,kBAE1CA,EAAoBlJ,EAAOkJ,sBAClB,MAAA,YAAalJ,KAAUA,EAAOwF,QAkCvC,MAAM,IAAI5L,MACR,yEAjCF,IAAImI,IAAAA,EAAAoD,EAAAD,EACF,MAAMhB,GAA0BnC,OAAhBA,EAAA/B,EAAOyC,YAAiB,OAARV,EAAhBA,EAAkBiC,aAAM,EAAxBjC,EAA0BmC,UAAWvC,EAC/CjG,GAAyB,OAAhByJ,EAAAnF,EAAOyC,YAAiB,OAAR0C,EAAhBA,EAAkBnB,aAAM,EAAxBmB,EAA0BzJ,SAAU,SAG7C2J,EAAM,GAvDOD,EAqDe,OAAhBF,EAAGlF,EAAOoF,QAAMF,EAxDjB,4BAIhBE,EAAO+D,QAAQ,YAAa,qDAsDkCnJ,EAAOwF,kBAAkB9J,aAAkBwI,IACpGlI,QAAiBoN,MAAM/D,GAE7B,IAAKrJ,EAASqN,GACZ,MAAM,IAAIzP,MACR,2BAA2BoC,EAAStD,UAAUsD,EAASsN,cAO3D,GAFAJ,SADmBlN,EAASuN,QACHC,OAEpBN,EACH,MAAU,IAAAtP,MAAM,0CAEpB,CAAE,MAAOD,GACP,IAAI8P,EAAM9P,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,GAM1D,MALIA,aAAiBC,OAASD,EAAME,QAAQyH,SAAS,SACnDmI,EACE,gGAGE,IAAI7P,MACR,gDAAgDoG,EAAOwF,YAAYiE,IAEvE,CAKF,CArFJ,IAA2BrE,EAuFvB,MAAMqD,EAAO,IAAIiB,EAEjB,IAEE,MAAMxO,EAAiB,QAAQyO,KAAKC,QAC9BlF,EAAczD,EAAY,aAC1B0D,EAAe1D,EAAY,aAC3B5I,EAAa,IAAImQ,EACrBC,EACAvN,EACAwJ,EACAC,EACA3E,GAII6J,EAAa7J,EAAO6J,YA3GD,kCA6HVC,IAAAA,QAfTrB,EAAKsB,QAAQF,EAAYX,SAGrB,IAAArD,QAAcC,IACtB,GAAIzN,EAAWqQ,YACb5C,QACK,CACL,MAAMkE,EAAcA,KAClBvB,EAAKwB,IAAIC,EAAUC,UAAWH,GAC9BlE,KAEF2C,EAAK2B,GAAGF,EAAUC,UAAWH,EAC/B,IAGEvB,EAAKlE,OACPlM,EAAW6C,gBAC6B,OAAtC4O,EAAArB,EAAKlE,KAAK8F,MAAM,6BAAsB,EAAtCP,EAAyC,KAAMrB,EAAKlE,MAInDvE,EAAOyD,gBACJgF,EAAK6B,iBAAiBC,sBAAqB,GAGnD,MAAMvI,EAAiBF,EAAmB9B,GAS1C,OAPA3H,EAAWiI,MAAM,CACfjH,KAAMwI,EACNhI,QAASmI,UAGL3J,EAAWiC,YAAY0H,GAEtB3J,CACT,CAAE,MAAOsB,GAEP,YADM8O,EAAK5H,aACLlH,CACR,CACF,CAEQsP,uBAAAA,GAAuB3Q,IAAAA,EAC7BE,KAAAA,KAAKiQ,KAAK2B,GAAGF,EAAUC,UAAWnR,iBAChCV,EAAKoQ,aAAc,EACnB/J,QAAQ4B,KAAK,wBACf,GAEA/H,KAAKiQ,KAAK2B,GAAGF,EAAUM,aAAcnP,IACnC7C,KAAKkQ,aAAc,EACnBlQ,KAAKqI,WAAW,CACdxF,OAAQ,QACRsC,QAAS,IAAIC,WAAW,QAAS,CAAEvC,OAAQA,MAAAA,OAAAA,EAAAA,EAAQoP,iBAIvDjS,KAAKiQ,KAAK2B,GAAGF,EAAUQ,uBAAwBC,IACzCA,IAAUC,EAAgBJ,eAC5BhS,KAAKkQ,aAAc,EACnBlQ,KAAKqI,WAAW,CACdxF,OAAQ,QACRxB,QAAS,uCAAuC8Q,IAChDhN,QAAS,IAAIe,MAAM,iCAMzBlG,KAAKiQ,KAAK2B,GACRF,EAAUW,aACV,CAACC,EAAqBC,KACpB,IACE,MAAMlR,EAAUkD,KAAKgI,OAAM,IAAIiG,aAAcC,OAAOH,IAGpD,GAAqB,UAAjBjR,EAAQR,KACV,OAGEuI,EAAmB/H,GACrBrB,KAAKuI,cAAclH,GAEnB8E,QAAQY,KAAK,iCAAkC1F,EAEnD,CAAE,MAAOF,GACPgF,QAAQY,KAAK,yCAA0C5F,GACvDgF,QAAQY,KAAK,gBAAgB,IAAIyL,aAAcC,OAAOH,GACxD,IAIJtS,KAAKiQ,KAAK2B,GACRF,EAAUgB,gBACVlS,eACEmS,EACAC,EACAC,GAEA,GACEF,EAAMG,OAASC,EAAMC,KAAKC,OAC1BJ,EAAYK,SAASpK,SAAS,SAC9B,CAEA,MAAMqK,EAAmBR,EACnBS,EAAeD,EAAiBE,SAKtC,GAJAD,EAAaE,UAAW,EACxBF,EAAaG,UAAW,EAGpBzT,EAAKwQ,gBAAkB8C,EAAaI,UACtC,UACQJ,EAAaI,UAAU1T,EAAKwQ,eACpC,CAAE,MAAOnP,GACPgF,QAAQY,KACN,qDACA5F,EAEJ,CAIFiS,EAAaK,MAAMC,QAAU,OAC7BC,SAASC,KAAKC,YAAYT,GAG1BtT,EAAKuQ,cAAc7H,KAAK4K,GAGU,IAA9BtT,EAAKuQ,cAAcpI,SAET,MAAZnI,EAAKZ,SAALY,EAAKZ,QAAU,CAAE2B,KAAM,+BAInBf,EAAKgU,kBAAkBX,EAC/B,CACF,GAGFnT,KAAKiQ,KAAK2B,GACRF,EAAUqC,sBACVvT,eAAOwT,GAEHlU,EAAK6C,WADHqR,EAAS/L,OAAS,GAElB+L,EAAS,GAAGd,SAASe,WAAW,SAAW,WAG7B,YAEpB,GAGFjU,KAAKiQ,KAAK2B,GACRF,EAAUwC,wBACTrB,IAAkC,IAAAsB,EAC7BA,OAAJA,EAAItB,EAAYK,WAAZiB,EAAsBF,WAAW,UACnCjU,KAAKqI,WAAW,CACdxF,OAAQ,QACRsC,QAAS,IAAIC,WAAW,QAAS,CAAEvC,OAAQ,0BAKrD,CAEOC,KAAAA,GACL,GAAI9C,KAAKkQ,YAAa,CACpB,IAEElQ,KAAKiQ,KAAK6B,iBAAiBsC,uBAAuBjM,QAChDkM,IACMA,EAAY1B,OACd0B,EAAY1B,MAAM2B,QAI1B,CAAE,MAAOnT,GACPgF,QAAQY,KAAK,+BAAgC5F,EAC/C,CAGInB,KAAKoQ,sBACPpQ,KAAKoQ,oBAAoBtN,QAAQyR,MAAMpT,IACrCgF,QAAQY,KAAK,uCAAwC5F,KAEvDnB,KAAKoQ,oBAAsB,MAI7BpQ,KAAKqQ,cAAclI,QAAQqM,IACrBA,EAAQC,YACVD,EAAQC,WAAWC,YAAYF,KAGnCxU,KAAKqQ,cAAgB,GAErBrQ,KAAKiQ,KAAK5H,YACZ,CACF,CAEO,iBAAMvG,CAAYT,GACvB,GAAKrB,KAAKkQ,aAAgBlQ,KAAKiQ,KAAK6B,kBAQpC,KAAI,qBAAsBzQ,GAK1B,IACE,MACMmL,GADU,IAAImI,aACCC,OAAOrQ,KAAKC,UAAUnD,UAErCrB,KAAKiQ,KAAK6B,iBAAiB+C,YAAYrI,EAAM,CAAEsI,UAAU,GACjE,CAAE,MAAO3T,GACPnB,KAAK8H,MAAM,CACTjH,KAAM,qBACNQ,QAAS,CACPA,UACAF,WAGJgF,QAAQhF,MAAM,qCAAsCA,EACtD,OA1BEgF,QAAQY,KACN,kEA0BN,CAGOgO,OAAAA,GACL,OAAO/U,KAAKiQ,IACd,CAEO,iBAAM3J,CAAYC,GACvB,IAAKvG,KAAKkQ,cAAgBlQ,KAAKiQ,KAAK6B,iBAIlC,YAHA3L,QAAQY,KACN,2EAMJ,MAAMiO,EAAsBhV,KAAKiQ,KAAK6B,iBAAiBmD,oBACrDlC,EAAMmC,OAAOC,YAGf,SAAIH,GAAAA,EAAqBrC,MACvB,IAEMpM,QACIyO,EAAoBrC,MAAMyC,aAE1BJ,EAAoBrC,MAAM0C,QAEpC,CAAE,MAAOC,SAEDtV,KAAKiQ,KAAK6B,iBAAiBC,sBAAsBxL,EACzD,YAGUvG,KAACiQ,KAAK6B,iBAAiBC,sBAAsBxL,EAE3D,CAEQ,uBAAMuN,CAAkBnB,GAC9B,IAEE,MAAM4C,EAAe,IAAIC,aACzBxV,KAAKoQ,oBAAsBmF,EAG3BvV,KAAKuQ,eAAiBgF,EAAaE,iBACnCzV,KAAKuQ,eAAemF,QAAU,KAC9B1V,KAAKuQ,eAAeoF,sBAAwB,GAG5C,MAAMC,EAAc,IAAIC,YAAY,CAAClD,EAAMmD,mBAGrC5S,EAASqS,EAAaQ,wBAAwBH,GAGpD1S,EAAOqO,QAAQvR,KAAKuQ,sBAEdR,EAAsBwF,EAAaS,cACzC,MAAM/G,EAAU,IAAIgH,iBAAiBV,EAAc,qBAGnDvV,KAAKuQ,eAAegB,QAAQtC,GAG5BA,EAAQiH,KAAKC,YAAY,CACvBtV,KAAM,YACN6H,OAAQ1I,KAAKmM,aAAazD,OAC1BK,WAAY/I,KAAKmM,aAAapD,aAIhCkG,EAAQiH,KAAKE,UAAapT,IACxB,MAAOqT,EAAWC,GAAatT,EAAMwJ,KAKrC,GAAI8J,EAFoB,IAES,CAE/B,MAAMC,EAAcxI,EAAoBsI,EAAUpI,QAG5CuI,EAAUxW,KAAKmQ,eAGrBnQ,KAAKuI,cAAc,CACjB1H,KAAM,QACN4V,YAAa,CACXC,cAAeH,EACfxU,SAAUyU,IAGhB,GAIFtT,EAAOqO,QAAQtC,EACjB,CAAE,MAAO9N,GACPgF,QAAQY,KAAK,kCAAmC5F,EAClD,CACF,CAEOwV,cAAAA,CAAexW,GACpBH,KAAKqQ,cAAclI,QAAQqM,IACzBA,EAAQrU,OAASA,GAErB,CAEO,0BAAMyW,CAAqBC,GAChC,KAAM,cAAeC,iBAAiB9S,WACpC,MAAM,IAAI5C,MAAM,8CAIlB,MAAM2V,EAAW/W,KAAKqQ,cAAc2G,IAAIxW,eAAMgU,GAC5C,UACQA,EAAQhB,UAAUqD,EAC1B,CAAE,MAAO1V,GAEP,MADAgF,QAAQhF,MAAM,2CAA4CA,GACpDA,CACR,CACF,SAEMkM,QAAQ4J,IAAIF,GAGlB/W,KAAKsQ,eAAiBuG,CACxB,CAEO,yBAAMK,CAAoBL,GAC/B,IAAK7W,KAAKkQ,cAAgBlQ,KAAKiQ,KAAK6B,iBAClC,MAAU,IAAA1Q,MACR,0EAIJ,IAEE,MAAM+V,EACJnX,KAAKiQ,KAAK6B,iBAAiBmD,oBAAoBlC,EAAMmC,OAAOC,YAG1DgC,MAAAA,GAAAA,EAA4BxE,cACxBwE,EAA2BxE,MAAM2B,aAC7BtU,KAACiQ,KAAK6B,iBAAiBsF,eAC/BD,EAA2BxE,QAK/B,MAAM0E,EAA0C,CAC9CR,SAAU,CAAES,MAAOT,GACnBU,kBAAkB,EAClBC,kBAAkB,EAClBC,iBAAiB,EACjBC,aAAc,CAAEC,MAAO,IAInBC,QAAmBC,EAAsBR,SAGzCrX,KAAKiQ,KAAK6B,iBAAiBgG,aAAaF,EAAY,CACxD7L,KAAM,aACN7I,OAAQ6P,EAAMmC,OAAOC,YAEzB,CAAE,MAAOhU,GACPgF,QAAQhF,MAAM,iCAAkCA,GAGhD,UACQnB,KAAKiQ,KAAK6B,iBAAiBC,sBAAqB,EACxD,CAAE,MAAOgG,GACP5R,QAAQhF,MACN,0DACA4W,EAEJ,CAEA,MAAM5W,CACR,CACF,CAEOsF,0BAAAA,GACL,OAAKzG,KAAKuQ,gBAEcyH,WAAnBxH,sBAALxQ,KAAKwQ,oBAAwB,IAAI7R,WAC/BqB,KAAKuQ,eAAe0H,oBAEtBjY,KAAKuQ,eAAe2H,qBAAqBlY,KAAKwQ,qBACnCxQ,KAACwQ,qBANyB,IAOvC,ECvhBKhQ,eAAe2X,EACpB3Q,GAEA,MAAM4Q,EAlBR,SAAiC5Q,GAE/B,OAAIA,EAAO4Q,eACF5Q,EAAO4Q,eAIZ,sBAAuB5Q,GAAUA,EAAOkJ,kBACnC,SAIF,WACT,CAKyB2H,CAAwB7Q,GAE/C,OAAQ4Q,GACN,IAAK,YACH,OAAOpM,EAAoBS,OAAOjF,GACpC,IAAK,SACH,OAAOwI,EAAiBvD,OAAOjF,GACjC,QACE,UAAUpG,MAAM,4BAA4BgX,KAElD,UCpCgBE,IACd,MACE,CACE,iBACA,mBACA,iBACA,OACA,SACA,QACAxP,SAASyP,UAAUC,WAEpBD,UAAUE,UAAU3P,SAAS,QAAU,eAAgB6K,QAE5D,gBCVsB+E,EACpBC,EAA2B,CACzBC,QAAS,EAETC,QAAS,MAGX,IAAIC,EAAQH,EAAYC,YACDG,EAAvB,GDKO,WAAWC,KAAKT,UAAUE,WCJ/BK,EAA2BC,OAAtBA,EAAGJ,EAAYE,SAAOE,EAAID,OACtBR,GAAAA,IAAe,KAAAW,EACxBH,EAAuBG,OAAlBA,EAAGN,EAAYO,KAAGD,EAAIH,CAC7B,CAEIA,EAAQ,SACA,IAAAzL,QAAQC,GAAWjB,WAAWiB,EAASwL,GAErD,OCfaK,UAAyBva,EAC7B,yBAAawa,CAClBxZ,GAEA,MAAMyZ,EAAcza,EAAiBC,eAAee,GAEhDyZ,EAAY7Z,gBACd6Z,EAAY7Z,eAAe,CAAEU,OAAQ,eAEnCmZ,EAAY5Z,yBACd4Z,EAAY5Z,wBAAwB,CAAEa,iBAAiB,IAErD+Y,EAAY9Z,cACd8Z,EAAY9Z,aAAa,CAAEU,KAAM,cAE/BoZ,EAAY5Z,yBACd4Z,EAAY5Z,wBAAwB,CAAEa,iBAAiB,IAGzD,IAAIT,EAAoC,KACxC,IAGE,aAFM6Y,EAAWW,EAAYC,iBAC7BzZ,QAAmBsY,EAAiBvY,GACzB,IAAAuZ,EAAiBE,EAAaxZ,EAC3C,CAAE,MAAOsB,GAAO,IAAAoY,EAKd,MAJIF,EAAY7Z,gBACd6Z,EAAY7Z,eAAe,CAAEU,OAAQ,iBAE7B,OAAVqZ,EAAA1Z,IAAA0Z,EAAYzW,QACN3B,CACR,CACF,EC1BF,MAGMqY,EAAqB,CACzBjC,kBAAkB,EAClBC,kBAAkB,EAElBC,iBAAiB,EAEjBC,aAAc,CAAEC,MAAO,UAGZ8B,EACJ,mBAAahN,EAAO1D,WACzBA,EAAUL,OACVA,EAAMgR,8BACNA,EAA6BC,cAC7BA,EAAaC,aACbA,EAAYC,kBACZA,IAEA,IAAI1U,EAA+B,KAC/B2U,EAAkC,KAEtC,IACE,MAAMla,EAAOb,EACXgK,CAAAA,WAAY,CAAE4O,MAAO5O,IAClByQ,GAGL,GAAIlB,KAAiBoB,EAA+B,CAClD,MAEMK,SADE7L,OAAOqK,UAAUyB,aAAaC,oBACDC,KACnCC,GAGa,eAAXA,EAAErH,MACF,CAAC,SAAU,YAAa,YAAYoH,KAAKE,GACvCD,EAAEE,MAAMC,cAAcxR,SAASsR,KAGjCL,IACFna,EAAQiX,SAAW,CAAEc,MAAOoC,EAAYlD,UAE5C,CAEI8C,IACF/Z,EAAQiX,SAAW4C,EAAMc,sBAAsBZ,IAGjD,MAAMa,EACJjC,UAAUyB,aAAaS,0BAA0B1R,WAEnD5D,EAAU,IAAI+I,OAAOsH,aACnBgF,EAA+B,CAAEzR,cAAe,CAAA,GAElD,MAAM2R,EAAWvV,EAAQsQ,iBACzB,IAAK+E,EAA8B,CAEjC,MAAMG,EAAmBd,GA3D/B,0GA4DY1U,EAAQ6Q,aAAa3G,UAAUsL,EACvC,OACM5K,EACJ5K,EAAQ6Q,aACR4D,MAAAA,OAAAA,EAAAA,EAAkC,mBAGpC,MAAMgB,EAAW7b,EAAA,CAAK8b,gBAAgB,GAASjb,GAC/Cka,QAAoBvB,UAAUyB,aAAac,aAAa,CACtDC,MAAOH,IAGT,MAAM1X,EAASiC,EAAQ4Q,wBAAwB+D,GACzC7K,EAAU,IAAIgH,iBAAiB9Q,EAAS,qBAQ9C,OAPA8J,EAAQiH,KAAKC,YAAY,CAAEtV,KAAM,YAAa6H,SAAQK,eAEtD7F,EAAOqO,QAAQmJ,GACfA,EAASnJ,QAAQtC,SAEX9J,EAAQ6V,SAEP,IAAIvB,EAAMtU,EAASuV,EAAUzL,EAAS6K,EAAa5W,EAC5D,CAAE,MAAO/B,GAAO8Z,IAAAA,EAAAC,EAKd,MAJAD,OAAAA,EAAAnB,IAAAmB,EAAaE,YAAYhT,QAAQwK,IAC/BA,EAAM2B,SAED,OAAP4G,EAAA/V,IAAA+V,EAASpY,QACH3B,CACR,CACF,CAGQ,4BAAOoZ,CACbZ,GAEA,GAAKA,EAGL,OAAOrB,IAAgB,CAAEX,MAAOgC,GAAkB,CAAErC,MAAOqC,EAC7D,CAEAha,WAAAA,CACkBwF,EACAuV,EACAzL,EACT6K,EACCsB,QAJQjW,aAAA,EAAAnF,KACA0a,cACAzL,EAAAA,KAAAA,oBACT6K,iBAAA,EAAA9Z,KACCob,uBAJQ,EAAApb,KAAOmF,QAAPA,EACAnF,KAAQ0a,SAARA,EACA1a,KAAOiP,QAAPA,EACTjP,KAAW8Z,YAAXA,EACC9Z,KAAiBob,kBAAjBA,CACP,CAEI,WAAMtY,GACX9C,KAAK8Z,YAAYqB,YAAYhT,QAAQwK,IACnCA,EAAM2B,SAERtU,KAAKob,kBAAkB/S,mBACjBrI,KAAKmF,QAAQrC,OACrB,CAEOuY,QAAAA,CAAS9U,GACdvG,KAAKiP,QAAQiH,KAAKC,YAAY,CAAEtV,KAAM,WAAY0F,WACpD,CAEO,oBAAM+U,CAAe3B,GAC1B,IAEE,MAAM/Z,EAAOb,EACRya,CAAAA,EAAAA,GAGDG,IACF/Z,EAAQiX,SAAW4C,EAAMc,sBAAsBZ,IAIjD,MAAMiB,EAAW7b,EAAA,CAAK8b,gBAAgB,GAASjb,GAGzC2b,QAAuBhD,UAAUyB,aAAac,aAAa,CAC/DC,MAAOH,IAIT5a,KAAK8Z,YAAYqB,YAAYhT,QAAQwK,IACnCA,EAAM2B,SAERtU,KAAKob,kBAAkB/S,aAGvBrI,KAAK8Z,YAAcyB,EACnBvb,KAAKob,kBACHpb,KAAKmF,QAAQ4Q,wBAAwBwF,GAGvCvb,KAAKob,kBAAkB7J,QAAQvR,KAAK0a,SACtC,CAAE,MAAOvZ,GAEP,MADAgF,QAAQhF,MAAM,iCAAkCA,GAC1CA,CACR,CACF,ECrKK,MAAMqa,EAA2BzM,EACtC,uBAEA,i8ECEW,MAAA0M,EACJ,mBAAahP,EAAO1D,WACzBA,EAAUL,OACVA,EAAM4H,eACNA,EAAcsJ,aACdA,IAEA,IAAIzU,EAA+B,KAC/BiO,EAAwC,KAC5C,IACEjO,EAAU,IAAIqQ,aAAa,CAAEzM,eAC7B,MAAM2R,EAAWvV,EAAQsQ,iBACnBiG,EAAOvW,EAAQwW,aAGrBvI,EAAe,IAAIH,MACnBG,EAAawI,IAAM,GACnBxI,EAAayI,OACbzI,EAAaE,UAAW,EACxBF,EAAaK,MAAMC,QAAU,OAE7BC,SAASC,KAAKC,YAAYT,GAG1B,MAAM0I,EAAc3W,EAAQ4W,+BAC5B3I,EAAa4I,UAAYF,EAAYG,OAErCP,EAAKnK,QAAQmJ,GACbA,EAASnJ,QAAQuK,SAEXN,EACJrW,EAAQ6Q,aACI,MAAZ4D,OAAY,EAAZA,EAAqC,sBAEvC,MAAM3K,EAAU,IAAIgH,iBAAiB9Q,EAAS,wBAmB9C,OAlBA8J,EAAQiH,KAAKC,YAAY,CAAEtV,KAAM,YAAa6H,WAC9CuG,EAAQsC,QAAQmK,SAEVvW,EAAQ6V,SAGV1K,GAAkB8C,EAAaI,iBAC3BJ,EAAaI,UAAUlD,GAGb,IAAImL,EACpBtW,EACAuV,EACAgB,EACAzM,EACAmE,EAIJ,CAAE,MAAOjS,GAAO,IAAA+a,EAAAC,EAUd,MARID,OAAJA,EAAI9I,IAAA8I,EAAczH,YAChBrB,EAAaqB,WAAWC,YAAYtB,GAE1B,OAAZ+I,EAAA/I,IAAA+I,EAAcC,QACVjX,GAA6B,WAAlBA,EAAQgN,aACfhN,EAAQrC,QAGV3B,CACR,CACF,CAEAxB,WAAAA,CACkBwF,EACAuV,EACAgB,EACAzM,EACAmE,QAJAjO,aAAA,EAAAnF,KACA0a,cAAA,EAAA1a,KACA0b,UAAA,EAAA1b,KACAiP,aACAmE,EAAAA,KAAAA,kBAJA,EAAApT,KAAOmF,QAAPA,EACAnF,KAAQ0a,SAARA,EACA1a,KAAI0b,KAAJA,EACA1b,KAAOiP,QAAPA,EACAjP,KAAYoT,aAAZA,CACf,CAEI,qBAAMiJ,CAAgBxF,GAC3B,KAAM,cAAeC,iBAAiB9S,WACpC,MAAU,IAAA5C,MAAM,oDAIZpB,KAAKoT,aAAaI,UAAUqD,GAAY,GAChD,CAEO,WAAM/T,GAEP9C,KAAKoT,aAAaqB,YACpBzU,KAAKoT,aAAaqB,WAAWC,YAAY1U,KAAKoT,cAEhDpT,KAAKoT,aAAagJ,cACRpc,KAACmF,QAAQrC,OACrB,ECrFI,MAAOwZ,UAA0B1d,EAC7B,4BAAa2d,GACnB,GAAI,aAAchE,UAEhB,IACE,aAAaA,UAAUiE,SAASC,QAAQ,SAC1C,CAAE,MAAOC,GAGX,CACA,OACF,IAAA,CAEO,yBAAatD,CAClBxZ,GAAuB,IAAA+c,EAEvB,MAAMtD,EAAcza,EAAiBC,eAAee,GAEhDyZ,EAAY7Z,gBACd6Z,EAAY7Z,eAAe,CAAEU,OAAQ,eAEnCmZ,EAAY5Z,yBACd4Z,EAAY5Z,wBAAwB,CAAEa,iBAAiB,IAGzD,IAAIsc,EAAsB,KACtB/c,EAAoC,KACpCgd,EAAwB,KACxBC,EAA6C,KAG7CN,EAAoC,MADD,OAAtBG,EAAG/c,EAAQmd,cAAWJ,KAGrCH,QAAiBF,EAAkBC,mBAGrC,IAAI,IAAAS,EA6BF,OA1BAF,QAA+BvE,UAAUyB,aAAac,aAAa,CACjEC,OAAO,UAGHrC,EAAWW,EAAYC,iBAC7BzZ,QAAmBsY,EAAiBvY,IACnCgd,EAAOC,SAAgBxP,QAAQ4J,IAAI,CAClCwC,EAAMhN,OAAM1N,EAAA,CAAA,EACPc,EAAWqM,YACdwN,CAAAA,8BAA+B9Z,EAAQ8Z,8BACvCC,cAAe/Z,EAAQ+Z,cACvBC,aAAcha,EAAQga,aACtBC,kBAAmBja,EAAQia,qBAE7B4B,EAAOhP,OAAM1N,EACRc,CAAAA,EAAAA,EAAWsM,aAAY,CAC1BmE,eAAgB1Q,EAAQ0Q,eACxBsJ,aAAcha,EAAQga,kBAIJ,OAAtBoD,EAAAF,IAAAE,EAAwB7B,YAAYhT,QAAQwK,IAC1CA,EAAM2B,SAERwI,EAAyB,KAElB,IAAIR,EACTjD,EACAxZ,EACA+c,EACAC,EACAL,EAEJ,CAAE,MAAOrb,GAAO8b,IAAAA,EAAA1D,EAAA2D,EAAAC,EACV9D,EAAY7Z,gBACd6Z,EAAY7Z,eAAe,CAAEU,OAAQ,iBAEvC+c,OAAAA,EAAAH,IAAAG,EAAwB9B,YAAYhT,QAAQwK,IAC1CA,EAAM2B,SAERiF,OAAAA,EAAA1Z,IAAA0Z,EAAYzW,cACNoa,OAANA,EAAMN,QAAAM,EAAAA,EAAOpa,eACD,OAAZqa,EAAMN,QAAM,EAANM,EAAQra,SACd,IAAI,IAAAsa,QACY,OAAdA,EAAMZ,QAAQ,EAARY,EAAUC,WAChBb,EAAW,IACb,CAAE,MAAOE,GACT,CAAA,MAAMvb,CACR,CACF,CAMAxB,WAAAA,CACEC,EACAC,EACO+c,EACAC,EACAL,GAEP5Q,MAAMhM,EAASC,GAAYG,KAJpB4c,WACAC,EAAAA,KAAAA,YACAL,EAAAA,KAAAA,qBATDc,wBAAkB,EAAAtd,KAClBwQ,yBAAmB,EAAAxQ,KACnBud,wBAA+C,KA8E/CC,KAAAA,sBAAyBxa,IAMX,cAAhBhD,KAAKE,QACPF,KAAKH,WAAWiC,YAAY,CAC1B2b,iBAAkB1P,EAPE/K,EAAMwJ,KAAK,GAOuByB,WAKpDyP,KAAAA,uBAAyB,EAAGlR,WAChB,YAAdA,EAAK3L,MACPb,KAAK2C,WAAW6J,EAAKmR,SAAW,YAAc,aAEjD3d,KAEO4d,oBAAuBC,IAC7B7d,KAAK6c,OAAOnB,KAAKA,KAAKoC,sBACpB9d,KAAK6c,OAAO1X,QAAQ4Y,aAEtB/d,KAAK6c,OAAOnB,KAAKA,KAAKsC,MAAQhe,KAAKG,OACnCH,KAAK6c,OAAO5N,QAAQiH,KAAKC,YAAY,CAAEtV,KAAM,qBAC7Cb,KAAK6c,OAAO5N,QAAQiH,KAAKC,YAAY,CACnCtV,KAAM,SACNoN,OAAQI,EAAoBwP,MAE/B7d,KAEOie,aAAe,KAErBje,KAAK2C,WAAW,aAChB3C,KAAK6c,OAAO5N,QAAQiH,KAAKC,YAAY,CAAEtV,KAAM,cAC7Cb,KAAK6c,OAAOnB,KAAKA,KAAKwC,6BACpB,KACAle,KAAK6c,OAAO1X,QAAQ4Y,YAAc,GAIpC1R,WAAW,KACTrM,KAAK6c,OAAOnB,KAAKA,KAAKsC,MAAQhe,KAAKG,OACnCH,KAAK6c,OAAO5N,QAAQiH,KAAKC,YAAY,CAAEtV,KAAM,sBAC5C,MACJb,KAEOme,gBAAmBC,IACzB,GAA6B,IAAzBA,EAAcnW,OAChB,OACF,EAIA,IAAI9H,EAAS,EACb,IAAK,IAAIwO,EAAI,EAAGA,EAAIyP,EAAcnW,OAAQ0G,IACxCxO,GAAUie,EAAczP,GAAK,IAI/B,OAFAxO,GAAUie,EAAcnW,OAEjB9H,EAAS,EAAI,EAAIA,EAAS,EAAI,EAAIA,GA2IpCsC,KAAAA,UAAY,EAAGtC,aAEpB,MAAMke,EAAgBrV,OAAOsV,SAASne,GAClCoe,KAAKC,IAAI,EAAGD,KAAKE,IAAI,EAAGte,IACxB,EACJH,KAAKG,OAASke,EAEVre,KAAKH,sBAAsBmQ,EAE7BhQ,KAAKH,WAAW8W,eAAe0H,GAG/Bre,KAAK6c,OAAOnB,KAAKA,KAAKsC,MAAQK,GA5RzBre,KAAK4c,MAALA,EACA5c,KAAM6c,OAANA,EACA7c,KAAQwc,SAARA,EAGPxc,KAAK4c,MAAM3N,QAAQiH,KAAKE,UAAYpW,KAAKwd,sBACzCxd,KAAK6c,OAAO5N,QAAQiH,KAAKE,UAAYpW,KAAK0d,uBAEtClB,IAGFxc,KAAKud,wBAA0B,KAAK,IAAAmB,EACD,YAA7B/K,SAASgL,iBAAiCD,OAAJA,EAAI1e,KAAKwc,WAALkC,EAAeE,UAC3DtC,EAAkBC,kBAAkBsC,KAAKC,IACvC9e,KAAKwc,SAAWsC,KAItBnL,SAASvH,iBACP,mBACApM,KAAKud,yBAGX,CAEmB,sBAAM5c,eACXA,mBAERX,KAAKud,yBACP5J,SAASoL,oBACP,mBACA/e,KAAKud,yBAIT,IAAIyB,IAAAA,QACIA,OAANA,EAAMhf,KAAKwc,eAALwC,EAAAA,EAAe3B,WACrBrd,KAAKwc,SAAW,IAClB,CAAE,MAAOE,GAAI,OAEH1c,KAAC4c,MAAM9Z,cACP9C,KAAC6c,OAAO/Z,OACpB,CAEmBhC,kBAAAA,CAAmBkC,GACpC4I,MAAM9K,mBAAmBkC,GACzBhD,KAAKie,cACP,CAEmBrc,WAAAA,CAAYoB,GAQUic,IAAAA,EAAAC,EAPvCtT,MAAMhK,YAAYoB,GAEdA,EAAMyT,YAAY0I,WAAanf,KAAKJ,QAAQwf,kBAC9Cpf,KAAKJ,QAAQwf,iBAAiBpc,EAAMyT,YAAY0I,WAG9Cnf,KAAKD,wBAA0BiD,EAAMyT,YAAY1U,WAC/CiB,EAAMyT,YAAYC,gBACpBuI,OAAAA,GAAAC,OAAKtf,SAAQN,UAAb2f,EAAA/a,KAAAgb,EAAuBlc,EAAMyT,YAAYC,eAInC1W,KAAKH,sBAAsBmQ,GAC/BhQ,KAAK4d,oBAAoB5a,EAAMyT,YAAYC,gBAI/C1W,KAAKI,eAAiB4C,EAAMyT,YAAY1U,SACxC/B,KAAK+C,wBACL/C,KAAK2C,WAAW,YAEpB,CAiEO2D,WAAAA,CAAYC,GAEbvG,KAAKH,sBAAsBmQ,EAC7BhQ,KAAKH,WAAWyG,YAAYC,GAG5BvG,KAAK4c,MAAMvB,SAAS9U,EAExB,CAEOC,yBAAAA,GAKL,aAJAxG,KAAKsd,qBAALtd,KAAKsd,mBAAuB,IAAI3e,WAC9BqB,KAAK4c,MAAMlC,SAASzC,oBAEtBjY,KAAK4c,MAAMlC,SAASxC,qBAAqBlY,KAAKsd,oBACvCtd,KAAKsd,kBACd,CAEO7W,0BAAAA,GAEL,OAAIzG,KAAKH,sBAAsBmQ,EACVhQ,KAAKH,WAAW4G,8BAKxB,IAAA9H,WAAW,OAGAqZ,MAApBhY,KAACwQ,sBAALxQ,KAAKwQ,oBAAwB,IAAI7R,WAC/BqB,KAAK6c,OAAOnC,SAASzC,oBAEvBjY,KAAK6c,OAAOnC,SAASxC,qBAAqBlY,KAAKwQ,0BACnCA,oBACd,CAEO9J,cAAAA,GACL,OAAO1G,KAAKme,gBAAgBne,KAAKwG,4BACnC,CAEOG,eAAAA,GACL,OAAO3G,KAAKme,gBAAgBne,KAAKyG,6BACnC,CAEO,uBAAM4Y,EAAkBtW,WAC7BA,EAAUL,OACVA,EAAMgR,8BACNA,EAA6BC,cAC7BA,IAEA,IAEE,GAAI3Z,KAAKH,sBAAsBmM,EAC7B,IAEE,aADMhM,KAAK4c,MAAMtB,eAAe3B,GACrB3Z,KAAC4c,KACd,CAAE,MAAOzb,GACPgF,QAAQY,KACN,yDACA5F,EAGJ,CAIEnB,KAAKH,sBAAsBmQ,SACnBhQ,KAACH,WAAWqX,oBAAoByC,GAAiB,UAInD3Z,KAAC4c,MAAM9Z,QAEjB,MAAMwc,QAAiB7F,EAAMhN,OAAO,CAClC1D,WAAsB,MAAVA,EAAAA,EAAc/I,KAAKH,WAAWqM,YAAYnD,WACtDL,OAAc,MAANA,EAAAA,EAAU1I,KAAKH,WAAWqM,YAAYxD,OAC9CgR,gCACAC,gBACAC,aAAc5Z,KAAKJ,QAAQga,aAC3BC,kBAAmB7Z,KAAKJ,QAAQia,oBAMlC,OAHA7Z,KAAK4c,MAAQ0C,EACbtf,KAAK4c,MAAM3N,QAAQiH,KAAKE,UAAYpW,KAAKwd,sBAElCxd,KAAK4c,KACd,CAAE,MAAOzb,GAEP,MADAgF,QAAQhF,MAAM,8BAA+BA,GACvCA,CACR,CACF,CAEO,wBAAMoe,EAAmBxW,WAC9BA,EAAUL,OACVA,EAAM4H,eACNA,IAEA,IAEE,GAAItQ,KAAKH,sBAAsBmM,EAC7B,IAEE,aADMhM,KAAK6c,OAAOR,gBAAgB/L,GACvBtQ,KAAC6c,MACd,CAAE,MAAO1b,GACPgF,QAAQY,KACN,0DACA5F,EAGJ,CAIEnB,KAAKH,sBAAsBmQ,SACnBhQ,KAACH,WAAW+W,qBAAqBtG,GAAkB,UAIrDtQ,KAAC6c,OAAO/Z,QAElB,MAAM0c,QAAkB/D,EAAOhP,OAAO,CACpC1D,WAAsB,MAAVA,EAAAA,EAAc/I,KAAKH,WAAWsM,aAAapD,WACvDL,OAAc,MAANA,EAAAA,EAAU1I,KAAKH,WAAWsM,aAAazD,OAC/C4H,iBACAsJ,aAAc5Z,KAAKJ,QAAQga,eAK7B,OAFA5Z,KAAK6c,OAAS2C,EAEPxf,KAAK6c,MACd,CAAE,MAAO1b,GAEP,MADAgF,QAAQhF,MAAM,+BAAgCA,GACxCA,CACR,CACF,EC3WI,SAAUse,EACd/c,EACAgd,EACA9S,EAtBuB,6BAwBvB,MAAMgH,EAIF,GASJ,MAP8B,kBAAnB8L,EACT9L,EAAK+L,SAAWD,EAAiB,OAAS,WAE1C9L,EAAKgM,OAASF,EAAeE,OAC7BhM,EAAKiM,QAAUH,EAAeG,SAGzBjP,MAAM,GAAGhE,6BAAkClK,aAA2B,CAC3Eod,OAAQ,OACRlM,KAAMrP,KAAKC,UAAUoP,GACrBmM,QAAS,CACP,eAAgB,qBAGtB,CCoBA,MAAMC,EAAYrgB,WAAAA,GAAAK,KACRigB,UAA4D,IAAInR,GAAK,CAE7E8C,EAAAA,CAAG5O,EAAekd,GACXlgB,KAAKigB,UAAUE,IAAInd,IACtBhD,KAAKigB,UAAU3Q,IAAItM,EAAO,IAAIod,KAEhC,MAAMC,EAAiBrgB,KAAKigB,UAAU7Q,IAAIpM,GACtCqd,GACFA,EAAeC,IAAIJ,EAEvB,CAEAzO,GAAAA,CAAIzO,EAAekd,GACjB,MAAMG,EAAiBrgB,KAAKigB,UAAU7Q,IAAIpM,GACtCqd,GACFA,EAAeE,OAAOL,EAE1B,CAEAM,IAAAA,CAAKxd,KAAkByd,GACrB,MAAMJ,EAAiBrgB,KAAKigB,UAAU7Q,IAAIpM,GACtCqd,GACFA,EAAelY,QAAQ+X,IACrBA,KAAYO,IAGlB,EAMU,IAAAC,GAAZ,SAAYA,GAEVA,EAAA,gBAAA,kBAEAA,EAAA,mBAAA,qBAEAA,EAAA,qBAAA,uBAEAA,EAAA,qCAAA,uCAEAA,EAAA,WAAA,aAEAA,EAAA,MAAA,QAEAA,EAAA,KAAA,OAEAA,EAAA,MAAA,QAEAA,EAAA,eAAA,iBAEAA,EAAA,iBAAA,mBAEAA,EAAA,kBAAA,oBAEAA,EAAA,iBAAA,mBAEAA,EAAA,aAAA,eAEAA,EAAA,YAAA,cAEAA,EAAA,eAAA,iBAEAA,EAAA,mBAAA,qBAEAA,EAAA,4BAAA,8BAEAA,EAAA,oBAAA,sBAEAA,EAAA,4BAAA,6BACD,CAvCD,CAAYA,IAAAA,EAuCX,WA2DYC,EAMXhhB,WAAAA,CAAYoJ,GALJ6X,KAAAA,UAA8B,KAAI5gB,KAClC6gB,aAA6B,IAAIb,OACjCc,kBAA4B,KAC7BC,KAAAA,mBAGL,EAAA/gB,KAAK8gB,kBAAoB/X,CAC3B,CAMOiY,YAAAA,CAAaJ,GAClB5gB,KAAK4gB,UAAYA,EAGb5gB,KAAK4gB,UAAUK,aAAe9T,UAAU+T,KAC1ClhB,KAAK6gB,aAAaL,KAAKE,EAAeQ,MAGtClhB,KAAK4gB,UAAUxU,iBAAiB,OAAQ,KACtCpM,KAAK6gB,aAAaL,KAAKE,EAAeQ,QAI1ClhB,KAAK4gB,UAAUxU,iBAAiB,UAAYpJ,IAC1C,IACE,MAAMwJ,EAAOjI,KAAKgI,MAAMvJ,EAAMwJ,MAE9B,OAAQA,EAAK2U,cACX,IAAK,kBACHnhB,KAAK6gB,aAAaL,KAAKE,EAAeU,gBAAiB5U,GACvD,MACF,IAAK,qBACHxM,KAAK6gB,aAAaL,KAAKE,EAAeW,mBAAoB7U,GAC1D,MACF,IAAK,uBACHxM,KAAK6gB,aAAaL,KAAKE,EAAeY,qBAAsB9U,GAC5D,MACF,IAAK,uCACHxM,KAAK6gB,aAAaL,KAChBE,EAAea,qCACf/U,GAEF,MAEF,IAAK,aACHxM,KAAK6gB,aAAaL,KAAKE,EAAec,WAAYhV,GAClDxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,iBACHxM,KAAK6gB,aAAaL,KAAKE,EAAegB,eAAgBlV,GACtDxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,mBACHxM,KAAK6gB,aAAaL,KAAKE,EAAeiB,iBAAkBnV,GACxDxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,oBACHxM,KAAK6gB,aAAaL,KAAKE,EAAekB,kBAAmBpV,GACzDxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,mBACHxM,KAAK6gB,aAAaL,KAAKE,EAAemB,iBAAkBrV,GACxDxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,eACHxM,KAAK6gB,aAAaL,KAAKE,EAAeoB,aAActV,GACpDxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,cACHxM,KAAK6gB,aAAaL,KAAKE,EAAeqB,YAAavV,GACnDxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,iBACHxM,KAAK6gB,aAAaL,KAAKE,EAAesB,eAAgBxV,GACtDxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,qBACHxM,KAAK6gB,aAAaL,KAAKE,EAAeuB,mBAAoBzV,GAC1DxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,8BACHxM,KAAK6gB,aAAaL,KAChBE,EAAewB,4BACf1V,GAEFxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,sBACHxM,KAAK6gB,aAAaL,KAAKE,EAAeyB,oBAAqB3V,GAC3DxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,8BACHxM,KAAK6gB,aAAaL,KAChBE,EAAe0B,4BACf5V,GAEFxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,IAAK,QACHxM,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOjV,GAC7C,MACF,QACErG,QAAQY,KAAK,wBAAyByF,GAE5C,CAAE,MAAOrL,GACPgF,QAAQhF,MAAM,qCAAsCA,EAAO6B,EAAMwJ,MACjExM,KAAK6gB,aAAaL,KAChBE,EAAee,MACf,IAAIrgB,MAAM,4BAA4BD,KAE1C,IAGFnB,KAAK4gB,UAAUxU,iBAAiB,QAAUjL,IACxCgF,QAAQhF,MAAM,mBAAoBA,GAClCnB,KAAK6gB,aAAaL,KAAKE,EAAee,MAAOtgB,KAG/CnB,KAAK4gB,UAAUxU,iBAAiB,QAAUpJ,IAMxC,GALAmD,QAAQkc,IACN,0BAA0Brf,EAAM+C,iBAAiB/C,EAAMH,qBAAqBG,EAAMsf,aAI/Etf,EAAMsf,UAA4B,MAAftf,EAAM+C,MAAgC,OAAf/C,EAAM+C,KAAgB,CACnE,MAAMwc,EAAe,kCAAkCvf,EAAM+C,UAAU/C,EAAMH,QAAU,uBACvFsD,QAAQhF,MAAMohB,GACdviB,KAAK6gB,aAAaL,KAAKE,EAAee,MAAO,IAAIrgB,MAAMmhB,GACzD,CAEAviB,KAAK6gB,aAAaL,KAAKE,EAAe8B,MAAOxf,IAEjD,CAuBO4O,EAAAA,CACL5O,EACAkd,GAIAlgB,KAAK6gB,aAAajP,GAAG5O,EAAOkd,EAC9B,CAiBOzO,GAAAA,CACLzO,EACAkd,GAIAlgB,KAAK6gB,aAAapP,IAAIzO,EAAOkd,EAC/B,CA4BOzS,IAAAA,CAAKjB,GAKX,IAAAiW,EAAAC,EACC,IAAK1iB,KAAK4gB,WAAa5gB,KAAK4gB,UAAUK,aAAe9T,UAAU+T,KAC7D,UAAU9f,MAAM,8BAGlB,MAAMC,EAA2B,CAC/B8f,aAAc,oBACdzK,cAAelK,EAAKmW,YACpBC,OAAmBH,OAAbA,EAAEjW,EAAKoW,SAAMH,EACnBI,mBAAWH,EAAElW,EAAKzD,YAAU2Z,EAAI1iB,KAAK8gB,kBACrCgC,cAAetW,EAAKuW,cAGtB/iB,KAAK4gB,UAAUnT,KAAKlJ,KAAKC,UAAUnD,GACrC,CAuBOuhB,MAAAA,GACL,IAAK5iB,KAAK4gB,WAAa5gB,KAAK4gB,UAAUK,aAAe9T,UAAU+T,KAC7D,MAAM,IAAI9f,MAAM,8BAUlBpB,KAAK4gB,UAAUnT,KAAKlJ,KAAKC,UAPQ,CAC/B2c,aAAc,oBACdzK,cAAe,GACfkM,QAAQ,EACRC,YAAa7iB,KAAK8gB,oBAItB,CAkBOhe,KAAAA,GAED9C,KAAK+gB,eACP/gB,KAAK+gB,gBAIH/gB,KAAK4gB,WACP5gB,KAAK4gB,UAAU9d,MAAM,IAAM,qBAE/B,EC7eK,MAAMkgB,EAA2BjU,EACtC,uBAEA,ssGCHU,IAAAkU,EAUAC,GAVZ,SAAYD,GACVA,EAAA,SAAA,WACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,WACD,CARD,CAAYA,IAAAA,EAQX,CAAA,IAED,SAAYC,GACVA,EAAA,OAAA,SACAA,EAAA,IAAA,KACD,CAHD,CAAYA,IAAAA,EAGX,CAAA,IAiFY,MAAAC,EAGH,sBAAOC,CACbC,EAAkBF,EAAeG,kBAEjC,MAAO,GAAGD,8BACZ,CAEQ,wBAAOE,CACb3jB,GAEA,MAAMyjB,EAAUF,EAAeC,gBAAgBxjB,EAAQyjB,SACjDG,EAAS,IAAIC,gBAanB,GAVAD,EAAOE,OAAO,WAAY9jB,EAAQ+jB,SAClCH,EAAOE,OAAO,QAAS9jB,EAAQoR,YAGA1E,IAA3B1M,EAAQgkB,gBACVJ,EAAOE,OAAO,kBAAmB9jB,EAAQgkB,qBAEftX,IAAxB1M,EAAQikB,aACVL,EAAOE,OAAO,eAAgB9jB,EAAQikB,kBAEAvX,IAApC1M,EAAQkkB,wBAAuC,CACjD,GACElkB,EAAQkkB,yBAA2B,IACnClkB,EAAQkkB,wBAA0B,EAElC,MAAM,IAAI1iB,MAAM,uDAElBoiB,EAAOE,OACL,6BACA9jB,EAAQkkB,wBAAwB7R,WAEpC,CACA,QAA6B3F,IAAzB1M,EAAQmkB,aAA4B,CACtC,GAAInkB,EAAQmkB,aAAe,IAAOnkB,EAAQmkB,aAAe,GACvD,MAAU,IAAA3iB,MAAM,4CAElBoiB,EAAOE,OAAO,gBAAiB9jB,EAAQmkB,aAAa9R,WACtD,CACA,QAAoC3F,IAAhC1M,EAAQokB,oBAAmC,CAC7C,GACEpkB,EAAQokB,qBAAuB,IAC/BpkB,EAAQokB,oBAAsB,IAE9B,MAAM,IAAI5iB,MAAM,mDAElBoiB,EAAOE,OACL,yBACA9jB,EAAQokB,oBAAoB/R,WAEhC,CACA,QAAqC3F,IAAjC1M,EAAQqkB,qBAAoC,CAC9C,GACErkB,EAAQqkB,sBAAwB,IAChCrkB,EAAQqkB,qBAAuB,IAE/B,MAAU,IAAA7iB,MAAM,oDAElBoiB,EAAOE,OACL,0BACA9jB,EAAQqkB,qBAAqBhS,WAEjC,MAC6B3F,IAAzB1M,EAAQskB,cACVV,EAAOE,OAAO,gBAAiB9jB,EAAQskB,mBAEP5X,IAA9B1M,EAAQukB,mBACVX,EAAOE,OACL,qBACA9jB,EAAQukB,kBAAoB,OAAS,SAIzC,MAAMC,EAAcZ,EAAOvR,WAC3B,OAAOmS,EAAc,GAAGf,KAAWe,IAAgBf,CACrD,CA6BO,cAAO9R,CACZ3R,GAEA,IAAKA,EAAQ+jB,QACX,MAAM,IAAIviB,MAAM,uBAIlB,MAIMvB,EAAa,IAAI8gB,EAHrB,eAAgB/gB,GAAWA,EAAQykB,WAC/B,KACCzkB,EAAyBmJ,YAI1Bub,EAAMnB,EAAeI,kBAAkB3jB,GAEvCghB,EAAY,IAAIzT,UAAUmX,GAchC,MAXI,eAAgB1kB,GAAWA,EAAQykB,YACrCzD,EAAUxU,iBAAiB,OAAQ,KACjC+W,EAAeoB,qBACb3kB,EACAC,KAKNA,EAAWmhB,aAAaJ,GAEjB/gB,CACT,CAEQ,iCAAa0kB,CACnB3kB,EACAC,GAEA,MAAM2kB,EAAqB,KAE3B,IAAIC,IAAAA,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAEF,MAAMjJ,QAAe1D,UAAUyB,aAAac,aAAa,CACvDC,MAAO,CACLlE,SAAU4N,OAAFA,EAAE7kB,EAAQykB,iBAARI,EAAAA,EAAoB5N,SAC9BU,iBAAsDmN,OAAtCA,EAAEC,OAAFA,EAAE/kB,EAAQykB,iBAARM,EAAAA,EAAoBpN,mBAAgBmN,EACtDlN,iBAAsDoN,OAAtCA,EAAEC,OAAFA,EAAEjlB,EAAQykB,iBAARQ,EAAAA,EAAoBrN,mBAAgBoN,EACtDnN,gBAAoDqN,OAArCA,EAAEC,OAAFA,EAAEnlB,EAAQykB,iBAARU,EAAAA,EAAoBtN,kBAAeqN,EACpDpN,aAA8CsN,OAAlCA,EAAEC,OAAFA,EAAErlB,EAAQykB,iBAARY,EAAAA,EAAoBvN,cAAYsN,EAAI,EAClDjc,WAAY,CAAE4O,MAAO6M,MAKnBW,EAAgBD,OAAHA,EAAGjJ,EAAOmJ,iBAAiB,SAAxBF,EAAAA,EAA4BG,cAC5CC,EAAmBH,MAAAA,OAAAA,EAAAA,EAAepc,WAIlCwM,EAAe,IAAIC,aACvB8P,EAAmB,CAAEvc,WAAYuc,GAAqB,CAAE,SAIpDtC,EAAyBzN,EAAaS,cAG5C,MAAM9S,EAASqS,EAAaQ,wBAAwBkG,GAC9CsJ,EAAa,IAAItP,iBACrBV,EACA,wBAKEA,EAAaxM,aAAeyb,GAC9Be,EAAWrP,KAAKC,YAAY,CAC1BtV,KAAM,YACN2kB,gBAAiBjQ,EAAaxM,WAC9B0c,iBAAkBjB,IAKtBe,EAAWrP,KAAKE,UAAYpT,IAC1B,MAAMqT,UAAEA,GAAcrT,EAAMwJ,KAEtBkC,EAAQ,IAAI/P,WAAW0X,GAC7B,IAAIqP,EAAS,GACb,IAAK,IAAI/W,EAAI,EAAGA,EAAID,EAAMzG,OAAQ0G,IAChC+W,GAAUpkB,OAAO8M,aAAaM,EAAMC,IAEtC,MAAM4H,EAAcpI,KAAKuX,GAEzB7lB,EAAW4N,KAAK,CAAEkV,YAAapM,KAIjCrT,EAAOqO,QAAQgU,GAGY,cAAvBhQ,EAAapD,aACToD,EAAayF,SAIrBnb,EAAWkhB,cAAgB,KACzB9E,EAAOd,YAAYhT,QAAQwK,IACzBA,EAAM2B,SAERpR,EAAOmF,aACPkd,EAAWld,aACXkN,EAAazS,QAEjB,CAAE,MAAO3B,GAEP,MADAgF,QAAQhF,MAAM,wCAAyCA,GACjDA,CACR,CACF,EAnOWgiB,EACaG,iBAAmB,gCC7BhCqC,UAAqB/mB,EACzB,mBAAOwa,CAAaxZ,GACzB,OAAOA,EAAQqL,SACXkO,EAAiBC,aAAaxZ,GAC9B0c,EAAkBlD,aAAaxZ,EACrC"}